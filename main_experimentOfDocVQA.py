'''
DocVQA/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ 1.png
â”‚   â”œâ”€â”€ 2.png
â”‚   â””â”€â”€ ...
â””â”€â”€ questions/
    â”œâ”€â”€ 1.txt
    â”œâ”€â”€ 2.txt
    â””â”€â”€ ...
'''

'''
DocVQAå®éªŒæ–‡æ¡£

'''

# main_experiment_docvqa.py - é’ˆå¯¹DocVQAæ•°æ®é›†çš„ç‰ˆæœ¬

import os
import json
import time
import csv
import numpy as np
from PIL import Image
import requests
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple, Any
from tqdm import tqdm
import re
import base64
import ast
from io import BytesIO
import glob


# ==================== é…ç½® ====================
@dataclass
class Config:
    # æœåŠ¡å™¨é…ç½®
    SERVER_IP = "è¿™æ˜¯æˆ‘çš„æœåŠ¡å™¨IPåœ°å€ï¼Œæˆ‘éšè—äº†"
    QWEN_URL = f"http://{SERVER_IP}:8020/chat_vl"
    CLIP_URL = f"http://{SERVER_IP}:8021/clip/score"
    SAM_URL = f"http://{SERVER_IP}:8022/segment_by_bbox"

    # DocVQAæ•°æ®é›†è·¯å¾„
    DATA_ROOT = r"C:\Users\kuanzhang\Desktop\courseB\fuwuqisanhaoji\DocVQA"  # ä¿®æ”¹è¿™é‡Œ
    IMAGE_DIR = os.path.join(DATA_ROOT, "images")
    QUESTION_DIR = os.path.join(DATA_ROOT, "questions")
    METADATA_PATH = os.path.join(DATA_ROOT, "metadata.json")  # ä¼šç”Ÿæˆè¿™ä¸ªæ–‡ä»¶

    # å®éªŒå‚æ•°
    MAX_RETRIES = 2
    CONFIDENCE_THRESHOLD = 0.2
    TEMP_EVIDENCE_PATH = "./temp_evidence.png"

    # è¾“å‡ºè·¯å¾„
    OUTPUT_DIR = "./docvqa_experiment_results"
    RESULTS_JSON = os.path.join(OUTPUT_DIR, "results.json")
    STATS_CSV = os.path.join(OUTPUT_DIR, "statistics.csv")
    SAM_SEGMENTS_DIR = os.path.join(OUTPUT_DIR, "sam_segments")

    # å®éªŒè®¾ç½®,æ ·æœ¬æ•°ï¼Œéšæœºç§å­
    NUM_SAMPLES = 200
    RANDOM_SEED = 42


# ==================== æ•°æ®ç»“æ„ ====================
@dataclass
class ExperimentResult:
    sample_id: int
    image_file: str
    question: str
    ground_truth_answers: List[str]

    # ç³»ç»Ÿè¾“å‡º
    initial_answer: str = ""
    initial_bbox: str = ""
    refined_answer: str = ""
    final_confidence: float = 0.0
    clip_scores: Dict[str, float] = None

    # æ€§èƒ½æŒ‡æ ‡
    iteration_count: int = 0
    sam_calls: int = 0
    clip_calls: int = 0
    qwen_calls: int = 0
    total_time: float = 0.0

    # è¯„ä¼°
    accuracy: float = 0.0
    is_correct: bool = False
    failure_type: str = ""
    notes: str = ""

    def __post_init__(self):
        if self.clip_scores is None:
            self.clip_scores = {}


@dataclass
class SystemStatistics:
    total_samples: int = 0
    correct_samples: int = 0
    total_iterations: int = 0
    total_sam_calls: int = 0
    total_clip_calls: int = 0
    total_qwen_calls: int = 0
    total_time: float = 0.0

    # æŒ‰å¤±è´¥ç±»å‹ç»Ÿè®¡
    failure_counts: Dict[str, int] = None

    def __post_init__(self):
        if self.failure_counts is None:
            self.failure_counts = {
                "location_failure": 0,
                "segmentation_failure": 0,
                "reasoning_failure": 0,
                "verification_failure": 0,
                "other": 0
            }

    @property
    def accuracy(self) -> float:
        return self.correct_samples / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_iterations(self) -> float:
        return self.total_iterations / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_time_per_sample(self) -> float:
        return self.total_time / self.total_samples if self.total_samples > 0 else 0


# ==================== å·¥å…·å‡½æ•° ====================
def parse_question_file(file_path: str) -> Tuple[str, List[str]]:
    """è§£æé—®é¢˜æ–‡ä»¶ï¼Œæå–é—®é¢˜å’Œç­”æ¡ˆ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()

        # æå–é—®é¢˜
        question_match = re.search(r'QUESTION:\s*(.*?)(?:\n|$)', content)
        question = question_match.group(1).strip() if question_match else ""

        # æå–ç­”æ¡ˆ
        answers_match = re.search(r'ANSWERS:\s*(.*?)(?:\n|$)', content)
        answers_str = answers_match.group(1).strip() if answers_match else "[]"

        # å°†å­—ç¬¦ä¸²å½¢å¼çš„åˆ—è¡¨è½¬æ¢ä¸ºå®é™…çš„åˆ—è¡¨
        try:
            # ä½¿ç”¨ast.literal_evalå®‰å…¨åœ°è¯„ä¼°å­—ç¬¦ä¸²
            answers = ast.literal_eval(answers_str)
            # ç¡®ä¿æ‰€æœ‰ç­”æ¡ˆæ˜¯å­—ç¬¦ä¸²
            answers = [str(ans) for ans in answers]
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–
            answers = []
            # åŒ¹é…å•å¼•å·æˆ–åŒå¼•å·å†…çš„å†…å®¹
            answer_matches = re.findall(r"['\"](.*?)['\"]", answers_str)
            answers = answer_matches if answer_matches else []

        return question, answers
    except Exception as e:
        print(f"è§£æé—®é¢˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return "", []


def load_docvqa_dataset(config: Config) -> List[Dict]:
    """åŠ è½½DocVQAæ•°æ®é›†"""
    print("ğŸ“Š å¼€å§‹åŠ è½½DocVQAæ•°æ®é›†...")

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„å…ƒæ•°æ®
    if os.path.exists(config.METADATA_PATH):
        print(f"ğŸ“ ä»ç¼“å­˜åŠ è½½å…ƒæ•°æ®: {config.METADATA_PATH}")
        with open(config.METADATA_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(data)} ä¸ªæ ·æœ¬")
        return data

    # æ‰«æå›¾åƒæ–‡ä»¶
    image_files = []
    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.gif']

    for ext in image_extensions:
        image_files.extend(glob.glob(os.path.join(config.IMAGE_DIR, f"*{ext}")))

    print(f"ğŸ“· æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")

    samples = []

    # å¤„ç†æ¯ä¸ªå›¾åƒ
    for image_path in tqdm(image_files, desc="å¤„ç†å›¾åƒ"):
        image_file = os.path.basename(image_path)
        image_id = os.path.splitext(image_file)[0]  # å»æ‰æ‰©å±•å

        # æ„å»ºå¯¹åº”çš„é—®é¢˜æ–‡ä»¶è·¯å¾„
        question_file = os.path.join(config.QUESTION_DIR, f"{image_id}.txt")

        # æ£€æŸ¥é—®é¢˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(question_file):
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ‰©å±•å
            found = False
            for q_ext in ['.txt', '.TXT', '.text']:
                alt_question_file = os.path.join(config.QUESTION_DIR, f"{image_id}{q_ext}")
                if os.path.exists(alt_question_file):
                    question_file = alt_question_file
                    found = True
                    break

            if not found:
                print(f"âš ï¸ æœªæ‰¾åˆ°é—®é¢˜æ–‡ä»¶: {image_id}")
                continue

        # è§£æé—®é¢˜æ–‡ä»¶
        question, answers = parse_question_file(question_file)

        if not question:
            print(f"âš ï¸ é—®é¢˜ä¸ºç©º: {image_id}")
            continue

        # åˆ›å»ºæ ·æœ¬
        sample = {
            'id': len(samples) + 1,
            'image_file': image_file,
            'question': question,
            'answers': answers,
            'image_id': image_id
        }

        samples.append(sample)

    print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(samples)} ä¸ªæ ·æœ¬")

    # ä¿å­˜å…ƒæ•°æ®ä»¥ä¾¿ä¸‹æ¬¡å¿«é€ŸåŠ è½½
    os.makedirs(os.path.dirname(config.METADATA_PATH), exist_ok=True)
    with open(config.METADATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(samples, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {config.METADATA_PATH}")
    return samples


def load_docvqa_dataset_for_experiment(config: Config) -> List[Dict]:
    """åŠ è½½DocVQAæ•°æ®é›†å¹¶éšæœºé€‰æ‹©æ ·æœ¬"""
    # åŠ è½½å®Œæ•´æ•°æ®é›†
    all_samples = load_docvqa_dataset(config)

    if not all_samples:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ ·æœ¬")
        return []

    # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆç¡®ä¿å¯å¤ç°ï¼‰
    np.random.seed(config.RANDOM_SEED)
    num_samples = min(config.NUM_SAMPLES, len(all_samples))
    selected_indices = np.random.choice(len(all_samples), num_samples, replace=False)

    selected_samples = []
    for idx in selected_indices:
        sample = all_samples[idx].copy()
        selected_samples.append(sample)

    print(f"ğŸ¯ éšæœºé€‰æ‹©äº† {len(selected_samples)} ä¸ªæ ·æœ¬è¿›è¡Œå®éªŒ")

    # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    if selected_samples:
        print("\nğŸ“ˆ æ ·æœ¬ç»Ÿè®¡:")
        print(f"  å¹³å‡ç­”æ¡ˆæ•°é‡: {np.mean([len(s['answers']) for s in selected_samples]):.2f}")
        print(f"  é—®é¢˜å¹³å‡é•¿åº¦: {np.mean([len(s['question']) for s in selected_samples]):.2f} å­—ç¬¦")

        # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
        print("\nğŸ“‹ å‰3ä¸ªæ ·æœ¬é¢„è§ˆ:")
        for i in range(min(3, len(selected_samples))):
            print(f"  æ ·æœ¬ {i + 1}: {selected_samples[i]['question'][:50]}...")
            print(f"       ç­”æ¡ˆ: {selected_samples[i]['answers'][:2] if selected_samples[i]['answers'] else 'æ— ç­”æ¡ˆ'}")

    return selected_samples


def image_to_base64(image_path: str, max_size=(512, 512)) -> str:
    """å›¾åƒè½¬Base64"""
    try:
        img = Image.open(image_path)
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
        img.thumbnail(max_size)
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ å›¾åƒè½¬Base64å¤±è´¥: {e}")
        return ""


def call_qwen(prompt: str, image_path: str = None, config: Config = None) -> str:
    """è°ƒç”¨Qwen-VLæœåŠ¡"""
    try:
        payload = {"prompt": prompt}
        if image_path and os.path.exists(image_path):
            print(f"ğŸ“¤ å‘é€å›¾åƒ: {os.path.basename(image_path)}")
            payload["image_url"] = image_to_base64(image_path)

        response = requests.post(config.QWEN_URL, json=payload, timeout=120)

        print(f"ğŸ“¡ Qwenå“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code == 200:
            res = response.json()
            print(f"ğŸ“¥ QwenåŸå§‹å“åº”: {res}")
            return res.get("response", "").strip()
        else:
            print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except requests.exceptions.Timeout:
        print("â° Qwenè°ƒç”¨è¶…æ—¶")
    except Exception as e:
        print(f"ğŸ’¥ Qwenè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return ""


def call_sam(image_path: str, bbox_str: str, config: Config,
             save_segment: bool = True, iteration: int = 1) -> bool:
    """è°ƒç”¨SAMæœåŠ¡ï¼Œæ·»åŠ å›¾åƒéªŒè¯"""
    try:
        with open(image_path, 'rb') as f:
            files = {'image': f}
            data = {'bbox': bbox_str}
            response = requests.post(config.SAM_URL, files=files, data=data, timeout=30)

            if response.status_code == 200:
                # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '')

                if 'image/png' in content_type:
                    segment_data = response.content

                    # === å…³é”®ä¿®å¤ï¼šéªŒè¯å›¾åƒæ•°æ®æ˜¯å¦æœ‰æ•ˆ ===
                    if len(segment_data) == 0:
                        print(f"âŒ SAMè¿”å›ç©ºå›¾åƒæ•°æ®")
                        return False

                    # å°è¯•è§£æå›¾åƒéªŒè¯å…¶æœ‰æ•ˆæ€§
                    try:
                        from PIL import Image
                        import io
                        img = Image.open(io.BytesIO(segment_data))
                        img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
                        width, height = img.size

                        if width == 0 or height == 0:
                            print(f"âŒ SAMè¿”å›æ— æ•ˆå›¾åƒå°ºå¯¸: {width}x{height}")
                            return False

                    except Exception as e:
                        print(f"âŒ SAMè¿”å›æ— æ•ˆå›¾åƒæ•°æ®: {e}")
                        return False
                    # === ç»“æŸéªŒè¯ ===

                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ç”¨äºåç»­å¤„ç†
                    with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                        out.write(segment_data)

                    # å¦‚æœéœ€è¦ä¿å­˜åˆ†å‰²å›¾åƒ
                    if save_segment:
                        segment_path = save_sam_segment(
                            segment_data, image_path, bbox_str, iteration, config
                        )
                        print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜: {segment_path}")

                    return True
                else:
                    # å¯èƒ½æ˜¯JSONé”™è¯¯å“åº”
                    try:
                        error_info = response.json()
                        print(f"âŒ SAMæœåŠ¡è¿”å›é”™è¯¯: {error_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    except:
                        print(f"âŒ SAMè¿”å›éå›¾åƒå“åº”: {content_type}")
                    return False
            else:
                print(f"âŒ SAMè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
                return False
    except Exception as e:
        print(f"ğŸ’¥ SAMè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
        return False


def call_clip(image_bytes: bytes, text_label: str, config: Config) -> float:
    """è°ƒç”¨CLIPæœåŠ¡ï¼Œè¿”å›æœ€é«˜ç›¸ä¼¼åº¦"""
    files = {'imagefile': ('evidence.png', image_bytes, 'image/png')}
    data = {'text': text_label, 'temperature': 100.0}

    try:
        response = requests.post(config.CLIP_URL, files=files, data=data, timeout=10)
        if response.status_code == 200:
            res = response.json()
            if res.get('results'):
                # è¿”å›æ‰€æœ‰æ ‡ç­¾ä¸­çš„æœ€é«˜ç›¸ä¼¼åº¦
                similarities = [v['similarity'] for v in res['results'].values()]
                return float(max(similarities)) if similarities else 0.0
        else:
            print(f"âŒ CLIPè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ CLIPè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return 0.0


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1, x2 = sorted([max(0, min(img_w, x)) for x in (x1, x2)])
            y1, y2 = sorted([max(0, min(img_h, y)) for y in (y1, y2)])
            return f"{x1},{y1},{x2},{y2}"

    # æœªæ‰¾åˆ°åæ ‡ï¼Œè¿”å›å…¨å›¾
    return f"0,0,{img_w},{img_h}"


def normalize_answer(answer: str) -> str:
    """æ ‡å‡†åŒ–ç­”æ¡ˆï¼šå°å†™ã€ç§»é™¤æ ‡ç‚¹ã€ç©ºæ ¼"""
    if not answer:
        return ""
    # è½¬æ¢ä¸ºå°å†™
    answer = answer.lower()
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™æ•°å­—å’Œå­—æ¯ï¼‰
    answer = re.sub(r'[^\w\s\d]', '', answer)
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    answer = ' '.join(answer.split())
    return answer


def calculate_accuracy(predicted_answer: str, ground_truths: List[str]) -> Tuple[float, bool]:
    """è®¡ç®—ç­”æ¡ˆå‡†ç¡®æ€§ï¼ˆé’ˆå¯¹DocVQAä¼˜åŒ–ï¼‰"""
    if not predicted_answer:
        return 0.0, False

    pred_normalized = normalize_answer(predicted_answer)

    for truth in ground_truths:
        if not truth:
            continue

        truth_normalized = normalize_answer(truth)

        # ç²¾ç¡®åŒ¹é…
        if pred_normalized == truth_normalized:
            return 1.0, True

        # åŒ…å«åŒ¹é…ï¼ˆé’ˆå¯¹è¾ƒé•¿ç­”æ¡ˆï¼‰
        if truth_normalized in pred_normalized or pred_normalized in truth_normalized:
            return 1.0, True

        # æ•°å­—æå–åŒ¹é…ï¼ˆé’ˆå¯¹DocVQAä¸­çš„æ•°å€¼é—®é¢˜ï¼‰
        pred_digits = re.findall(r'\d+\.?\d*', pred_normalized)
        truth_digits = re.findall(r'\d+\.?\d*', truth_normalized)

        if pred_digits and truth_digits:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„æ•°å­—
            for p_digit in pred_digits:
                for t_digit in truth_digits:
                    # ç§»é™¤å‰å¯¼é›¶å’Œå°æ•°ç‚¹åçš„é›¶
                    p_clean = p_digit.lstrip('0').rstrip('.') if '.' in p_digit else p_digit.lstrip('0')
                    t_clean = t_digit.lstrip('0').rstrip('.') if '.' in t_digit else t_digit.lstrip('0')

                    if p_clean and t_clean and p_clean == t_clean:
                        return 1.0, True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯ï¼ˆé’ˆå¯¹DocVQAæ–‡æ¡£ä¸­çš„ç‰¹å®šä¿¡æ¯ï¼‰
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é’ˆå¯¹æ–‡æ¡£ç†è§£çš„ç‰¹å®šåŒ¹é…è§„åˆ™

        # æ£€æŸ¥æ˜¯å¦ä¸º"yes/no"ç±»å‹é—®é¢˜
        if pred_normalized in ['yes', 'no', 'true', 'false'] and truth_normalized in ['yes', 'no', 'true', 'false']:
            if pred_normalized == truth_normalized:
                return 1.0, True

    return 0.0, False


def analyze_failure_type(result: ExperimentResult, config: Config) -> str:
    """åˆ†æå¤±è´¥ç±»å‹"""
    if result.final_confidence < config.CONFIDENCE_THRESHOLD:
        return "verification_failure"
    elif result.iteration_count == 0:
        return "location_failure"
    elif "æ— æ³•" in result.refined_answer or "ä¸èƒ½" in result.refined_answer or "no" in result.refined_answer.lower():
        return "reasoning_failure"
    else:
        return "other"


def get_fallback_bbox(current_bbox: str, img_w: int, img_h: int, iteration: int) -> str:
    """è·å–æ™ºèƒ½å›é€€çš„bbox"""
    try:
        # è§£æå½“å‰bbox
        x1, y1, x2, y2 = map(int, current_bbox.split(','))

        if iteration == 1:
            # ç¬¬ä¸€æ¬¡å›é€€ï¼šæ‰©å¤§åŒºåŸŸï¼ˆ1.5å€ï¼‰
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            width = x2 - x1
            height = y2 - y1

            # ç¡®ä¿æœ‰æœ€å°å°ºå¯¸
            min_size = 50
            width = max(width, min_size)
            height = max(height, min_size)

            # æ‰©å¤§1.5å€
            new_width = int(width * 1.5)
            new_height = int(height * 1.5)

            x1 = max(0, center_x - new_width // 2)
            y1 = max(0, center_y - new_height // 2)
            x2 = min(img_w, center_x + new_width // 2)
            y2 = min(img_h, center_y + new_height // 2)

            return f"{x1},{y1},{x2},{y2}"

        else:
            # åç»­å›é€€ï¼šä½¿ç”¨å…¨å›¾
            return f"0,0,{img_w},{img_h}"

    except:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›å…¨å›¾
        return f"0,0,{img_w},{img_h}"


# ==================== ä¸»å®éªŒæµç¨‹ ====================
def run_single_experiment(sample: Dict, config: Config) -> ExperimentResult:
    """è¿è¡Œå•ä¸ªæ ·æœ¬çš„å®éªŒ"""
    result = ExperimentResult(
        sample_id=sample['id'],
        image_file=sample['image_file'],
        question=sample['question'],
        ground_truth_answers=sample['answers']
    )

    start_time = time.time()
    image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])

    # Step 1: è·å–å›¾åƒå°ºå¯¸
    try:
        with Image.open(image_path) as img:
            img_w, img_h = img.size
            print(f"ğŸ“ å›¾åƒå°ºå¯¸: {img_w}x{img_h}")

            # æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰æ•ˆ
            if img_w == 0 or img_h == 0:
                result.notes = f"æ— æ•ˆå›¾åƒå°ºå¯¸: {img_w}x{img_h}"
                result.total_time = time.time() - start_time
                return result
    except Exception as e:
        result.notes = f"æ— æ³•æ‰“å¼€å›¾åƒ: {e}"
        result.total_time = time.time() - start_time
        return result

    # Step 2: Qwenåˆæ­¥å›ç­” + å®šä½
    prompt1 = f"é—®é¢˜ï¼š{sample['question']} è¯·å…ˆç»™å‡ºç­”æ¡ˆï¼›å†ä»¥æ ¼å¼(å·¦ä¸Šè§’xåæ ‡,å·¦ä¸Šè§’yåæ ‡) (å³ä¸‹è§’xåæ ‡,å³ä¸‹è§’yåæ ‡) ä¸¤ç‚¹ç”Ÿæˆçš„çŸ©å½¢æ¡†å°†å›¾ç‰‡éœ€è¦å…³æ³¨åŒºåŸŸåŒ…å›´è¿›å»ã€‚"
    print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º: {prompt1}")

    initial_response = call_qwen(prompt1, image_path, config)
    result.qwen_calls += 1

    if not initial_response:
        result.notes = "Qwenåˆæ­¥å›ç­”å¤±è´¥"
        result.total_time = time.time() - start_time
        return result

    print(f"ğŸ“¥ Qwenåˆæ­¥å›ç­”: {initial_response}")
    result.initial_answer = initial_response
    result.initial_bbox = extract_bbox_from_text(initial_response, img_w, img_h)
    print(f"ğŸ“ æå–çš„BBox: {result.initial_bbox}")

    # Step 3: é—­ç¯éªŒè¯å¾ªç¯
    bbox_str = result.initial_bbox
    refined_answer = ""
    confidence = 0.0
    iteration = 0
    sam_failures = 0  # SAMå¤±è´¥è®¡æ•°å™¨

    for retry in range(config.MAX_RETRIES + 1):
        iteration += 1
        print(f"ğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£å°è¯•...")
        print(f"ğŸ“ ä½¿ç”¨BBox: {bbox_str}")

        # è°ƒç”¨SAMåˆ†å‰²ï¼Œå¹¶ä¿å­˜å›¾åƒ
        sam_success = call_sam(image_path, bbox_str, config,
                               save_segment=True, iteration=iteration)

        # === å…³é”®ä¿®å¤ï¼šéªŒè¯SAMè°ƒç”¨æ˜¯å¦æˆåŠŸ ===
        if not sam_success:
            sam_failures += 1
            result.notes = f"SAMåˆ†å‰²å¤±è´¥ (ç¬¬{sam_failures}æ¬¡)"

            # å¦‚æœSAMè¿ç»­å¤±è´¥2æ¬¡ï¼Œç›´æ¥é€€å‡ºå¾ªç¯
            if sam_failures >= 2:
                print(f"âš ï¸ SAMè¿ç»­å¤±è´¥{sam_failures}æ¬¡ï¼Œè·³è¿‡æ­¤æ ·æœ¬")
                break

            # å°è¯•ä½¿ç”¨å›é€€ç­–ç•¥ï¼šå…ˆæ‰©å¤§åŒºåŸŸï¼Œå†å…¨å›¾
            bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
            print(f"ğŸ”„ å°è¯•å›é€€BBox: {bbox_str}")
            continue  # è·³è¿‡åç»­æ­¥éª¤ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£

        result.sam_calls += 1
        sam_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°å™¨

        # æ£€æŸ¥è¯æ®å›¾æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        if not os.path.exists(config.TEMP_EVIDENCE_PATH):
            result.notes = f"è¯æ®å›¾æœªç”Ÿæˆ (è¿­ä»£{iteration})"
            # å°è¯•å›é€€
            bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
            continue

        # æ£€æŸ¥è¯æ®å›¾æ˜¯å¦ä¸ºç©º
        try:
            evidence_size = os.path.getsize(config.TEMP_EVIDENCE_PATH)
            if evidence_size == 0:
                result.notes = f"è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶ (è¿­ä»£{iteration})"
                bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
                continue
        except:
            result.notes = f"æ£€æŸ¥è¯æ®å›¾å¤±è´¥ (è¿­ä»£{iteration})"
            bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
            continue

        # === é¢å¤–éªŒè¯ï¼šæ£€æŸ¥è¯æ®å›¾æ˜¯å¦èƒ½è¢«æ­£ç¡®æ‰“å¼€ ===
        try:
            evidence_img = Image.open(config.TEMP_EVIDENCE_PATH)
            evidence_img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
            evidence_img.close()
        except Exception as e:
            result.notes = f"è¯æ®å›¾æŸåæˆ–æ ¼å¼é”™è¯¯: {e}"
            # åˆ é™¤æŸåçš„æ–‡ä»¶
            try:
                os.remove(config.TEMP_EVIDENCE_PATH)
            except:
                pass

            # å°è¯•å›é€€
            bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
            continue

        # è¯»å–è¯æ®å›¾ç”¨äºåç»­å¤„ç†
        try:
            with open(config.TEMP_EVIDENCE_PATH, "rb") as f:
                evidence_bytes = f.read()
        except Exception as e:
            result.notes = f"è¯»å–è¯æ®å›¾å¤±è´¥: {e}"
            bbox_str = get_fallback_bbox(bbox_str, img_w, img_h, iteration)
            continue

        # QwenåŸºäºè¯æ®å›¾é‡æ–°å›ç­”
        prompt2 = f"åªçœ‹è¿™å¼ è£å‰ªåçš„å›¾åƒï¼Œå›ç­”ï¼š{sample['question']}"
        refined_answer = call_qwen(prompt2, config.TEMP_EVIDENCE_PATH, config)
        result.qwen_calls += 1

        if not refined_answer:
            result.notes = f"Qwené‡ç­”å¤±è´¥ (è¿­ä»£{iteration})"
            # Qwené‡ç­”å¤±è´¥æ—¶ï¼Œå¦‚æœè¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼Œå°è¯•å…¨å›¾
            if retry < config.MAX_RETRIES:
                bbox_str = f"0,0,{img_w},{img_h}"
                continue
            else:
                break

        print(f"ğŸ“¥ Qwenç²¾ç‚¼å›ç­”: {refined_answer}")

        # CLIPéªŒè¯
        confidence = call_clip(evidence_bytes, refined_answer, config)
        result.clip_calls += 1
        result.clip_scores[f"iteration_{iteration}"] = float(confidence)

        print(f"ğŸ¯ CLIPç½®ä¿¡åº¦: {confidence:.3f} (é˜ˆå€¼: {config.CONFIDENCE_THRESHOLD})")

        if confidence >= config.CONFIDENCE_THRESHOLD:
            result.refined_answer = refined_answer
            result.final_confidence = float(confidence)
            print(f"âœ… éªŒè¯é€šè¿‡!")
            break
        elif retry < config.MAX_RETRIES:
            # éªŒè¯å¤±è´¥ï¼Œå¦‚æœè¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼Œå°è¯•å…¨å›¾
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾...")
            bbox_str = f"0,0,{img_w},{img_h}"
        else:
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

    result.iteration_count = iteration
    result.total_time = time.time() - start_time

    # å¦‚æœç²¾ç‚¼ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨åˆå§‹ç­”æ¡ˆ
    if not result.refined_answer and result.initial_answer:
        result.refined_answer = result.initial_answer
        # å¦‚æœæ²¡æœ‰CLIPéªŒè¯ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
        if result.final_confidence == 0.0:
            result.final_confidence = 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦

    # è¯„ä¼°å‡†ç¡®æ€§
    answer_to_evaluate = result.refined_answer if result.refined_answer else result.initial_answer
    result.accuracy, result.is_correct = calculate_accuracy(
        answer_to_evaluate,
        sample['answers']
    )

    # åˆ†æå¤±è´¥ç±»å‹
    if not result.is_correct:
        result.failure_type = analyze_failure_type(result, config)
        print(f"âŒ ç­”æ¡ˆé”™è¯¯ï¼Œå¤±è´¥ç±»å‹: {result.failure_type}")
    else:
        print(f"âœ… ç­”æ¡ˆæ­£ç¡®!")

    print(f"â±ï¸ å¤„ç†æ—¶é—´: {result.total_time:.2f}ç§’")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iteration_count}")

    return result

def save_sam_segment(segment_data: bytes, original_image_path: str,
                     bbox_str: str, iteration: int, config: Config):
    """ä¿å­˜SAMåˆ†å‰²çš„å›¾åƒ"""
    # åˆ›å»ºç›®å½•
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    base_name = os.path.splitext(os.path.basename(original_image_path))[0]
    if iteration == 1:
        suffix = "initial"
    elif iteration == 2:
        suffix = "full"
    else:
        suffix = f"retry{iteration}"

    # ç®€åŒ–bboxå­—ç¬¦ä¸²ç”¨äºæ–‡ä»¶åï¼ˆç§»é™¤é€—å·ï¼‰
    bbox_simple = bbox_str.replace(',', '_')

    # å®Œæ•´çš„æ–‡ä»¶å
    filename = f"{base_name}_{suffix}_{bbox_simple}.png"
    filepath = os.path.join(config.SAM_SEGMENTS_DIR, filename)

    # ä¿å­˜æ–‡ä»¶
    with open(filepath, "wb") as f:
        f.write(segment_data)

    return filepath


# ==================== å®éªŒç®¡ç† ====================
class ExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.results: List[ExperimentResult] = []
        self.stats = SystemStatistics()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹DocVQAå®éªŒ...")

        # åŠ è½½æ•°æ®
        samples = load_docvqa_dataset_for_experiment(self.config)
        self.stats.total_samples = len(samples)

        if self.stats.total_samples == 0:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ ·æœ¬ï¼Œå®éªŒç»ˆæ­¢")
            return

        # é€ä¸ªè¿è¡Œå®éªŒ
        for i, sample in enumerate(tqdm(samples, desc="è¿›è¡Œå®éªŒ")):
            print(f"\n{'=' * 60}")
            print(f"æ ·æœ¬ {i + 1}/{len(samples)}: {sample['question']}")
            print(f"å›¾åƒ: {sample['image_file']}")
            print(f"å‚è€ƒç­”æ¡ˆ: {sample['answers'][:3]}")  # æ˜¾ç¤ºå‰3ä¸ªå‚è€ƒç­”æ¡ˆ

            result = run_single_experiment(sample, self.config)
            self.results.append(result)

            # æ›´æ–°ç»Ÿè®¡
            self.stats.correct_samples += 1 if result.is_correct else 0
            self.stats.total_iterations += result.iteration_count
            self.stats.total_sam_calls += result.sam_calls
            self.stats.total_clip_calls += result.clip_calls
            self.stats.total_qwen_calls += result.qwen_calls
            self.stats.total_time += result.total_time

            if result.failure_type:
                self.stats.failure_counts[result.failure_type] += 1

            # æ¯5ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡è¿›åº¦
            if (i + 1) % 5 == 0:
                self.save_results()
                print(f"\nğŸ’¾ å·²ä¿å­˜{len(self.results)}ä¸ªæ ·æœ¬çš„ç»“æœ")

        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_results()
        self.generate_report()
        print("\nâœ… å®éªŒå®Œæˆ!")

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # è½¬æ¢ç»“æœä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        results_list = []
        for r in self.results:
            result_dict = {
                'id': int(r.sample_id),
                'question': str(r.question),
                'image_file': str(r.image_file),
                'ground_truth': [str(ans) for ans in r.ground_truth_answers],
                'initial_answer': str(r.initial_answer),
                'initial_bbox': str(r.initial_bbox),
                'refined_answer': str(r.refined_answer),
                'confidence': float(r.final_confidence),
                'clip_scores': {k: float(v) for k, v in r.clip_scores.items()},
                'is_correct': bool(r.is_correct),
                'accuracy': float(r.accuracy),
                'failure_type': str(r.failure_type),
                'iteration_count': int(r.iteration_count),
                'sam_calls': int(r.sam_calls),
                'clip_calls': int(r.clip_calls),
                'qwen_calls': int(r.qwen_calls),
                'time': float(r.total_time),
                'notes': str(r.notes)
            }
            results_list.append(result_dict)

        results_dict = {
            'config': {
                'max_retries': int(self.config.MAX_RETRIES),
                'confidence_threshold': float(self.config.CONFIDENCE_THRESHOLD),
                'num_samples': int(self.config.NUM_SAMPLES),
                'random_seed': int(self.config.RANDOM_SEED)
            },
            'statistics': {
                'total_samples': int(self.stats.total_samples),
                'correct_samples': int(self.stats.correct_samples),
                'accuracy': float(self.stats.accuracy),
                'total_iterations': int(self.stats.total_iterations),
                'avg_iterations': float(self.stats.avg_iterations),
                'total_sam_calls': int(self.stats.total_sam_calls),
                'total_clip_calls': int(self.stats.total_clip_calls),
                'total_qwen_calls': int(self.stats.total_qwen_calls),
                'total_time': float(self.stats.total_time),
                'avg_time_per_sample': float(self.stats.avg_time_per_sample),
                'failure_counts': {k: int(v) for k, v in self.stats.failure_counts.items()}
            },
            'results': results_list
        }

        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        with open(self.config.RESULTS_JSON, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2, default=str)

        # ä¿å­˜CSVæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        with open(self.config.STATS_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ ·æœ¬ID', 'é—®é¢˜', 'å›¾åƒ', 'å‚è€ƒç­”æ¡ˆ',
                'åˆå§‹ç­”æ¡ˆ', 'ç²¾ç‚¼ç­”æ¡ˆ', 'ç½®ä¿¡åº¦',
                'æ˜¯å¦æ­£ç¡®', 'å‡†ç¡®ç‡', 'å¤±è´¥ç±»å‹',
                'è¿­ä»£æ¬¡æ•°', 'SAMè°ƒç”¨', 'CLIPè°ƒç”¨', 'Qwenè°ƒç”¨',
                'æ—¶é—´(s)', 'å¤‡æ³¨'
            ])

            for r in self.results:
                writer.writerow([
                    int(r.sample_id),
                    str(r.question)[:80],  # é’ˆå¯¹DocVQAé—®é¢˜å¯èƒ½è¾ƒé•¿ï¼Œå¢åŠ æˆªæ–­é•¿åº¦
                    str(r.image_file),
                    '; '.join([str(ans) for ans in r.ground_truth_answers[:3]]),
                    str(r.initial_answer)[:50],
                    str(r.refined_answer)[:50],
                    f"{float(r.final_confidence):.3f}",
                    "æ˜¯" if r.is_correct else "å¦",
                    f"{float(r.accuracy):.3f}",
                    str(r.failure_type),
                    int(r.iteration_count),
                    int(r.sam_calls),
                    int(r.clip_calls),
                    int(r.qwen_calls),
                    f"{float(r.total_time):.2f}",
                    str(r.notes)[:50]
                ])

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {self.config.OUTPUT_DIR}")

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report = f"""
# å¯éªŒè¯è§†è§‰é—®ç­”é—­ç¯ç³»ç»Ÿå®éªŒæŠ¥å‘Š - DocVQAæ•°æ®é›†

## 1. å®éªŒæ¦‚è¿°
- æ•°æ®é›†ï¼šDocVQAï¼ˆ{self.stats.total_samples}ä¸ªæ ·æœ¬ï¼‰
- é—­ç¯é…ç½®ï¼šæœ€å¤§è¿­ä»£{self.config.MAX_RETRIES}æ¬¡ï¼Œç½®ä¿¡åº¦é˜ˆå€¼{self.config.CONFIDENCE_THRESHOLD}
- éšæœºç§å­ï¼š{self.config.RANDOM_SEED}

## 2. ä¸»è¦ç»“æœ
- **æ€»ä½“å‡†ç¡®ç‡**ï¼š{self.stats.accuracy:.2%} ({self.stats.correct_samples}/{self.stats.total_samples})
- **å¹³å‡è¿­ä»£æ¬¡æ•°**ï¼š{self.stats.avg_iterations:.2f}
- **å¹³å‡å¤„ç†æ—¶é—´**ï¼š{self.stats.avg_time_per_sample:.2f}ç§’/æ ·æœ¬
- **æ€»å®éªŒæ—¶é—´**ï¼š{self.stats.total_time:.2f}ç§’

## 3. å·¥å…·è°ƒç”¨ç»Ÿè®¡
- SAMè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_sam_calls}
- CLIPè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_clip_calls}
- Qwenè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_qwen_calls}

## 4. å¤±è´¥åˆ†æ
"""

        total_failures = sum(self.stats.failure_counts.values())
        for failure_type, count in self.stats.failure_counts.items():
            if count > 0:
                percentage = count / total_failures * 100 if total_failures > 0 else 0
                report += f"- **{failure_type}**: {count}æ¬¡ ({percentage:.1f}%)\n"

        report += """
## 5. DocVQAæ•°æ®é›†ç‰¹ç‚¹åˆ†æ
1. **æ–‡æ¡£ç±»å‹å¤šæ ·**ï¼šåŒ…å«è¡¨æ ¼ã€å›¾è¡¨ã€ç¥¨æ®ã€æ–‡æ¡£ç­‰
2. **æ–‡æœ¬å¯†é›†**ï¼šéœ€è¦ç²¾ç¡®çš„OCRèƒ½åŠ›
3. **æ•°å€¼é—®é¢˜å¤š**ï¼šå¾ˆå¤šé—®é¢˜æ¶‰åŠæ•°å­—å’Œè®¡ç®—
4. **ç»“æ„ç†è§£é‡è¦**ï¼šéœ€è¦ç†è§£è¡¨æ ¼ç»“æ„å’Œæ–‡æ¡£å¸ƒå±€

## 6. å…³é”®å‘ç°
1. **å®šä½æŒ‘æˆ˜**ï¼šæ–‡æ¡£å›¾åƒä¸­çš„æ–‡æœ¬åŒºåŸŸå®šä½æ¯”è‡ªç„¶å›¾åƒæ›´å…·æŒ‘æˆ˜æ€§
2. **OCRå‡†ç¡®æ€§**ï¼šQwençš„OCRèƒ½åŠ›å¯¹æ–‡æ¡£å›¾åƒå‡†ç¡®ç‡å½±å“å¤§
3. **æ•°å€¼éªŒè¯**ï¼šCLIPå¯¹æ•°å€¼ç±»ç­”æ¡ˆçš„éªŒè¯æ•ˆæœéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°
4. **è¯æ®è´¨é‡**ï¼šæ–‡æ¡£åˆ†å‰²éœ€è¦æ›´ç²¾ç¡®çš„è¾¹ç•Œæ¡†

## 7. æ”¹è¿›å»ºè®®
1. **é¢„å¤„ç†ä¼˜åŒ–**ï¼šå¯¹æ–‡æ¡£å›¾åƒè¿›è¡Œå¢å¼ºé¢„å¤„ç†ï¼ˆå»å™ªã€äºŒå€¼åŒ–ç­‰ï¼‰
2. **åæ ‡æå–æ”¹è¿›**ï¼šé’ˆå¯¹æ–‡æ¡£åæ ‡æ ¼å¼ä¼˜åŒ–æ­£åˆ™è¡¨è¾¾å¼
3. **å¤šå°ºåº¦éªŒè¯**ï¼šå°è¯•ä¸åŒå°ºåº¦çš„è¯æ®å›¾è¿›è¡ŒéªŒè¯
4. **åå¤„ç†è§„åˆ™**ï¼šé’ˆå¯¹æ•°å€¼ç­”æ¡ˆæ·»åŠ åå¤„ç†è§„åˆ™

## 8. æ ·æœ¬ç¤ºä¾‹
"""

        # æ·»åŠ 3ä¸ªç¤ºä¾‹ç»“æœ
        for i, r in enumerate(self.results[:3]):
            report += f"""
### ç¤ºä¾‹ {i + 1}
- **é—®é¢˜**: {r.question}
- **åˆå§‹ç­”æ¡ˆ**: {r.initial_answer}
- **ç²¾ç‚¼ç­”æ¡ˆ**: {r.refined_answer}
- **ç½®ä¿¡åº¦**: {r.final_confidence:.3f}
- **æ˜¯å¦æ­£ç¡®**: {'æ˜¯' if r.is_correct else 'å¦'}
- **å¤„ç†æ—¶é—´**: {r.total_time:.2f}ç§’
- **å¤±è´¥ç±»å‹**: {r.failure_type if r.failure_type else 'N/A'}
"""

        report_path = os.path.join(self.config.OUTPUT_DIR, "experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")


def validate_bbox(x1: int, y1: int, x2: int, y2: int, img_w: int, img_h: int, min_size=20) -> Tuple[int, int, int, int]:
    """éªŒè¯å¹¶ä¿®æ­£bboxåæ ‡ï¼Œç¡®ä¿å…¶æœ‰æ•ˆ"""
    # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡®
    x1, x2 = sorted([x1, x2])
    y1, y2 = sorted([y1, y2])

    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(img_w, x2), min(img_h, y2)

    # ç¡®ä¿bboxæœ‰æœ€å°å°ºå¯¸
    if (x2 - x1) < min_size:
        # æ‰©å¤§å®½åº¦ï¼Œä¿æŒä¸­å¿ƒä¸å˜
        center_x = (x1 + x2) // 2
        x1 = max(0, center_x - min_size // 2)
        x2 = min(img_w, center_x + min_size // 2)
        if (x2 - x1) < min_size:  # å¦‚æœè¿˜åœ¨è¾¹ç•Œå¤„ä¸å¤Ÿ
            x2 = min(img_w, x1 + min_size)

    if (y2 - y1) < min_size:
        # æ‰©å¤§é«˜åº¦ï¼Œä¿æŒä¸­å¿ƒä¸å˜
        center_y = (y1 + y2) // 2
        y1 = max(0, center_y - min_size // 2)
        y2 = min(img_h, center_y + min_size // 2)
        if (y2 - y1) < min_size:  # å¦‚æœè¿˜åœ¨è¾¹ç•Œå¤„ä¸å¤Ÿ
            y2 = min(img_h, y1 + min_size)

    return x1, y1, x2, y2


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡ï¼Œå¹¶éªŒè¯ä¿®æ­£"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            # éªŒè¯å¹¶ä¿®æ­£bbox
            x1, y1, x2, y2 = validate_bbox(x1, y1, x2, y2, img_w, img_h)
            return f"{x1},{y1},{x2},{y2}"

    # æœªæ‰¾åˆ°åæ ‡ï¼Œè¿”å›å…¨å›¾
    return f"0,0,{img_w},{img_h}"



# ==================== ä¸»ç¨‹åº ====================
def main():
    # åˆå§‹åŒ–é…ç½®
    config = Config()

    # ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•éƒ½å­˜åœ¨
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # è¿è¡Œä¸»å®éªŒ
    print("=" * 60)
    print("ğŸ“ è®¡ç®—æœºè§†è§‰ç»“è¯¾è®ºæ–‡å®éªŒç³»ç»Ÿ - DocVQAæ•°æ®é›†")
    print("=" * 60)

    manager = ExperimentManager(config)
    manager.run_experiments()

    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {config.OUTPUT_DIR}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {config.RESULTS_JSON}")
    print(f"ğŸ“Š ç»Ÿè®¡è¡¨æ ¼: {config.STATS_CSV}")
    print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {config.OUTPUT_DIR}/experiment_report.md")


if __name__ == "__main__":
    main()