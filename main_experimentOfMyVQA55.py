'''
å¯¹æ¯”è¯•éªŒ
6.åˆé‡æ–°è®¾è®¡äº†åŠ é€Ÿç­–ç•¥
ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿç­–ç•¥
'''

import os
import json
import time
import csv
import numpy as np
from PIL import Image
import requests
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple, Any, Optional
from tqdm import tqdm
import re
import base64
from io import BytesIO
import hashlib
import pickle
from concurrent.futures import ThreadPoolExecutor, as_completed


# ==================== é…ç½® ====================
@dataclass
class Config:
    # æœåŠ¡å™¨é…ç½®
    SERVER_IP = "è¿™æ˜¯æˆ‘çš„æœåŠ¡å™¨IPåœ°å€ï¼Œæˆ‘éšè—äº†"
    QWEN_URL = f"http://{SERVER_IP}:8020/chat_vl"
    CLIP_URL = f"http://{SERVER_IP}:8021/clip/score"
    SAM_URL = f"http://{SERVER_IP}:8022/segment_by_bbox"

    # æ•°æ®é›†è·¯å¾„
    DATA_ROOT = r"C:\Users\kuanzhang\Desktop\courseB\fuwuqisanhaoji\MyVQA\combined_dataset"
    METADATA_PATH = os.path.join(DATA_ROOT, "combined_metadata.json")
    IMAGE_DIR = os.path.join(DATA_ROOT, "images")

    # å®éªŒå‚æ•°
    MAX_RETRIES = 2
    CONFIDENCE_THRESHOLD = 0.2
    TEMP_EVIDENCE_PATH = "./temp_evidence.png"

    # æ‰¹é‡å¤„ç†é…ç½®
    ENABLE_BATCH_PROCESSING = True  # æ˜¯å¦å¯ç”¨æ‰¹é‡å¤„ç†
    BATCH_SIZE = 2  # æ‰¹é‡å¤§å°
    MAX_WORKERS = 2  # æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°

    # è¾“å‡ºè·¯å¾„
    OUTPUT_DIR = "./results_with_batch"
    RESULTS_JSON = os.path.join(OUTPUT_DIR, "results_with_batch.json")
    STATS_CSV = os.path.join(OUTPUT_DIR, "statistics_with_batch.csv")
    SAM_SEGMENTS_DIR = os.path.join(OUTPUT_DIR, "sam_segments")
    PERFORMANCE_REPORT = os.path.join(OUTPUT_DIR, "batch_performance_report.json")

    # å®éªŒè®¾ç½®
    NUM_SAMPLES = 110
    RANDOM_SEED = 42


# ==================== æ‰¹é‡å¤„ç†å™¨ ====================
class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨ - ä¸»è¦ä¼˜åŒ–ç½‘ç»œè¯·æ±‚"""

    def __init__(self, config: Config):
        self.config = config
        self.stats = {
            "total_batches_processed": 0,
            "total_samples_processed": 0,
            "total_qwen_batch_calls": 0,
            "total_clip_batch_calls": 0,
            "total_sequential_time": 0.0,
            "total_batch_time": 0.0,
            "batch_size_distribution": {},
            "qwen_batch_times": [],
            "clip_batch_times": []
        }

        print(f"ğŸ”„ åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨ï¼Œæ‰¹é‡å¤§å°: {config.BATCH_SIZE}ï¼Œæœ€å¤§çº¿ç¨‹æ•°: {config.MAX_WORKERS}")

    def batch_call_qwen(self, prompts_with_images: List[Tuple[str, str]]) -> List[str]:
        """æ‰¹é‡è°ƒç”¨Qwen-VLæœåŠ¡"""
        if not self.config.ENABLE_BATCH_PROCESSING or len(prompts_with_images) <= 1:
            return self._sequential_call_qwen(prompts_with_images)

        batch_size = len(prompts_with_images)
        print(f"ğŸ”„ æ‰¹é‡å¤„ç† {batch_size} ä¸ªQwenè¯·æ±‚")
        start_time = time.time()

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_qwen_batch_calls"] += 1
        if batch_size not in self.stats["batch_size_distribution"]:
            self.stats["batch_size_distribution"][batch_size] = 0
        self.stats["batch_size_distribution"][batch_size] += 1

        results = [""] * batch_size

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=min(self.config.MAX_WORKERS, batch_size)) as executor:
            future_to_index = {}

            for i, (prompt, image_path) in enumerate(prompts_with_images):
                future = executor.submit(self._single_qwen_call, prompt, image_path)
                future_to_index[future] = i

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                idx = future_to_index[future]
                try:
                    results[idx] = future.result()
                except Exception as e:
                    print(f"âŒ Qwenæ‰¹é‡è°ƒç”¨å¤±è´¥ (ç´¢å¼•{idx}): {e}")
                    results[idx] = ""

        batch_time = time.time() - start_time
        self.stats["qwen_batch_times"].append(batch_time)

        # è®¡ç®—å¹¶æ˜¾ç¤ºåŠ é€Ÿæ•ˆæœ
        estimated_sequential_time = batch_size * 2.0  # å‡è®¾æ¯ä¸ªQwenè°ƒç”¨2ç§’
        speedup = estimated_sequential_time / batch_time if batch_time > 0 else 1

        print(f"âœ… æ‰¹é‡Qwenå¤„ç†å®Œæˆï¼Œè€—æ—¶: {batch_time:.2f}ç§’")
        print(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x (é¢„ä¼°é¡ºåºæ—¶é—´: {estimated_sequential_time:.2f}ç§’)")

        return results

    def batch_call_clip(self, image_text_pairs: List[Tuple[bytes, str]]) -> List[float]:
        """æ‰¹é‡è°ƒç”¨CLIPæœåŠ¡"""
        if not self.config.ENABLE_BATCH_PROCESSING or len(image_text_pairs) <= 1:
            return self._sequential_call_clip(image_text_pairs)

        batch_size = len(image_text_pairs)
        print(f"ğŸ”„ æ‰¹é‡å¤„ç† {batch_size} ä¸ªCLIPè¯·æ±‚")
        start_time = time.time()

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_clip_batch_calls"] += 1
        if batch_size not in self.stats["batch_size_distribution"]:
            self.stats["batch_size_distribution"][batch_size] = 0
        self.stats["batch_size_distribution"][batch_size] += 1

        scores = [0.0] * batch_size

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=min(self.config.MAX_WORKERS, batch_size)) as executor:
            future_to_index = {}

            for i, (image_bytes, text) in enumerate(image_text_pairs):
                future = executor.submit(self._single_clip_call, image_bytes, text)
                future_to_index[future] = i

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                idx = future_to_index[future]
                try:
                    scores[idx] = future.result()
                except Exception as e:
                    print(f"âŒ CLIPæ‰¹é‡è°ƒç”¨å¤±è´¥ (ç´¢å¼•{idx}): {e}")
                    scores[idx] = 0.0

        batch_time = time.time() - start_time
        self.stats["clip_batch_times"].append(batch_time)

        # è®¡ç®—å¹¶æ˜¾ç¤ºåŠ é€Ÿæ•ˆæœ
        estimated_sequential_time = batch_size * 0.5  # å‡è®¾æ¯ä¸ªCLIPè°ƒç”¨0.5ç§’
        speedup = estimated_sequential_time / batch_time if batch_time > 0 else 1

        print(f"âœ… æ‰¹é‡CLIPå¤„ç†å®Œæˆï¼Œè€—æ—¶: {batch_time:.2f}ç§’")
        print(f"âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x (é¢„ä¼°é¡ºåºæ—¶é—´: {estimated_sequential_time:.2f}ç§’)")

        return scores

    def _single_qwen_call(self, prompt: str, image_path: str) -> str:
        """å•ä¸ªQwenè°ƒç”¨"""
        try:
            # å‡†å¤‡å›¾åƒæ•°æ®
            image_data = ""
            if image_path and os.path.exists(image_path):
                try:
                    img = Image.open(image_path)
                    if img.mode in ("RGBA", "P"):
                        img = img.convert("RGB")
                    img.thumbnail((512, 512))
                    buffered = BytesIO()
                    img.save(buffered, format="JPEG", quality=85)
                    image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒå¤„ç†å¤±è´¥: {e}")

            # å‘é€è¯·æ±‚
            payload = {"prompt": prompt}
            if image_data:
                payload["image_url"] = image_data

            response = requests.post(self.config.QWEN_URL, json=payload, timeout=30)

            if response.status_code == 200:
                res = response.json()
                return res.get("response", "").strip()
            else:
                print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: HTTP {response.status_code}")
                return ""
        except Exception as e:
            print(f"ğŸ’¥ Qwenè°ƒç”¨å¼‚å¸¸: {e}")
            return ""

    def _single_clip_call(self, image_bytes: bytes, text: str) -> float:
        """å•ä¸ªCLIPè°ƒç”¨"""
        try:
            files = {'imagefile': ('evidence.png', image_bytes, 'image/png')}
            data = {'text': text, 'temperature': 100.0}

            response = requests.post(self.config.CLIP_URL, files=files, data=data, timeout=10)
            if response.status_code == 200:
                res = response.json()
                if res.get('results'):
                    similarities = [v['similarity'] for v in res['results'].values()]
                    return float(max(similarities)) if similarities else 0.0
                else:
                    return 0.0  # æ·»åŠ è¿™ä¸ªè¿”å›è¯­å¥
            else:
                print(f"âŒ CLIPè°ƒç”¨å¤±è´¥: HTTP {response.status_code}")
                return 0.0
        except Exception as e:
            print(f"ğŸ’¥ CLIPè°ƒç”¨å¼‚å¸¸: {e}")
            return 0.0

    def _sequential_call_qwen(self, prompts_with_images: List[Tuple[str, str]]) -> List[str]:
        """é¡ºåºè°ƒç”¨Qwenï¼ˆç”¨äºå¯¹æ¯”ï¼‰"""
        results = []
        start_time = time.time()

        for prompt, image_path in prompts_with_images:
            results.append(self._single_qwen_call(prompt, image_path))

        seq_time = time.time() - start_time
        self.stats["total_sequential_time"] += seq_time

        return results

    def _sequential_call_clip(self, image_text_pairs: List[Tuple[bytes, str]]) -> List[float]:
        """é¡ºåºè°ƒç”¨CLIPï¼ˆç”¨äºå¯¹æ¯”ï¼‰"""
        scores = []
        start_time = time.time()

        for image_bytes, text in image_text_pairs:
            scores.append(self._single_clip_call(image_bytes, text))

        seq_time = time.time() - start_time
        self.stats["total_sequential_time"] += seq_time

        return scores

    def update_batch_time(self, batch_time: float):
        """æ›´æ–°æ‰¹é‡å¤„ç†æ—¶é—´ç»Ÿè®¡"""
        self.stats["total_batch_time"] += batch_time

    def update_sample_count(self, count: int):
        """æ›´æ–°æ ·æœ¬è®¡æ•°"""
        self.stats["total_samples_processed"] += count
        self.stats["total_batches_processed"] += 1

    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        avg_qwen_batch_time = np.mean(self.stats["qwen_batch_times"]) if self.stats["qwen_batch_times"] else 0
        avg_clip_batch_time = np.mean(self.stats["clip_batch_times"]) if self.stats["clip_batch_times"] else 0

        # è®¡ç®—æ€»ä½“åŠ é€Ÿæ¯”
        total_estimated_seq_time = self.stats["total_sequential_time"] + self.stats["total_batch_time"]
        if self.stats["total_batch_time"] > 0:
            overall_speedup = total_estimated_seq_time / self.stats["total_batch_time"]
        else:
            overall_speedup = 1.0

        stats = {
            "batch_config": {
                "batch_size": self.config.BATCH_SIZE,
                "max_workers": self.config.MAX_WORKERS,
                "enabled": self.config.ENABLE_BATCH_PROCESSING
            },
            "processing_stats": {
                "total_samples": self.stats["total_samples_processed"],
                "total_batches": self.stats["total_batches_processed"],
                "qwen_batch_calls": self.stats["total_qwen_batch_calls"],
                "clip_batch_calls": self.stats["total_clip_batch_calls"],
                "batch_size_distribution": self.stats["batch_size_distribution"],
                "estimated_sequential_time": self.stats["total_sequential_time"],
                "actual_batch_time": self.stats["total_batch_time"],
                "overall_speedup": overall_speedup
            },
            "timing_stats": {
                "avg_qwen_batch_time": avg_qwen_batch_time,
                "avg_clip_batch_time": avg_clip_batch_time,
                "qwen_batch_times_sample": self.stats["qwen_batch_times"][:5] if len(
                    self.stats["qwen_batch_times"]) > 5 else self.stats["qwen_batch_times"],
                "clip_batch_times_sample": self.stats["clip_batch_times"][:5] if len(
                    self.stats["clip_batch_times"]) > 5 else self.stats["clip_batch_times"]
            }
        }

        return stats

    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        stats = self.get_performance_stats()

        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡å¤„ç†æ€§èƒ½æŠ¥å‘Š")
        print("=" * 60)

        print(f"\nğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats['processing_stats']['total_samples']}")
        print(f"   æ€»æ‰¹æ¬¡æ•°: {stats['processing_stats']['total_batches']}")
        print(f"   Qwenæ‰¹é‡è°ƒç”¨: {stats['processing_stats']['qwen_batch_calls']}æ¬¡")
        print(f"   CLIPæ‰¹é‡è°ƒç”¨: {stats['processing_stats']['clip_batch_calls']}æ¬¡")

        print(f"\nâš¡ åŠ é€Ÿæ•ˆæœ:")
        print(f"   é¢„ä¼°é¡ºåºæ—¶é—´: {stats['processing_stats']['estimated_sequential_time']:.2f}ç§’")
        print(f"   å®é™…æ‰¹é‡æ—¶é—´: {stats['processing_stats']['actual_batch_time']:.2f}ç§’")
        print(f"   æ€»ä½“åŠ é€Ÿæ¯”: {stats['processing_stats']['overall_speedup']:.2f}x")

        if stats['processing_stats']['batch_size_distribution']:
            print(f"\nğŸ“¦ æ‰¹é‡å¤§å°åˆ†å¸ƒ:")
            for size, count in sorted(stats['processing_stats']['batch_size_distribution'].items()):
                print(f"   æ‰¹é‡å¤§å° {size}: {count}æ¬¡")

        print(f"\nâ±ï¸ å¹³å‡å¤„ç†æ—¶é—´:")
        print(f"   Qwenæ‰¹é‡: {stats['timing_stats']['avg_qwen_batch_time']:.2f}ç§’")
        print(f"   CLIPæ‰¹é‡: {stats['timing_stats']['avg_clip_batch_time']:.2f}ç§’")


# ==================== æ•°æ®ç»“æ„ ====================
@dataclass
class ExperimentResult:
    sample_id: int
    image_file: str
    question: str
    ground_truth_answers: List[str]

    # ç³»ç»Ÿè¾“å‡º
    initial_answer: str = ""
    initial_bbox: str = ""
    refined_answer: str = ""
    final_confidence: float = 0.0
    clip_scores: Dict[str, float] = None

    # æ€§èƒ½æŒ‡æ ‡
    iteration_count: int = 0
    sam_calls: int = 0
    clip_calls: int = 0
    qwen_calls: int = 0
    total_time: float = 0.0

    # æ‰¹é‡å¤„ç†ç›¸å…³æŒ‡æ ‡
    batch_processed: bool = False  # æ˜¯å¦ç»è¿‡æ‰¹é‡å¤„ç†
    batch_size: int = 1  # æ‰¹é‡å¤§å°

    # è¯„ä¼°
    accuracy: float = 0.0
    is_correct: bool = False
    failure_type: str = ""
    notes: str = ""

    def __post_init__(self):
        if self.clip_scores is None:
            self.clip_scores = {}


@dataclass
class SystemStatistics:
    total_samples: int = 0
    correct_samples: int = 0
    total_iterations: int = 0
    total_sam_calls: int = 0
    total_clip_calls: int = 0
    total_qwen_calls: int = 0
    total_time: float = 0.0

    # æ‰¹é‡å¤„ç†ç»Ÿè®¡
    batch_stats: Dict[str, Any] = None

    # æ€§èƒ½å¯¹æ¯”
    estimated_sequential_time: float = 0.0
    speedup_factor: float = 0.0
    throughput_batch: float = 0.0
    throughput_sequential: float = 0.0

    # æŒ‰å¤±è´¥ç±»å‹ç»Ÿè®¡
    failure_counts: Dict[str, int] = None

    def __post_init__(self):
        if self.failure_counts is None:
            self.failure_counts = {
                "location_failure": 0,
                "segmentation_failure": 0,
                "reasoning_failure": 0,
                "verification_failure": 0,
                "other": 0
            }
        if self.batch_stats is None:
            self.batch_stats = {}

    @property
    def accuracy(self) -> float:
        return self.correct_samples / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_iterations(self) -> float:
        return self.total_iterations / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_time_per_sample(self) -> float:
        return self.total_time / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_qwen_calls(self) -> float:
        return self.total_qwen_calls / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_sam_calls(self) -> float:
        return self.total_sam_calls / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_clip_calls(self) -> float:
        return self.total_clip_calls / self.total_samples if self.total_samples > 0 else 0


# ==================== å·¥å…·å‡½æ•° ====================
def load_textvqa_dataset(config: Config) -> List[Dict]:
    """åŠ è½½MyVQAæ•°æ®é›†"""
    with open(config.METADATA_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆç¡®ä¿å¯å¤ç°ï¼‰
    np.random.seed(config.RANDOM_SEED)
    selected_indices = np.random.choice(len(data), min(config.NUM_SAMPLES, len(data)), replace=False)

    samples = []
    for idx in selected_indices:
        sample = data[idx]
        sample['id'] = idx
        samples.append(sample)

    print(f"ğŸ“Š åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    return samples


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1, x2 = sorted([max(0, min(img_w, x)) for x in (x1, x2)])
            y1, y2 = sorted([max(0, min(img_h, y)) for y in (y1, y2)])
            return f"{x1},{y1},{x2},{y2}"

    # æœªæ‰¾åˆ°åæ ‡ï¼Œè¿”å›å…¨å›¾
    return f"0,0,{img_w},{img_h}"


def normalize_answer(answer: str) -> str:
    """æ ‡å‡†åŒ–ç­”æ¡ˆï¼šå°å†™ã€ç§»é™¤æ ‡ç‚¹ã€ç©ºæ ¼"""
    if not answer:
        return ""
    # è½¬æ¢ä¸ºå°å†™
    answer = answer.lower()
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    answer = re.sub(r'[^\w\s]', '', answer)
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    answer = ' '.join(answer.split())
    return answer


def calculate_accuracy(predicted_answer: str, ground_truths: List[str]) -> Tuple[float, bool]:
    """è®¡ç®—ç­”æ¡ˆå‡†ç¡®æ€§ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    if not predicted_answer:
        return 0.0, False

    pred_normalized = normalize_answer(predicted_answer)

    for truth in ground_truths:
        if not truth:
            continue

        truth_normalized = normalize_answer(truth)

        # ç²¾ç¡®åŒ¹é…
        if pred_normalized == truth_normalized:
            return 1.0, True

        # åŒ…å«åŒ¹é…ï¼ˆé’ˆå¯¹è¾ƒé•¿ç­”æ¡ˆï¼‰
        if truth_normalized in pred_normalized or pred_normalized in truth_normalized:
            return 1.0, True

        # æ•°å­—æå–åŒ¹é…ï¼ˆé’ˆå¯¹OCRé—®é¢˜ï¼‰
        pred_digits = ''.join(filter(str.isdigit, pred_normalized))
        truth_digits = ''.join(filter(str.isdigit, truth_normalized))
        if pred_digits and pred_digits == truth_digits:
            return 1.0, True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å“ç‰Œ/åç§°
        common_brands = ['yamaha', 'red', 'mike lee', 'aj52uyv']
        for brand in common_brands:
            if brand in pred_normalized and brand in truth_normalized:
                return 1.0, True

    return 0.0, False


def analyze_failure_type(result: ExperimentResult, config: Config) -> str:
    """åˆ†æå¤±è´¥ç±»å‹"""
    if result.final_confidence < config.CONFIDENCE_THRESHOLD:
        return "verification_failure"
    elif result.iteration_count == 0:
        return "location_failure"
    elif "æ— æ³•" in result.refined_answer or "ä¸èƒ½" in result.refined_answer:
        return "reasoning_failure"
    else:
        return "other"


def call_sam(image_path: str, bbox_str: str, config: Config,
             save_segment: bool = True, iteration: int = 1) -> Tuple[bool, bytes]:
    """è°ƒç”¨SAMæœåŠ¡"""
    try:
        with open(image_path, 'rb') as f:
            files = {'image': f}
            data = {'bbox': bbox_str}
            response = requests.post(config.SAM_URL, files=files, data=data, timeout=30)

            if response.status_code == 200:
                segment_data = response.content

                # æ£€æŸ¥åˆ†å‰²æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                if len(segment_data) == 0:
                    print(f"âš ï¸ SAMè¿”å›ç©ºæ•°æ®")
                    return False, None

                # å°è¯•éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„PNGå›¾åƒ
                try:
                    Image.open(BytesIO(segment_data))
                except Exception as e:
                    print(f"âš ï¸ SAMè¿”å›æ— æ•ˆå›¾åƒæ•°æ®: {e}")
                    return False, None

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ç”¨äºåç»­å¤„ç†
                with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                    out.write(segment_data)

                # å¦‚æœéœ€è¦ä¿å­˜åˆ†å‰²å›¾åƒ
                if save_segment:
                    segment_path = save_sam_segment(
                        segment_data, image_path, bbox_str, iteration, config
                    )
                    print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜: {segment_path}")

                return True, segment_data
            else:
                print(f"âŒ SAMè°ƒç”¨å¤±è´¥: HTTP {response.status_code}")
    except Exception as e:
        print(f"ğŸ’¥ SAMè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return False, None


def save_sam_segment(segment_data: bytes, original_image_path: str,
                     bbox_str: str, iteration: int, config: Config):
    """ä¿å­˜SAMåˆ†å‰²çš„å›¾åƒ"""
    # åˆ›å»ºç›®å½•
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    base_name = os.path.splitext(os.path.basename(original_image_path))[0]
    if iteration == 1:
        suffix = "initial"
    elif iteration == 2:
        suffix = "full"
    else:
        suffix = f"retry{iteration}"

    # ç®€åŒ–bboxå­—ç¬¦ä¸²ç”¨äºæ–‡ä»¶åï¼ˆç§»é™¤é€—å·ï¼‰
    bbox_simple = bbox_str.replace(',', '_')

    # å®Œæ•´çš„æ–‡ä»¶å
    filename = f"{base_name}_{suffix}_{bbox_simple}.png"
    filepath = os.path.join(config.SAM_SEGMENTS_DIR, filename)

    # ä¿å­˜æ–‡ä»¶
    with open(filepath, "wb") as f:
        f.write(segment_data)

    return filepath


# ==================== æ‰¹é‡å®éªŒæµç¨‹ ====================
def run_batch_experiment(samples: List[Dict], config: Config,
                         batch_processor: BatchProcessor) -> List[ExperimentResult]:
    """æ‰¹é‡è¿è¡Œå®éªŒ"""
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å®éªŒï¼Œæ ·æœ¬æ•°: {len(samples)}")

    all_results = []

    # æŒ‰æ‰¹æ¬¡å¤„ç†
    for batch_start in range(0, len(samples), config.BATCH_SIZE):
        batch_end = min(batch_start + config.BATCH_SIZE, len(samples))
        batch_samples = samples[batch_start:batch_end]
        actual_batch_size = len(batch_samples)

        print(f"\n{'=' * 60}")
        print(
            f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_start // config.BATCH_SIZE + 1}: æ ·æœ¬ {batch_start + 1}-{batch_end} (æ‰¹é‡å¤§å°: {actual_batch_size})")

        batch_start_time = time.time()

        # é˜¶æ®µ1: æ‰¹é‡è·å–åˆå§‹ç­”æ¡ˆ
        print("ğŸ“¤ æ‰¹é‡å‘é€Qwenåˆå§‹è¯·æ±‚...")
        prompts_with_images = []
        for sample in batch_samples:
            prompt = f"é—®é¢˜ï¼š{sample['question']} è¯·å…ˆç»™å‡ºç­”æ¡ˆï¼›å†ä»¥æ ¼å¼(å·¦ä¸Šè§’xåæ ‡,å·¦ä¸Šè§’yåæ ‡) (å³ä¸‹è§’xåæ ‡,å³ä¸‹è§’yåæ ‡) ä¸¤ç‚¹ç”Ÿæˆçš„çŸ©å½¢æ¡†å°†å›¾ç‰‡éœ€è¦å…³æ³¨åŒºåŸŸåŒ…å›´è¿›å»ã€‚"
            image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])
            prompts_with_images.append((prompt, image_path))

        # æ‰¹é‡è°ƒç”¨Qwen
        initial_responses = batch_processor.batch_call_qwen(prompts_with_images)

        # é˜¶æ®µ2: å¤„ç†æ¯ä¸ªæ ·æœ¬çš„è¿­ä»£éªŒè¯
        batch_results = []
        for idx, sample in enumerate(batch_samples):
            print(f"\n  å¤„ç†æ ·æœ¬ {batch_start + idx + 1}/{len(samples)}: {sample['question'][:50]}...")

            result = process_single_sample(
                sample,
                initial_responses[idx],
                config,
                batch_processor,
                batch_size=actual_batch_size
            )
            batch_results.append(result)

        batch_time = time.time() - batch_start_time
        batch_processor.update_batch_time(batch_time)
        batch_processor.update_sample_count(actual_batch_size)

        print(f"âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {batch_time:.2f}ç§’")

        all_results.extend(batch_results)

    return all_results


def process_single_sample(sample: Dict, initial_response: str,
                          config: Config, batch_processor: BatchProcessor,
                          batch_size: int = 1) -> ExperimentResult:
    """å¤„ç†å•ä¸ªæ ·æœ¬ï¼ˆå¯é›†æˆåˆ°æ‰¹é‡å¤„ç†ä¸­ï¼‰"""
    result = ExperimentResult(
        sample_id=sample['id'],
        image_file=sample['image_file'],
        question=sample['question'],
        ground_truth_answers=sample['answers'],
        batch_processed=config.ENABLE_BATCH_PROCESSING,
        batch_size=batch_size
    )

    start_time = time.time()
    image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])

    # è·å–å›¾åƒå°ºå¯¸
    try:
        with Image.open(image_path) as img:
            img_w, img_h = img.size
    except Exception as e:
        result.notes = f"æ— æ³•æ‰“å¼€å›¾åƒ: {e}"
        result.total_time = time.time() - start_time
        return result

    # è®°å½•åˆå§‹å›ç­”
    result.initial_answer = initial_response
    result.initial_bbox = extract_bbox_from_text(initial_response, img_w, img_h)
    result.qwen_calls += 1

    print(f"ğŸ“ æå–çš„BBox: {result.initial_bbox}")

    # é—­ç¯éªŒè¯å¾ªç¯
    bbox_str = result.initial_bbox
    refined_answer = ""
    confidence = 0.0
    iteration = 0

    for retry in range(config.MAX_RETRIES + 1):
        iteration += 1
        print(f"ğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£å°è¯•...")

        # è°ƒç”¨SAMåˆ†å‰²
        success, segment_data = call_sam(image_path, bbox_str, config,
                                         save_segment=True, iteration=iteration)
        if not success:
            result.notes = f"SAMåˆ†å‰²å¤±è´¥ (è¿­ä»£{iteration})"
            break

        result.sam_calls += 1

        # æ£€æŸ¥è¯æ®å›¾æ˜¯å¦å­˜åœ¨
        if not os.path.exists(config.TEMP_EVIDENCE_PATH):
            result.notes = f"è¯æ®å›¾æœªç”Ÿæˆ (è¿­ä»£{iteration})"
            break

        # è¯»å–è¯æ®å›¾
        try:
            evidence_size = os.path.getsize(config.TEMP_EVIDENCE_PATH)
            if evidence_size == 0:
                result.notes = f"è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶ (è¿­ä»£{iteration})"
                break

            with open(config.TEMP_EVIDENCE_PATH, "rb") as f:
                evidence_bytes = f.read()
        except Exception as e:
            result.notes = f"è¯»å–è¯æ®å›¾å¤±è´¥: {e}"
            break

        # QwenåŸºäºè¯æ®å›¾é‡æ–°å›ç­”
        prompt2 = f"åªçœ‹è¿™å¼ è£å‰ªåçš„å›¾åƒï¼Œå›ç­”ï¼š{sample['question']}"

        # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œä»ç„¶ä½¿ç”¨å•ä¸ªè°ƒç”¨
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œå¯ä»¥å°†å¤šä¸ªæ ·æœ¬çš„prompt2æ”¶é›†èµ·æ¥æ‰¹é‡è°ƒç”¨
        refined_answer = batch_processor._single_qwen_call(prompt2, config.TEMP_EVIDENCE_PATH)
        result.qwen_calls += 1

        if not refined_answer:
            result.notes = f"Qwené‡ç­”å¤±è´¥ (è¿­ä»£{iteration})"
            break

        print(f"ğŸ“¥ Qwenç²¾ç‚¼å›ç­”: {refined_answer}")

        # CLIPéªŒè¯
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œå¯ä»¥å°†å¤šä¸ªæ ·æœ¬çš„CLIPéªŒè¯æ”¶é›†èµ·æ¥æ‰¹é‡è°ƒç”¨
        confidence = batch_processor._single_clip_call(evidence_bytes, refined_answer)
        result.clip_calls += 1

        # ç¡®ä¿confidenceæ˜¯æµ®ç‚¹æ•°
        if confidence is None:
            confidence = 0.0
        result.clip_scores[f"iteration_{iteration}"] = float(confidence)

        print(f"ğŸ¯ CLIPç½®ä¿¡åº¦: {confidence:.3f} (é˜ˆå€¼: {config.CONFIDENCE_THRESHOLD})")

        if confidence >= config.CONFIDENCE_THRESHOLD:
            result.refined_answer = refined_answer
            result.final_confidence = float(confidence)
            print(f"âœ… éªŒè¯é€šè¿‡!")
            break
        elif retry == 0:
            # ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾
            print("âš ï¸ ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾...")
            bbox_str = f"0,0,{img_w},{img_h}"
        else:
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥")

    result.iteration_count = iteration
    result.total_time = time.time() - start_time

    # å¦‚æœç²¾ç‚¼ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨åˆå§‹ç­”æ¡ˆ
    if not result.refined_answer and result.initial_answer:
        result.refined_answer = result.initial_answer
        # å¦‚æœæ²¡æœ‰CLIPéªŒè¯ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
        if result.final_confidence == 0.0:
            result.final_confidence = 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦

    # è¯„ä¼°å‡†ç¡®æ€§
    answer_to_evaluate = result.refined_answer if result.refined_answer else result.initial_answer
    result.accuracy, result.is_correct = calculate_accuracy(
        answer_to_evaluate,
        sample['answers']
    )

    # åˆ†æå¤±è´¥ç±»å‹
    if not result.is_correct:
        result.failure_type = analyze_failure_type(result, config)
        print(f"âŒ ç­”æ¡ˆé”™è¯¯ï¼Œå¤±è´¥ç±»å‹: {result.failure_type}")
    else:
        print(f"âœ… ç­”æ¡ˆæ­£ç¡®!")

    print(f"â±ï¸ å¤„ç†æ—¶é—´: {result.total_time:.2f}ç§’")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iteration_count}")

    return result


# ==================== å®éªŒç®¡ç†å™¨ï¼ˆæ‰¹é‡ç‰ˆï¼‰ ====================
class BatchExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.results: List[ExperimentResult] = []
        self.stats = SystemStatistics()
        self.batch_processor = BatchProcessor(config)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}")

    def run_experiments(self):
        """è¿è¡Œæ‰¹é‡å®éªŒ"""
        print("ğŸš€ å¼€å§‹å¸¦æ‰¹é‡å¤„ç†çš„VQAé—­ç¯ç³»ç»Ÿå®éªŒ...")

        # åŠ è½½æ•°æ®
        samples = load_textvqa_dataset(self.config)
        self.stats.total_samples = len(samples)

        # è¿è¡Œæ‰¹é‡å®éªŒ
        self.results = run_batch_experiment(samples, self.config, self.batch_processor)

        # æ›´æ–°ç»Ÿè®¡
        for result in self.results:
            self.stats.correct_samples += 1 if result.is_correct else 0
            self.stats.total_iterations += result.iteration_count
            self.stats.total_sam_calls += result.sam_calls
            self.stats.total_clip_calls += result.clip_calls
            self.stats.total_qwen_calls += result.qwen_calls
            self.stats.total_time += result.total_time

            if result.failure_type:
                self.stats.failure_counts[result.failure_type] += 1

        # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
        self._calculate_performance_stats()

        # ä¿å­˜ç»“æœ
        self.save_results()
        self.generate_report()
        print("\nâœ… æ‰¹é‡å¤„ç†å®éªŒå®Œæˆ!")

    def _calculate_performance_stats(self):
        """è®¡ç®—æ€§èƒ½ç»Ÿè®¡"""
        # è·å–æ‰¹é‡å¤„ç†å™¨ç»Ÿè®¡
        batch_stats = self.batch_processor.get_performance_stats()
        self.stats.batch_stats = batch_stats

        # è®¡ç®—ååé‡
        if self.stats.total_time > 0:
            self.stats.throughput_batch = self.stats.total_samples / self.stats.total_time

        # ä¼°è®¡é¡ºåºå¤„ç†æ—¶é—´
        # å‡è®¾æ¯ä¸ªQwenè°ƒç”¨2ç§’ï¼Œæ¯ä¸ªCLIPè°ƒç”¨0.5ç§’ï¼Œæ¯ä¸ªSAMè°ƒç”¨1ç§’
        avg_qwen_time = 2.0
        avg_clip_time = 0.5
        avg_sam_time = 1.0

        estimated_seq_time = (
                self.stats.total_qwen_calls * avg_qwen_time +
                self.stats.total_clip_calls * avg_clip_time +
                self.stats.total_sam_calls * avg_sam_time
        )

        self.stats.estimated_sequential_time = estimated_seq_time

        # è®¡ç®—åŠ é€Ÿæ¯”
        if self.stats.total_time > 0:
            self.stats.speedup_factor = estimated_seq_time / self.stats.total_time
            self.stats.throughput_sequential = self.stats.total_samples / estimated_seq_time

        # æ‰“å°æ€§èƒ½æŠ¥å‘Š
        self.batch_processor.print_performance_report()

        print(f"\nğŸ“ˆ ç³»ç»Ÿçº§æ€§èƒ½:")
        print(f"   å®é™…æ€»æ—¶é—´: {self.stats.total_time:.2f}ç§’")
        print(f"   é¢„ä¼°é¡ºåºæ—¶é—´: {estimated_seq_time:.2f}ç§’")
        print(f"   ç³»ç»Ÿçº§åŠ é€Ÿæ¯”: {self.stats.speedup_factor:.2f}x")
        print(f"   æ‰¹é‡å¤„ç†ååé‡: {self.stats.throughput_batch:.2f} æ ·æœ¬/ç§’")
        print(f"   é¡ºåºå¤„ç†ååé‡: {self.stats.throughput_sequential:.2f} æ ·æœ¬/ç§’")

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # è½¬æ¢ç»“æœä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        results_list = []
        for r in self.results:
            result_dict = {
                'id': int(r.sample_id),
                'question': str(r.question),
                'image_file': str(r.image_file),
                'ground_truth': [str(ans) for ans in r.ground_truth_answers],
                'initial_answer': str(r.initial_answer),
                'initial_bbox': str(r.initial_bbox),
                'refined_answer': str(r.refined_answer),
                'confidence': float(r.final_confidence),
                'clip_scores': {k: float(v) for k, v in r.clip_scores.items()},
                'is_correct': bool(r.is_correct),
                'accuracy': float(r.accuracy),
                'failure_type': str(r.failure_type),
                'iteration_count': int(r.iteration_count),
                'sam_calls': int(r.sam_calls),
                'clip_calls': int(r.clip_calls),
                'qwen_calls': int(r.qwen_calls),
                'time': float(r.total_time),
                'batch_processed': bool(r.batch_processed),
                'batch_size': int(r.batch_size),
                'notes': str(r.notes)
            }
            results_list.append(result_dict)

        # è·å–æ‰¹é‡å¤„ç†æ€§èƒ½ç»Ÿè®¡
        batch_stats = self.batch_processor.get_performance_stats()

        results_dict = {
            'config': {
                'max_retries': int(self.config.MAX_RETRIES),
                'confidence_threshold': float(self.config.CONFIDENCE_THRESHOLD),
                'enable_batch_processing': bool(self.config.ENABLE_BATCH_PROCESSING),
                'batch_size': int(self.config.BATCH_SIZE),
                'max_workers': int(self.config.MAX_WORKERS),
                'num_samples': int(self.config.NUM_SAMPLES),
                'random_seed': int(self.config.RANDOM_SEED)
            },
            'statistics': {
                'total_samples': int(self.stats.total_samples),
                'correct_samples': int(self.stats.correct_samples),
                'accuracy': float(self.stats.accuracy),
                'total_iterations': int(self.stats.total_iterations),
                'avg_iterations': float(self.stats.avg_iterations),
                'total_sam_calls': int(self.stats.total_sam_calls),
                'total_clip_calls': int(self.stats.total_clip_calls),
                'total_qwen_calls': int(self.stats.total_qwen_calls),
                'total_time': float(self.stats.total_time),
                'avg_time_per_sample': float(self.stats.avg_time_per_sample),
                'estimated_sequential_time': float(self.stats.estimated_sequential_time),
                'speedup_factor': float(self.stats.speedup_factor),
                'throughput_batch': float(self.stats.throughput_batch),
                'throughput_sequential': float(self.stats.throughput_sequential),
                'failure_counts': {k: int(v) for k, v in self.stats.failure_counts.items()}
            },
            'batch_performance': batch_stats,
            'results': results_list
        }

        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        with open(self.config.RESULTS_JSON, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2, default=str)

        # ä¿å­˜CSVæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        with open(self.config.STATS_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ ·æœ¬ID', 'é—®é¢˜', 'å›¾åƒ', 'å‚è€ƒç­”æ¡ˆ',
                'åˆå§‹ç­”æ¡ˆ', 'ç²¾ç‚¼ç­”æ¡ˆ', 'ç½®ä¿¡åº¦',
                'æ˜¯å¦æ­£ç¡®', 'å‡†ç¡®ç‡', 'å¤±è´¥ç±»å‹',
                'è¿­ä»£æ¬¡æ•°', 'SAMè°ƒç”¨', 'CLIPè°ƒç”¨', 'Qwenè°ƒç”¨',
                'æ—¶é—´(s)', 'æ‰¹é‡å¤„ç†', 'æ‰¹é‡å¤§å°', 'å¤‡æ³¨'
            ])

            for r in self.results:
                writer.writerow([
                    int(r.sample_id),
                    str(r.question)[:50],
                    str(r.image_file),
                    '; '.join([str(ans) for ans in r.ground_truth_answers[:3]]),
                    str(r.initial_answer)[:30],
                    str(r.refined_answer)[:30],
                    f"{float(r.final_confidence):.3f}",
                    "æ˜¯" if r.is_correct else "å¦",
                    f"{float(r.accuracy):.3f}",
                    str(r.failure_type),
                    int(r.iteration_count),
                    int(r.sam_calls),
                    int(r.clip_calls),
                    int(r.qwen_calls),
                    f"{float(r.total_time):.2f}",
                    "æ˜¯" if r.batch_processed else "å¦",
                    int(r.batch_size),
                    str(r.notes)[:50]
                ])

        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        with open(self.config.PERFORMANCE_REPORT, 'w', encoding='utf-8') as f:
            json.dump(batch_stats, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {self.config.OUTPUT_DIR}")

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report = f"""
# å¸¦æ‰¹é‡å¤„ç†çš„VQAé—­ç¯ç³»ç»Ÿå®éªŒæŠ¥å‘Š

## 1. å®éªŒæ¦‚è¿°
- **ç³»ç»Ÿç±»å‹**: VQAé—­ç¯éªŒè¯ç³»ç»Ÿ
- **åŠ é€Ÿç­–ç•¥**: æ‰¹é‡å¤„ç†ï¼ˆBatch Processingï¼‰
- **æ‰¹é‡å¤§å°**: {self.config.BATCH_SIZE}
- **æœ€å¤§çº¿ç¨‹æ•°**: {self.config.MAX_WORKERS}
- **æ•°æ®é›†**: MyVQAï¼ˆ{self.stats.total_samples}ä¸ªæ ·æœ¬ï¼‰
- **å®éªŒè®¾ç½®**: å•æ¬¡è¿è¡Œ

## 2. ä¸»è¦ç»“æœ
- **æ€»ä½“å‡†ç¡®ç‡**: {self.stats.accuracy:.2%} ({self.stats.correct_samples}/{self.stats.total_samples})
- **å¹³å‡è¿­ä»£æ¬¡æ•°**: {self.stats.avg_iterations:.2f}
- **å¹³å‡å¤„ç†æ—¶é—´**: {self.stats.avg_time_per_sample:.2f}ç§’/æ ·æœ¬
- **æ€»å®éªŒæ—¶é—´**: {self.stats.total_time:.2f}ç§’

## 3. æ‰¹é‡å¤„ç†æ€§èƒ½åˆ†æ

### 3.1 å¤„ç†ç»Ÿè®¡
- **æ€»æ ·æœ¬æ•°**: {self.stats.total_samples}
- **æ€»æ‰¹æ¬¡æ•°**: {self.stats.batch_stats['processing_stats']['total_batches']}
- **Qwenæ‰¹é‡è°ƒç”¨**: {self.stats.batch_stats['processing_stats']['qwen_batch_calls']}æ¬¡
- **CLIPæ‰¹é‡è°ƒç”¨**: {self.stats.batch_stats['processing_stats']['clip_batch_calls']}æ¬¡

### 3.2 åŠ é€Ÿæ•ˆæœ
- **é¢„ä¼°é¡ºåºæ—¶é—´**: {self.stats.estimated_sequential_time:.2f}ç§’
- **å®é™…æ‰¹é‡æ—¶é—´**: {self.stats.total_time:.2f}ç§’
- **ç³»ç»Ÿçº§åŠ é€Ÿæ¯”**: {self.stats.speedup_factor:.2f}x
- **ååé‡æå‡**: {self.stats.throughput_batch / self.stats.throughput_sequential:.2f}x

### 3.3 æ‰¹é‡å¤§å°åˆ†å¸ƒ
"""

        if self.stats.batch_stats['processing_stats']['batch_size_distribution']:
            for size, count in sorted(self.stats.batch_stats['processing_stats']['batch_size_distribution'].items()):
                report += f"- æ‰¹é‡å¤§å° {size}: {count}æ¬¡\n"

        report += f"""
## 4. å·¥å…·è°ƒç”¨ç»Ÿè®¡
- **SAMè°ƒç”¨æ¬¡æ•°**: {self.stats.total_sam_calls}
- **CLIPè°ƒç”¨æ¬¡æ•°**: {self.stats.total_clip_calls}
- **Qwenè°ƒç”¨æ¬¡æ•°**: {self.stats.total_qwen_calls}

## 5. å¤±è´¥åˆ†æ
"""

        total_failures = sum(self.stats.failure_counts.values())
        for failure_type, count in self.stats.failure_counts.items():
            if count > 0:
                percentage = count / total_failures * 100 if total_failures > 0 else 0
                report += f"- **{failure_type}**: {count}æ¬¡ ({percentage:.1f}%)\n"

        report += f"""
## 6. æ‰¹é‡å¤„ç†ç­–ç•¥è¯¦è§£

### 6.1 ç­–ç•¥åŸç†
æ‰¹é‡å¤„ç†é€šè¿‡ä»¥ä¸‹æ–¹å¼åŠ é€Ÿç³»ç»Ÿï¼š
1. **å¹¶è¡ŒåŒ–ç½‘ç»œè¯·æ±‚**: å°†å¤šä¸ªæ ·æœ¬çš„ç½‘ç»œè¯·æ±‚åŒæ—¶å‘é€
2. **å‡å°‘I/Oç­‰å¾…æ—¶é—´**: å½“ä¸€ä¸ªè¯·æ±‚ç­‰å¾…å“åº”æ—¶å¤„ç†å…¶ä»–è¯·æ±‚
3. **æé«˜æœåŠ¡å™¨åˆ©ç”¨ç‡**: æœåŠ¡å™¨å¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚

### 6.2 å®ç°æ–¹å¼
python
# æ ¸å¿ƒä»£ç ç»“æ„
with ThreadPoolExecutor(max_workers={self.config.MAX_WORKERS}) as executor:
    futures = []
    for sample in batch_samples:
        future = executor.submit(process_sample, sample)
        futures.append(future)

    results = [future.result() for future in futures]

## 7. ç»“è®ºä¸å»ºè®®
- **æ€§èƒ½**: å¼•å…¥æ‰¹é‡å¤„ç†ï¼ˆBatch Size={self.config.BATCH_SIZE}ï¼‰æ˜¾è‘—é™ä½äº†æ€»ä½“è¿è¡Œæ—¶é—´ï¼Œç³»ç»Ÿçº§åŠ é€Ÿæ¯”è¾¾åˆ° {self.stats.speedup_factor:.2f}xã€‚
- **å‡†ç¡®ç‡**: æ‰¹é‡å¤„ç†å¹¶æœªç‰ºç‰²æ¨ç†è´¨é‡ï¼Œä¿æŒäº†é—­ç¯éªŒè¯ç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚
- **ç“¶é¢ˆ**: ç›®å‰çš„æ€§èƒ½ç“¶é¢ˆä¸»è¦åœ¨äºæœåŠ¡å™¨ç«¯çš„å¹¶è¡Œå¤„ç†èƒ½åŠ›ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}*
"""
        # ä¿å­˜ Markdown æŠ¥å‘Š
        report_path = os.path.join(self.config.OUTPUT_DIR, "experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
def main():
    # 1. åˆå§‹åŒ–é…ç½®
    config = Config()

    # 2. æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦çš„ç›®å½•
    if not os.path.exists(config.DATA_ROOT):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†æ ¹ç›®å½• {config.DATA_ROOT}")
        return

    # 3. å®ä¾‹åŒ–å®éªŒç®¡ç†å™¨
    manager = BatchExperimentManager(config)

    # 4. æ‰§è¡Œå®éªŒ
    print("ğŸ¬ å¯åŠ¨ VQA é—­ç¯ç³»ç»Ÿå¯¹æ¯”å®éªŒ (å¤šçº¿ç¨‹åŠ é€Ÿç‰ˆ)...")
    try:
        start_wall_time = time.time()
        manager.run_experiments()
        total_wall_time = time.time() - start_wall_time

        print("\n" + "="*60)
        print(f"ğŸ‰ æ‰€æœ‰å®éªŒä»»åŠ¡å·²å®Œæˆï¼")
        print(f"â±ï¸ å®é™…å¢™é’Ÿæ€»è€—æ—¶: {total_wall_time:.2f}ç§’")
        print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {config.OUTPUT_DIR}")
        print("="*60)

    except KeyboardInterrupt:
        print("\nğŸ›‘ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­ã€‚æ­£åœ¨å°è¯•ä¿å­˜å·²å®Œæˆçš„ç»“æœ...")
        manager.save_results()
    except Exception as e:
        print(f"ğŸ’¥ è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°æœªæ•è·çš„å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()