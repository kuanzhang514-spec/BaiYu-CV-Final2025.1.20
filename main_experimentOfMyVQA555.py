'''
å¯¹æ¯”è¯•éªŒ
6.åˆé‡æ–°è®¾è®¡äº†åŠ é€Ÿç­–ç•¥
å¤šçº§ç¼“å­˜åŠ é€Ÿç­–ç•¥ï¼Œç¼“å­˜åˆ°æœ¬åœ°./cache_new555ç›®å½•äº†
'''

import os
import json
import time
import csv
import numpy as np
from PIL import Image
import requests
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple, Any, Optional
from tqdm import tqdm
import re
import base64
from io import BytesIO
import pickle
import hashlib
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed


# ==================== é…ç½® ====================
@dataclass
class Config:
    # æœåŠ¡å™¨é…ç½®
    SERVER_IP = "è¿™æ˜¯æˆ‘çš„æœåŠ¡å™¨IPåœ°å€ï¼Œæˆ‘éšè—äº†"
    QWEN_URL = f"http://{SERVER_IP}:8020/chat_vl"
    CLIP_URL = f"http://{SERVER_IP}:8021/clip/score"
    SAM_URL = f"http://{SERVER_IP}:8022/segment_by_bbox"

    # æ•°æ®é›†è·¯å¾„
    DATA_ROOT = r"C:\Users\kuanzhang\Desktop\courseB\fuwuqisanhaoji\MyVQA\combined_dataset"
    METADATA_PATH = os.path.join(DATA_ROOT, "combined_metadata.json")
    IMAGE_DIR = os.path.join(DATA_ROOT, "images")

    # å®éªŒå‚æ•°
    MAX_RETRIES = 2
    CONFIDENCE_THRESHOLD = 0.2
    TEMP_EVIDENCE_PATH = "./temp_evidence.png"

    # è¾“å‡ºè·¯å¾„
    OUTPUT_DIR = "./results_with_cache_new555_again"
    RESULTS_JSON = os.path.join(OUTPUT_DIR, "results1.json")
    STATS_CSV = os.path.join(OUTPUT_DIR, "statistics.csv")
    SAM_SEGMENTS_DIR = os.path.join(OUTPUT_DIR, "sam_segments")

    # ç¼“å­˜é…ç½®
    CACHE_DIR = "./cache_new555"
    CACHE_ENABLED = True
    CACHE_EXPIRY_SECONDS = 3600  # ç¼“å­˜1å°æ—¶è¿‡æœŸ
    PARALLEL_CALLS = True  # å¯ç”¨å¹¶è¡Œè°ƒç”¨
    MAX_WORKERS = 2  # æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°

    # å®éªŒè®¾ç½®,æ ·æœ¬æ•°ï¼Œéšæœºç§å­
    NUM_SAMPLES = 110  # è‡ªå»ºæ•°æ®é›†
    RANDOM_SEED = 42


# ==================== ç¼“å­˜ç®¡ç†å™¨ ====================
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ï¼Œç”¨äºåŠ é€Ÿé‡å¤è°ƒç”¨"""

    def __init__(self, config: Config):
        self.config = config
        self.cache_dir = config.CACHE_DIR
        self.enabled = config.CACHE_ENABLED
        self.expiry = config.CACHE_EXPIRY_SECONDS

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        if self.enabled:
            os.makedirs(self.cache_dir, exist_ok=True)

        # å†…å­˜ç¼“å­˜ï¼ˆå‡å°‘ç£ç›˜IOï¼‰
        self.memory_cache = {
            'qwen': {},
            'clip': {},
            'sam': {}
        }

        # ç»Ÿè®¡ä¿¡æ¯
        self.hits = 0
        self.misses = 0

    def _get_cache_key(self, service: str, *args, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å°†å‚æ•°åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²
        data = f"{service}:{str(args)}:{str(sorted(kwargs.items()))}"
        # ä½¿ç”¨MD5ç”ŸæˆçŸ­é”®
        return hashlib.md5(data.encode('utf-8')).hexdigest()

    def _get_cache_path(self, cache_key: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, f"{cache_key}.pkl")

    def get(self, service: str, *args, **kwargs) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if not self.enabled:
            return None

        cache_key = self._get_cache_key(service, *args, **kwargs)

        # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache[service]:
            self.hits += 1
            return self.memory_cache[service][cache_key]

        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_path = self._get_cache_path(cache_key)
        if os.path.exists(cache_path):
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - os.path.getmtime(cache_path) < self.expiry:
                try:
                    with open(cache_path, 'rb') as f:
                        data = pickle.load(f)
                    # å­˜å…¥å†…å­˜ç¼“å­˜
                    self.memory_cache[service][cache_key] = data
                    self.hits += 1
                    return data
                except Exception as e:
                    print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")

        self.misses += 1
        return None

    def set(self, service: str, data: Any, *args, **kwargs) -> None:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if not self.enabled:
            return

        cache_key = self._get_cache_key(service, *args, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        # å­˜å…¥å†…å­˜ç¼“å­˜
        self.memory_cache[service][cache_key] = data

        # å­˜å…¥ç£ç›˜ç¼“å­˜ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜å†™å…¥å¤±è´¥: {e}")

    def clear_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œè¿”å›æ¸…ç†æ•°é‡"""
        if not self.enabled:
            return 0

        cleared = 0
        current_time = time.time()

        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.pkl'):
                cache_path = os.path.join(self.cache_dir, filename)
                if current_time - os.path.getmtime(cache_path) > self.expiry:
                    try:
                        os.remove(cache_path)
                        cleared += 1
                    except Exception as e:
                        print(f"âš ï¸ ç¼“å­˜åˆ é™¤å¤±è´¥: {e}")

        return cleared

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'enabled': self.enabled,
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': self.hits / (self.hits + self.misses) if (self.hits + self.misses) > 0 else 0,
            'memory_cache_sizes': {k: len(v) for k, v in self.memory_cache.items()}
        }


# ==================== å¹¶è¡Œè°ƒç”¨ç®¡ç†å™¨ ====================
class ParallelCallManager:
    """å¹¶è¡Œè°ƒç”¨ç®¡ç†å™¨"""

    def __init__(self, config: Config):
        self.config = config
        self.executor = None

    def __enter__(self):
        if self.config.PARALLEL_CALLS:
            self.executor = ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.executor:
            self.executor.shutdown(wait=True)

    def submit(self, fn, *args, **kwargs):
        """æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± """
        if self.executor:
            return self.executor.submit(fn, *args, **kwargs)
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            class DummyFuture:
                def __init__(self, result):
                    self.result = result

                def result(self):
                    return self.result

            return DummyFuture(fn(*args, **kwargs))


# ==================== æ•°æ®ç»“æ„ ====================
@dataclass
class ExperimentResult:
    sample_id: int
    image_file: str
    question: str
    ground_truth_answers: List[str]

    # ç³»ç»Ÿè¾“å‡º
    initial_answer: str = ""
    initial_bbox: str = ""
    refined_answer: str = ""
    final_confidence: float = 0.0
    clip_scores: Dict[str, float] = None

    # æ€§èƒ½æŒ‡æ ‡
    iteration_count: int = 0
    sam_calls: int = 0
    clip_calls: int = 0
    qwen_calls: int = 0
    total_time: float = 0.0

    # ç¼“å­˜æŒ‡æ ‡
    cache_hits: Dict[str, int] = None
    cache_saved_time: float = 0.0

    # è¯„ä¼°
    accuracy: float = 0.0
    is_correct: bool = False
    failure_type: str = ""
    notes: str = ""

    def __post_init__(self):
        if self.clip_scores is None:
            self.clip_scores = {}
        if self.cache_hits is None:
            self.cache_hits = {'qwen': 0, 'clip': 0, 'sam': 0}


@dataclass
class SystemStatistics:
    total_samples: int = 0
    correct_samples: int = 0
    total_iterations: int = 0
    total_sam_calls: int = 0
    total_clip_calls: int = 0
    total_qwen_calls: int = 0
    total_time: float = 0.0

    # ç¼“å­˜ç»Ÿè®¡
    cache_stats: Dict[str, Any] = None
    total_cache_saved_time: float = 0.0

    # æŒ‰å¤±è´¥ç±»å‹ç»Ÿè®¡
    failure_counts: Dict[str, int] = None

    def __post_init__(self):
        if self.failure_counts is None:
            self.failure_counts = {
                "location_failure": 0,
                "segmentation_failure": 0,
                "reasoning_failure": 0,
                "verification_failure": 0,
                "other": 0
            }
        if self.cache_stats is None:
            self.cache_stats = {}

    @property
    def accuracy(self) -> float:
        return self.correct_samples / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_iterations(self) -> float:
        return self.total_iterations / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_time_per_sample(self) -> float:
        return self.total_time / self.total_samples if self.total_samples > 0 else 0


# ==================== å·¥å…·å‡½æ•° ====================
def load_textvqa_dataset(config: Config) -> List[Dict]:
    """åŠ è½½MyVQAæ•°æ®é›†"""
    with open(config.METADATA_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆç¡®ä¿å¯å¤ç°ï¼‰
    np.random.seed(config.RANDOM_SEED)
    selected_indices = np.random.choice(len(data), min(config.NUM_SAMPLES, len(data)), replace=False)

    samples = []
    for idx in selected_indices:
        sample = data[idx]
        sample['id'] = idx  # ç¡®ä¿IDæ­£ç¡®
        samples.append(sample)

    print(f"ğŸ“Š åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    return samples


def image_to_base64(image_path: str, max_size=(512, 512)) -> str:
    """å›¾åƒè½¬Base64"""
    try:
        img = Image.open(image_path)
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
        img.thumbnail(max_size)
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ å›¾åƒè½¬Base64å¤±è´¥: {e}")
        return ""


def call_qwen(prompt: str, image_path: str = None, config: Config = None,
              cache_manager: CacheManager = None) -> str:
    """è°ƒç”¨Qwen-VLæœåŠ¡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ£€æŸ¥ç¼“å­˜
    if cache_manager:
        cached = cache_manager.get('qwen', prompt, image_path)
        if cached is not None:
            print(f"ğŸ“¦ Qwenç¼“å­˜å‘½ä¸­!")
            return cached

    try:
        payload = {"prompt": prompt}
        if image_path and os.path.exists(image_path):
            print(f"ğŸ“¤ å‘é€å›¾åƒ: {os.path.basename(image_path)}")
            payload["image_url"] = image_to_base64(image_path)

        response = requests.post(config.QWEN_URL, json=payload, timeout=120)

        print(f"ğŸ“¡ Qwenå“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code == 200:
            res = response.json()
            print(f"ğŸ“¥ QwenåŸå§‹å“åº”: {res}")
            result = res.get("response", "").strip()

            # å­˜å…¥ç¼“å­˜
            if cache_manager:
                cache_manager.set('qwen', result, prompt, image_path)

            return result
        else:
            print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except requests.exceptions.Timeout:
        print("â° Qwenè°ƒç”¨è¶…æ—¶")
    except Exception as e:
        print(f"ğŸ’¥ Qwenè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return ""


def call_sam(image_path: str, bbox_str: str, config: Config,
             save_segment: bool = True, iteration: int = 1,
             cache_manager: CacheManager = None) -> Tuple[bool, Optional[bytes]]:
    """è°ƒç”¨SAMæœåŠ¡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ£€æŸ¥ç¼“å­˜
    if cache_manager:
        cache_key = f"{image_path}:{bbox_str}"
        cached = cache_manager.get('sam', cache_key)
        if cached is not None:
            print(f"ğŸ“¦ SAMç¼“å­˜å‘½ä¸­!")
            # å³ä½¿ä»ç¼“å­˜è¯»å–ï¼Œä¹Ÿéœ€è¦ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                out.write(cached)

            # å¦‚æœéœ€è¦ä¿å­˜åˆ†å‰²å›¾åƒ
            if save_segment:
                segment_path = save_sam_segment(
                    cached, image_path, bbox_str, iteration, config
                )
                print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜ (ç¼“å­˜): {segment_path}")

            return True, cached

    try:
        with open(image_path, 'rb') as f:
            files = {'image': f}
            data = {'bbox': bbox_str}
            response = requests.post(config.SAM_URL, files=files, data=data, timeout=30)

            if response.status_code == 200:
                segment_data = response.content

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ç”¨äºåç»­å¤„ç†
                with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                    out.write(segment_data)

                # å¦‚æœéœ€è¦ä¿å­˜åˆ†å‰²å›¾åƒ
                if save_segment:
                    segment_path = save_sam_segment(
                        segment_data, image_path, bbox_str, iteration, config
                    )
                    print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜: {segment_path}")

                # å­˜å…¥ç¼“å­˜
                if cache_manager:
                    cache_manager.set('sam', segment_data, f"{image_path}:{bbox_str}")

                return True, segment_data
            else:
                print(f"âŒ SAMè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ SAMè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return False, None


def call_clip(image_bytes: bytes, text_label: str, config: Config,
              cache_manager: CacheManager = None) -> float:
    """è°ƒç”¨CLIPæœåŠ¡ï¼Œè¿”å›æœ€é«˜ç›¸ä¼¼åº¦ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ£€æŸ¥ç¼“å­˜
    if cache_manager:
        # ä½¿ç”¨å›¾åƒå­—èŠ‚æµçš„å“ˆå¸Œå’Œæ–‡æœ¬ä½œä¸ºç¼“å­˜é”®
        image_hash = hashlib.md5(image_bytes).hexdigest()
        cache_key = f"{image_hash}:{text_label}"
        cached = cache_manager.get('clip', cache_key)
        if cached is not None:
            print(f"ğŸ“¦ CLIPç¼“å­˜å‘½ä¸­!")
            return cached

    files = {'imagefile': ('evidence.png', image_bytes, 'image/png')}
    data = {'text': text_label, 'temperature': 100.0}

    try:
        response = requests.post(config.CLIP_URL, files=files, data=data, timeout=10)
        if response.status_code == 200:
            res = response.json()
            if res.get('results'):
                # è¿”å›æ‰€æœ‰æ ‡ç­¾ä¸­çš„æœ€é«˜ç›¸ä¼¼åº¦
                similarities = [v['similarity'] for v in res['results'].values()]
                result = float(max(similarities)) if similarities else 0.0

                # å­˜å…¥ç¼“å­˜
                if cache_manager:
                    cache_manager.set('clip', result, f"{hashlib.md5(image_bytes).hexdigest()}:{text_label}")

                return result
        else:
            print(f"âŒ CLIPè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ CLIPè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return 0.0


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1, x2 = sorted([max(0, min(img_w, x)) for x in (x1, x2)])
            y1, y2 = sorted([max(0, min(img_h, y)) for y in (y1, y2)])
            return f"{x1},{y1},{x2},{y2}"

    # æœªæ‰¾åˆ°åæ ‡ï¼Œè¿”å›å…¨å›¾
    return f"0,0,{img_w},{img_h}"


def normalize_answer(answer: str) -> str:
    """æ ‡å‡†åŒ–ç­”æ¡ˆï¼šå°å†™ã€ç§»é™¤æ ‡ç‚¹ã€ç©ºæ ¼"""
    if not answer:
        return ""
    # è½¬æ¢ä¸ºå°å†™
    answer = answer.lower()
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    answer = re.sub(r'[^\w\s]', '', answer)
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    answer = ' '.join(answer.split())
    return answer


def calculate_accuracy(predicted_answer: str, ground_truths: List[str]) -> Tuple[float, bool]:
    """è®¡ç®—ç­”æ¡ˆå‡†ç¡®æ€§ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    if not predicted_answer:
        return 0.0, False

    pred_normalized = normalize_answer(predicted_answer)

    for truth in ground_truths:
        if not truth:
            continue

        truth_normalized = normalize_answer(truth)

        # ç²¾ç¡®åŒ¹é…
        if pred_normalized == truth_normalized:
            return 1.0, True

        # åŒ…å«åŒ¹é…ï¼ˆé’ˆå¯¹è¾ƒé•¿ç­”æ¡ˆï¼‰
        if truth_normalized in pred_normalized or pred_normalized in truth_normalized:
            return 1.0, True

        # æ•°å­—æå–åŒ¹é…ï¼ˆé’ˆå¯¹OCRé—®é¢˜ï¼‰
        pred_digits = ''.join(filter(str.isdigit, pred_normalized))
        truth_digits = ''.join(filter(str.isdigit, truth_normalized))
        if pred_digits and pred_digits == truth_digits:
            return 1.0, True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å“ç‰Œ/åç§°
        common_brands = ['yamaha', 'red', 'mike lee', 'aj52uyv']
        for brand in common_brands:
            if brand in pred_normalized and brand in truth_normalized:
                return 1.0, True

    return 0.0, False


def analyze_failure_type(result: ExperimentResult, config: Config) -> str:
    """åˆ†æå¤±è´¥ç±»å‹"""
    if result.final_confidence < config.CONFIDENCE_THRESHOLD:
        return "verification_failure"
    elif result.iteration_count == 0:
        return "location_failure"
    elif "æ— æ³•" in result.refined_answer or "ä¸èƒ½" in result.refined_answer:
        return "reasoning_failure"
    else:
        return "other"


# ==================== ä¸»å®éªŒæµç¨‹ ====================
def run_single_experiment(sample: Dict, config: Config,
                          cache_manager: CacheManager) -> ExperimentResult:
    """è¿è¡Œå•ä¸ªæ ·æœ¬çš„å®éªŒï¼ˆå¸¦ç¼“å­˜åŠ é€Ÿï¼‰"""
    result = ExperimentResult(
        sample_id=sample['id'],
        image_file=sample['image_file'],
        question=sample['question'],
        ground_truth_answers=sample['answers']
    )

    start_time = time.time()
    image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])

    # Step 1: è·å–å›¾åƒå°ºå¯¸
    try:
        with Image.open(image_path) as img:
            img_w, img_h = img.size
    except Exception as e:
        result.notes = f"æ— æ³•æ‰“å¼€å›¾åƒ: {e}"
        result.total_time = time.time() - start_time
        return result

    # Step 2: Qwenåˆæ­¥å›ç­” + å®šä½
    prompt1 = f"é—®é¢˜ï¼š{sample['question']} è¯·å…ˆç»™å‡ºç­”æ¡ˆï¼›å†ä»¥æ ¼å¼(å·¦ä¸Šè§’xåæ ‡,å·¦ä¸Šè§’yåæ ‡) (å³ä¸‹è§’xåæ ‡,å³ä¸‹è§’yåæ ‡) ä¸¤ç‚¹ç”Ÿæˆçš„çŸ©å½¢æ¡†å°†å›¾ç‰‡éœ€è¦å…³æ³¨åŒºåŸŸåŒ…å›´è¿›å»ã€‚"
    print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º: {prompt1}")

    cache_before = cache_manager.get_stats()['hits'] if cache_manager else 0

    initial_response = call_qwen(prompt1, image_path, config, cache_manager)
    result.qwen_calls += 1

    # è®°å½•ç¼“å­˜å‘½ä¸­
    if cache_manager:
        cache_after = cache_manager.get_stats()['hits']
        if cache_after > cache_before:
            result.cache_hits['qwen'] += 1

    if not initial_response:
        result.notes = "Qwenåˆæ­¥å›ç­”å¤±è´¥"
        result.total_time = time.time() - start_time
        return result

    print(f"ğŸ“¥ Qwenåˆæ­¥å›ç­”: {initial_response}")
    result.initial_answer = initial_response
    result.initial_bbox = extract_bbox_from_text(initial_response, img_w, img_h)
    print(f"ğŸ“ æå–çš„BBox: {result.initial_bbox}")

    # Step 3: é—­ç¯éªŒè¯å¾ªç¯
    bbox_str = result.initial_bbox
    refined_answer = ""
    confidence = 0.0
    iteration = 0

    for retry in range(config.MAX_RETRIES + 1):
        iteration += 1
        print(f"ğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£å°è¯•...")

        # è°ƒç”¨SAMåˆ†å‰²ï¼Œå¹¶ä¿å­˜å›¾åƒï¼ˆå¸¦ç¼“å­˜ï¼‰
        sam_success, evidence_bytes = call_sam(
            image_path, bbox_str, config,
            save_segment=True, iteration=iteration,
            cache_manager=cache_manager
        )

        if not sam_success:
            result.notes = f"SAMåˆ†å‰²å¤±è´¥ (è¿­ä»£{iteration})"
            break

        result.sam_calls += 1

        # è®°å½•SAMç¼“å­˜å‘½ä¸­
        if cache_manager and evidence_bytes:
            # æ£€æŸ¥æ˜¯å¦ä»ç¼“å­˜è·å–ï¼ˆé€šè¿‡æ¯”è¾ƒç¼“å­˜ç»Ÿè®¡ï¼‰
            pass  # å·²åœ¨call_samä¸­è®°å½•

        # æ£€æŸ¥è¯æ®å›¾æ˜¯å¦å­˜åœ¨
        if not os.path.exists(config.TEMP_EVIDENCE_PATH):
            result.notes = f"è¯æ®å›¾æœªç”Ÿæˆ (è¿­ä»£{iteration})"
            break

        # è¯»å–è¯æ®å›¾
        try:
            evidence_size = os.path.getsize(config.TEMP_EVIDENCE_PATH)
            if evidence_size == 0:
                result.notes = f"è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶ (è¿­ä»£{iteration})"
                break

            # å¦‚æœå·²ç»ä»ç¼“å­˜è·å–äº†å­—èŠ‚æµï¼Œå°±ç›´æ¥ä½¿ç”¨
            if evidence_bytes is None:
                with open(config.TEMP_EVIDENCE_PATH, "rb") as f:
                    evidence_bytes = f.read()
        except Exception as e:
            result.notes = f"è¯»å–è¯æ®å›¾å¤±è´¥: {e}"
            break

        # QwenåŸºäºè¯æ®å›¾é‡æ–°å›ç­”
        prompt2 = f"åªçœ‹è¿™å¼ è£å‰ªåçš„å›¾åƒï¼Œå›ç­”ï¼š{sample['question']}"
        refined_answer = call_qwen(prompt2, config.TEMP_EVIDENCE_PATH, config, cache_manager)
        result.qwen_calls += 1

        if not refined_answer:
            result.notes = f"Qwené‡ç­”å¤±è´¥ (è¿­ä»£{iteration})"
            break

        print(f"ğŸ“¥ Qwenç²¾ç‚¼å›ç­”: {refined_answer}")

        # CLIPéªŒè¯ï¼ˆå¸¦ç¼“å­˜ï¼‰
        confidence = call_clip(evidence_bytes, refined_answer, config, cache_manager)
        result.clip_calls += 1
        result.clip_scores[f"iteration_{iteration}"] = float(confidence)

        print(f"ğŸ¯ CLIPç½®ä¿¡åº¦: {confidence:.3f} (é˜ˆå€¼: {config.CONFIDENCE_THRESHOLD})")

        if confidence >= config.CONFIDENCE_THRESHOLD:
            result.refined_answer = refined_answer
            result.final_confidence = float(confidence)
            print(f"âœ… éªŒè¯é€šè¿‡!")
            break
        elif retry == 0:
            # ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾
            print("âš ï¸ ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾...")
            bbox_str = f"0,0,{img_w},{img_h}"
        else:
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥")

    result.iteration_count = iteration
    result.total_time = time.time() - start_time

    # å¦‚æœç²¾ç‚¼ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨åˆå§‹ç­”æ¡ˆ
    if not result.refined_answer and result.initial_answer:
        result.refined_answer = result.initial_answer
        # å¦‚æœæ²¡æœ‰CLIPéªŒè¯ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
        if result.final_confidence == 0.0:
            result.final_confidence = 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦

    # è¯„ä¼°å‡†ç¡®æ€§
    answer_to_evaluate = result.refined_answer if result.refined_answer else result.initial_answer
    result.accuracy, result.is_correct = calculate_accuracy(
        answer_to_evaluate,
        sample['answers']
    )

    # åˆ†æå¤±è´¥ç±»å‹
    if not result.is_correct:
        result.failure_type = analyze_failure_type(result, config)
        print(f"âŒ ç­”æ¡ˆé”™è¯¯ï¼Œå¤±è´¥ç±»å‹: {result.failure_type}")
    else:
        print(f"âœ… ç­”æ¡ˆæ­£ç¡®!")

    # ä¼°ç®—ç¼“å­˜èŠ‚çœçš„æ—¶é—´ï¼ˆå‡è®¾æ¯æ¬¡ç½‘ç»œè°ƒç”¨å¹³å‡200msï¼‰
    avg_call_time = 0.2
    total_hits = sum(result.cache_hits.values())
    result.cache_saved_time = total_hits * avg_call_time

    print(f"â±ï¸ å¤„ç†æ—¶é—´: {result.total_time:.2f}ç§’")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iteration_count}")
    print(f"ğŸ“¦ ç¼“å­˜å‘½ä¸­: {result.cache_hits}, èŠ‚çœæ—¶é—´: {result.cache_saved_time:.2f}ç§’")

    return result


def save_sam_segment(segment_data: bytes, original_image_path: str,
                     bbox_str: str, iteration: int, config: Config):
    """ä¿å­˜SAMåˆ†å‰²çš„å›¾åƒ"""
    # åˆ›å»ºç›®å½•
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    base_name = os.path.splitext(os.path.basename(original_image_path))[0]
    if iteration == 1:
        suffix = "initial"
    elif iteration == 2:
        suffix = "full"
    else:
        suffix = f"retry{iteration}"

    # ç®€åŒ–bboxå­—ç¬¦ä¸²ç”¨äºæ–‡ä»¶åï¼ˆç§»é™¤é€—å·ï¼‰
    bbox_simple = bbox_str.replace(',', '_')

    # å®Œæ•´çš„æ–‡ä»¶å
    filename = f"{base_name}_{suffix}_{bbox_simple}.png"
    filepath = os.path.join(config.SAM_SEGMENTS_DIR, filename)

    # ä¿å­˜æ–‡ä»¶
    with open(filepath, "wb") as f:
        f.write(segment_data)

    return filepath


# ==================== å®éªŒç®¡ç† ====================
class ExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.results: List[ExperimentResult] = []
        self.stats = SystemStatistics()
        self.cache_manager = CacheManager(config)
        self.parallel_manager = ParallelCallManager(config)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        if config.CACHE_ENABLED:
            cleared = self.cache_manager.clear_expired()
            if cleared > 0:
                print(f"ğŸ§¹ æ¸…ç†äº† {cleared} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")

    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®éªŒ...")
        print(f"ğŸ“¦ ç¼“å­˜åŠ é€Ÿ: {'å¯ç”¨' if self.config.CACHE_ENABLED else 'ç¦ç”¨'}")
        print(f"âš¡ å¹¶è¡Œè°ƒç”¨: {'å¯ç”¨' if self.config.PARALLEL_CALLS else 'ç¦ç”¨'}")

        # åŠ è½½æ•°æ®
        samples = load_textvqa_dataset(self.config)
        self.stats.total_samples = len(samples)

        # ä½¿ç”¨å¹¶è¡Œç®¡ç†å™¨
        with self.parallel_manager as pm:
            # é€ä¸ªè¿è¡Œå®éªŒ
            for i, sample in enumerate(tqdm(samples, desc="è¿›è¡Œå®éªŒ")):
                print(f"\n{'=' * 60}")
                print(f"æ ·æœ¬ {i + 1}/{len(samples)}: {sample['question']}")
                print(f"å›¾åƒ: {sample['image_file']}")
                print(f"å‚è€ƒç­”æ¡ˆ: {sample['answers'][:3]}")  # æ˜¾ç¤ºå‰3ä¸ªå‚è€ƒç­”æ¡ˆ

                result = run_single_experiment(sample, self.config, self.cache_manager)
                self.results.append(result)

                # æ›´æ–°ç»Ÿè®¡
                self.stats.correct_samples += 1 if result.is_correct else 0
                self.stats.total_iterations += result.iteration_count
                self.stats.total_sam_calls += result.sam_calls
                self.stats.total_clip_calls += result.clip_calls
                self.stats.total_qwen_calls += result.qwen_calls
                self.stats.total_time += result.total_time
                self.stats.total_cache_saved_time += result.cache_saved_time

                if result.failure_type:
                    self.stats.failure_counts[result.failure_type] += 1

                # æ¯5ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡è¿›åº¦
                if (i + 1) % 5 == 0:
                    self.save_results()
                    print(f"\nğŸ’¾ å·²ä¿å­˜{len(self.results)}ä¸ªæ ·æœ¬çš„ç»“æœ")

        # æ›´æ–°ç¼“å­˜ç»Ÿè®¡
        self.stats.cache_stats = self.cache_manager.get_stats()

        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_results()
        self.generate_report()
        print("\nâœ… å®éªŒå®Œæˆ!")

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # è½¬æ¢ç»“æœä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        results_list = []
        for r in self.results:
            result_dict = {
                'id': int(r.sample_id),
                'question': str(r.question),
                'image_file': str(r.image_file),
                'ground_truth': [str(ans) for ans in r.ground_truth_answers],
                'initial_answer': str(r.initial_answer),
                'initial_bbox': str(r.initial_bbox),
                'refined_answer': str(r.refined_answer),
                'confidence': float(r.final_confidence),
                'clip_scores': {k: float(v) for k, v in r.clip_scores.items()},
                'is_correct': bool(r.is_correct),
                'accuracy': float(r.accuracy),
                'failure_type': str(r.failure_type),
                'iteration_count': int(r.iteration_count),
                'sam_calls': int(r.sam_calls),
                'clip_calls': int(r.clip_calls),
                'qwen_calls': int(r.qwen_calls),
                'cache_hits': dict(r.cache_hits),
                'cache_saved_time': float(r.cache_saved_time),
                'time': float(r.total_time),
                'notes': str(r.notes)
            }
            results_list.append(result_dict)

        results_dict = {
            'config': {
                'max_retries': int(self.config.MAX_RETRIES),
                'confidence_threshold': float(self.config.CONFIDENCE_THRESHOLD),
                'num_samples': int(self.config.NUM_SAMPLES),
                'random_seed': int(self.config.RANDOM_SEED),
                'cache_enabled': bool(self.config.CACHE_ENABLED),
                'parallel_calls': bool(self.config.PARALLEL_CALLS)
            },
            'statistics': {
                'total_samples': int(self.stats.total_samples),
                'correct_samples': int(self.stats.correct_samples),
                'accuracy': float(self.stats.accuracy),
                'total_iterations': int(self.stats.total_iterations),
                'avg_iterations': float(self.stats.avg_iterations),
                'total_sam_calls': int(self.stats.total_sam_calls),
                'total_clip_calls': int(self.stats.total_clip_calls),
                'total_qwen_calls': int(self.stats.total_qwen_calls),
                'total_time': float(self.stats.total_time),
                'avg_time_per_sample': float(self.stats.avg_time_per_sample),
                'total_cache_saved_time': float(self.stats.total_cache_saved_time),
                'cache_stats': dict(self.stats.cache_stats),
                'failure_counts': {k: int(v) for k, v in self.stats.failure_counts.items()}
            },
            'results': results_list
        }

        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        with open(self.config.RESULTS_JSON, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2, default=str)

        # ä¿å­˜CSVæ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        with open(self.config.STATS_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ ·æœ¬ID', 'é—®é¢˜', 'å›¾åƒ', 'å‚è€ƒç­”æ¡ˆ',
                'åˆå§‹ç­”æ¡ˆ', 'ç²¾ç‚¼ç­”æ¡ˆ', 'ç½®ä¿¡åº¦',
                'æ˜¯å¦æ­£ç¡®', 'å‡†ç¡®ç‡', 'å¤±è´¥ç±»å‹',
                'è¿­ä»£æ¬¡æ•°', 'SAMè°ƒç”¨', 'CLIPè°ƒç”¨', 'Qwenè°ƒç”¨',
                'ç¼“å­˜å‘½ä¸­(Qwen/SAM/CLIP)', 'ç¼“å­˜èŠ‚çœæ—¶é—´(s)',
                'æ—¶é—´(s)', 'å¤‡æ³¨'
            ])

            for r in self.results:
                writer.writerow([
                    int(r.sample_id),
                    str(r.question)[:50],  # æˆªæ–­é•¿é—®é¢˜
                    str(r.image_file),
                    '; '.join([str(ans) for ans in r.ground_truth_answers[:3]]),
                    str(r.initial_answer)[:30],
                    str(r.refined_answer)[:30],
                    f"{float(r.final_confidence):.3f}",
                    "æ˜¯" if r.is_correct else "å¦",
                    f"{float(r.accuracy):.3f}",
                    str(r.failure_type),
                    int(r.iteration_count),
                    int(r.sam_calls),
                    int(r.clip_calls),
                    int(r.qwen_calls),
                    f"{r.cache_hits['qwen']}/{r.cache_hits['sam']}/{r.cache_hits['clip']}",
                    f"{float(r.cache_saved_time):.2f}",
                    f"{float(r.total_time):.2f}",
                    str(r.notes)[:50]
                ])

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {self.config.OUTPUT_DIR}")

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        cache_stats = self.stats.cache_stats

        report = f"""
# å¯éªŒè¯è§†è§‰é—®ç­”é—­ç¯ç³»ç»Ÿå®éªŒæŠ¥å‘Š

## 1. å®éªŒæ¦‚è¿°
- æ•°æ®é›†ï¼šMyVQAï¼ˆ{self.stats.total_samples}ä¸ªæ ·æœ¬ï¼‰
- é—­ç¯é…ç½®ï¼šæœ€å¤§è¿­ä»£{self.config.MAX_RETRIES}æ¬¡ï¼Œç½®ä¿¡åº¦é˜ˆå€¼{self.config.CONFIDENCE_THRESHOLD}
- éšæœºç§å­ï¼š{self.config.RANDOM_SEED}
- ç¼“å­˜åŠ é€Ÿï¼š{'å¯ç”¨' if self.config.CACHE_ENABLED else 'ç¦ç”¨'}
- å¹¶è¡Œè°ƒç”¨ï¼š{'å¯ç”¨' if self.config.PARALLEL_CALLS else 'ç¦ç”¨'}

## 2. ä¸»è¦ç»“æœ
- **æ€»ä½“å‡†ç¡®ç‡**ï¼š{self.stats.accuracy:.2%} ({self.stats.correct_samples}/{self.stats.total_samples})
- **å¹³å‡è¿­ä»£æ¬¡æ•°**ï¼š{self.stats.avg_iterations:.2f}
- **å¹³å‡å¤„ç†æ—¶é—´**ï¼š{self.stats.avg_time_per_sample:.2f}ç§’/æ ·æœ¬
- **æ€»å®éªŒæ—¶é—´**ï¼š{self.stats.total_time:.2f}ç§’

## 3. ç¼“å­˜åŠ é€Ÿæ•ˆæœ
- **ç¼“å­˜å‘½ä¸­ç‡**ï¼š{cache_stats.get('hit_rate', 0):.2%}
- **æ€»å‘½ä¸­æ¬¡æ•°**ï¼š{cache_stats.get('hits', 0)}
- **æ€»æœªå‘½ä¸­æ¬¡æ•°**ï¼š{cache_stats.get('misses', 0)}
- **é¢„ä¼°èŠ‚çœæ—¶é—´**ï¼š{self.stats.total_cache_saved_time:.2f}ç§’
- **å†…å­˜ç¼“å­˜å¤§å°**ï¼šQwen: {cache_stats.get('memory_cache_sizes', {}).get('qwen', 0)}, 
                   SAM: {cache_stats.get('memory_cache_sizes', {}).get('sam', 0)},
                   CLIP: {cache_stats.get('memory_cache_sizes', {}).get('clip', 0)}

## 4. å·¥å…·è°ƒç”¨ç»Ÿè®¡
- SAMè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_sam_calls}
- CLIPè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_clip_calls}
- Qwenè°ƒç”¨æ¬¡æ•°ï¼š{self.stats.total_qwen_calls}

## 5. å¤±è´¥åˆ†æ
"""

        total_failures = sum(self.stats.failure_counts.values())
        for failure_type, count in self.stats.failure_counts.items():
            if count > 0:
                percentage = count / total_failures * 100 if total_failures > 0 else 0
                report += f"- **{failure_type}**: {count}æ¬¡ ({percentage:.1f}%)\n"

        report += """
## 6. å…³é”®å‘ç°
1. **å®šä½å‡†ç¡®æ€§**ï¼šQwenèƒ½å¤Ÿæå–åæ ‡ï¼Œä½†æœ‰æ—¶æå–çš„åæ ‡ä¸å‡†ç¡®
2. **è¯æ®è´¨é‡**ï¼šSAMåˆ†å‰²çš„è¯æ®å›¾æœ‰æ—¶ä¸èƒ½åŒ…å«å…³é”®ä¿¡æ¯
3. **éªŒè¯æœ‰æ•ˆæ€§**ï¼šCLIPéªŒè¯èƒ½å¤Ÿè¿‡æ»¤éƒ¨åˆ†é”™è¯¯ç­”æ¡ˆï¼Œä½†é˜ˆå€¼éœ€è¦è°ƒæ•´
4. **ç¼“å­˜æ•ˆæœ**ï¼šç¼“å­˜æ˜¾è‘—å‡å°‘äº†é‡å¤è°ƒç”¨ï¼Œæå‡å®éªŒé€Ÿåº¦{self.config.CACHE_ENABLED}
5. **ç³»ç»Ÿç¨³å®šæ€§**ï¼šæ•´ä¸ªé—­ç¯ç³»ç»Ÿèƒ½å¤Ÿç¨³å®šè¿è¡Œï¼Œä½†è€—æ—¶è¾ƒé•¿

## 7. æ”¹è¿›å»ºè®®
1. **åæ ‡æå–ä¼˜åŒ–**ï¼šæ”¹è¿›æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¤„ç†æ›´å¤šåæ ‡æ ¼å¼
2. **è¯æ®å›¾å¢å¼º**ï¼šè€ƒè™‘ä½¿ç”¨å¤šä¸ªå€™é€‰åŒºåŸŸï¼Œé€‰æ‹©æœ€ä½³è¯æ®
3. **éªŒè¯ç­–ç•¥**ï¼šè°ƒæ•´CLIPæ¸©åº¦å‚æ•°ï¼Œæé«˜åˆ†æ•°åŒºåˆ†åº¦
4. **å¹¶è¡Œå¤„ç†**ï¼šå°†å¤šä¸ªå·¥å…·è°ƒç”¨å¹¶è¡ŒåŒ–ä»¥å‡å°‘æ—¶é—´
5. **ç¼“å­˜ä¼˜åŒ–**ï¼šå¢åŠ ç¼“å­˜é¢„çƒ­ã€é¢„åŠ è½½ç­–ç•¥
6. **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡æ ·æœ¬åŒæ—¶å¤„ç†ï¼Œå‡å°‘ç½‘ç»œå¼€é”€

## 8. æ ·æœ¬ç¤ºä¾‹
"""

        # æ·»åŠ 3ä¸ªç¤ºä¾‹ç»“æœ
        for i, r in enumerate(self.results[:3]):
            report += f"""
### ç¤ºä¾‹ {i + 1}
- **é—®é¢˜**: {r.question}
- **åˆå§‹ç­”æ¡ˆ**: {r.initial_answer}
- **ç²¾ç‚¼ç­”æ¡ˆ**: {r.refined_answer}
- **ç½®ä¿¡åº¦**: {r.final_confidence:.3f}
- **æ˜¯å¦æ­£ç¡®**: {'æ˜¯' if r.is_correct else 'å¦'}
- **ç¼“å­˜å‘½ä¸­**: Qwen:{r.cache_hits['qwen']}, SAM:{r.cache_hits['sam']}, CLIP:{r.cache_hits['clip']}
- **å¤„ç†æ—¶é—´**: {r.total_time:.2f}ç§’ (èŠ‚çœ{r.cache_saved_time:.2f}ç§’)
"""

        report_path = os.path.join(self.config.OUTPUT_DIR, "experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")


# ==================== ä¸»ç¨‹åº ====================
def main():
    # åˆå§‹åŒ–é…ç½®
    config = Config()

    # ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•éƒ½å­˜åœ¨
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)
    os.makedirs(config.CACHE_DIR, exist_ok=True)

    # è¿è¡Œä¸»å®éªŒ
    print("=" * 60)
    print("ğŸ“ è®¡ç®—æœºè§†è§‰ç»“è¯¾è®ºæ–‡å®éªŒç³»ç»Ÿ - ç¼“å­˜åŠ é€Ÿç‰ˆ")
    print("=" * 60)

    manager = ExperimentManager(config)
    manager.run_experiments()

    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {config.OUTPUT_DIR}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {config.RESULTS_JSON}")
    print(f"ğŸ“Š ç»Ÿè®¡è¡¨æ ¼: {config.STATS_CSV}")
    print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {config.OUTPUT_DIR}/experiment_report.md")
    print(f"ğŸ“¦ ç¼“å­˜ç›®å½•: {config.CACHE_DIR}")


if __name__ == "__main__":
    main()
