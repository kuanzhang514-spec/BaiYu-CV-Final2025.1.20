'''
2.è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿ
åŸºäºå†å²ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´é˜ˆå€¼
'''

import os
import json
import time
import csv
import numpy as np
from PIL import Image
import requests
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Tuple, Any, Optional
from tqdm import tqdm
import re
import base64
from io import BytesIO
from collections import deque
import statistics


# ==================== é…ç½® ====================
@dataclass
class Config:
    # æœåŠ¡å™¨é…ç½®
    SERVER_IP = "192.168.10.115"
    QWEN_URL = f"http://{SERVER_IP}:8020/chat_vl"
    CLIP_URL = f"http://{SERVER_IP}:8021/clip/score"
    SAM_URL = f"http://{SERVER_IP}:8022/segment_by_bbox"

    # æ•°æ®é›†è·¯å¾„
    DATA_ROOT = r"C:\Users\kuanzhang\Desktop\courseB\fuwuqisanhaoji\MyVQA\combined_dataset"
    METADATA_PATH = os.path.join(DATA_ROOT, "combined_metadata.json")
    IMAGE_DIR = os.path.join(DATA_ROOT, "images")

    # å®éªŒå‚æ•°
    MAX_RETRIES = 2
    INITIAL_CONFIDENCE_THRESHOLD = 0.2  # åˆå§‹é˜ˆå€¼
    TEMP_EVIDENCE_PATH = "./temp_evidence.png"

    # è‡ªé€‚åº”é˜ˆå€¼å‚æ•°
    ADAPTIVE_WINDOW_SIZE = 20  # æ»‘åŠ¨çª—å£å¤§å°
    MIN_THRESHOLD = 0.1  # æœ€å°é˜ˆå€¼
    MAX_THRESHOLD = 0.5  # æœ€å¤§é˜ˆå€¼
    THRESHOLD_ADJUSTMENT_STEP = 0.05  # è°ƒæ•´æ­¥é•¿
    CONFIDENCE_SMOOTHING_ALPHA = 0.3  # æŒ‡æ•°å¹³æ»‘ç³»æ•°

    # è¾“å‡ºè·¯å¾„
    OUTPUT_DIR = "./results_adaptive"
    RESULTS_JSON = os.path.join(OUTPUT_DIR, "results_adaptive.json")
    STATS_CSV = os.path.join(OUTPUT_DIR, "statistics_adaptive.csv")
    THRESHOLD_LOG = os.path.join(OUTPUT_DIR, "threshold_evolution.csv")
    SAM_SEGMENTS_DIR = os.path.join(OUTPUT_DIR, "sam_segments")

    # å®éªŒè®¾ç½®
    NUM_SAMPLES = 110
    RANDOM_SEED = 42


# ==================== è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨ ====================
class AdaptiveThresholdManager:
    """ç®¡ç†è‡ªé€‚åº”é˜ˆå€¼ï¼Œæ ¹æ®å†å²è¡¨ç°åŠ¨æ€è°ƒæ•´å…¨å±€é˜ˆå€¼"""

    def __init__(self, config: Config):
        self.config = config
        self.current_threshold = config.INITIAL_CONFIDENCE_THRESHOLD
        self.confidence_history = deque(maxlen=config.ADAPTIVE_WINDOW_SIZE)
        self.threshold_history = []
        self.performance_history = []  # è®°å½•æ­£ç¡®/é”™è¯¯
        self.smoothed_confidence = 0.0

        print(f"ğŸ“Š åˆå§‹åŒ–è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨")
        print(f"  åˆå§‹é˜ˆå€¼: {self.current_threshold:.3f}")
        print(f"  é˜ˆå€¼èŒƒå›´: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]")
        print(f"  æ»‘åŠ¨çª—å£å¤§å°: {self.config.ADAPTIVE_WINDOW_SIZE}")

    def get_threshold(self) -> float:
        """è·å–å½“å‰é˜ˆå€¼"""
        return self.current_threshold

    def update(self, confidence: float, is_correct: bool):
        """æ›´æ–°å†å²å¹¶è°ƒæ•´é˜ˆå€¼"""
        # æ›´æ–°å†å²è®°å½•
        self.confidence_history.append(confidence)
        self.performance_history.append(is_correct)
        self.threshold_history.append(self.current_threshold)

        # è®¡ç®—æŒ‡æ•°å¹³æ»‘çš„ç½®ä¿¡åº¦
        if self.smoothed_confidence == 0:
            self.smoothed_confidence = confidence
        else:
            alpha = self.config.CONFIDENCE_SMOOTHING_ALPHA
            self.smoothed_confidence = (alpha * confidence +
                                       (1 - alpha) * self.smoothed_confidence)

        print(f"ğŸ“ˆ æ›´æ–°é˜ˆå€¼å†å²: ç½®ä¿¡åº¦={confidence:.3f}, æ˜¯å¦æ­£ç¡®={is_correct}")
        print(f"   å†å²ç½®ä¿¡åº¦çª—å£: {len(self.confidence_history)}/{self.config.ADAPTIVE_WINDOW_SIZE}")
        print(f"   å¹³æ»‘ç½®ä¿¡åº¦: {self.smoothed_confidence:.3f}")

        # å¦‚æœæœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œè°ƒæ•´é˜ˆå€¼
        if len(self.confidence_history) >= 5:
            old_threshold = self.current_threshold
            self._adjust_threshold()

            # è¾“å‡ºè°ƒæ•´ä¿¡æ¯
            if abs(old_threshold - self.current_threshold) > 0.001:
                print(f"ğŸ”„ é˜ˆå€¼è°ƒæ•´: {old_threshold:.3f} â†’ {self.current_threshold:.3f}")

        return self.current_threshold

    def _adjust_threshold(self):
        """åŸºäºå†å²è¡¨ç°è°ƒæ•´é˜ˆå€¼"""
        if len(self.confidence_history) < 5:
            return

        # è®¡ç®—å…³é”®ç»Ÿè®¡é‡
        window_size = min(10, len(self.confidence_history))
        recent_confidences = list(self.confidence_history)[-window_size:]
        mean_confidence = np.mean(recent_confidences)
        std_confidence = np.std(recent_confidences)

        # è®¡ç®—æœ€è¿‘æ­£ç¡®ç‡
        recent_performances = self.performance_history[-window_size:] if len(self.performance_history) >= window_size else self.performance_history
        if recent_performances:
            recent_accuracy = sum(recent_performances) / len(recent_performances)
        else:
            recent_accuracy = 0.5

        print(f"ğŸ“Š åˆ†æç»Ÿè®¡: å¹³å‡ç½®ä¿¡åº¦={mean_confidence:.3f}, æ ‡å‡†å·®={std_confidence:.3f}, æœ€è¿‘æ­£ç¡®ç‡={recent_accuracy:.2%}")

        old_threshold = self.current_threshold

        # è§„åˆ™1: å¦‚æœç½®ä¿¡åº¦æ™®éè¾ƒé«˜ï¼Œæé«˜é˜ˆå€¼ä»¥æé«˜ç²¾åº¦
        if mean_confidence > 0.4 and recent_accuracy > 0.7:
            self.current_threshold += self.config.THRESHOLD_ADJUSTMENT_STEP
            print(f"  è§„åˆ™1è§¦å‘: ç½®ä¿¡åº¦é«˜ä¸”æ­£ç¡®ç‡é«˜ â†’ æé«˜é˜ˆå€¼")

        # è§„åˆ™2: å¦‚æœç½®ä¿¡åº¦æ™®éè¾ƒä½ï¼Œé™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
        elif mean_confidence < 0.2 and recent_accuracy < 0.4:
            self.current_threshold -= self.config.THRESHOLD_ADJUSTMENT_STEP
            print(f"  è§„åˆ™2è§¦å‘: ç½®ä¿¡åº¦ä½ä¸”æ­£ç¡®ç‡ä½ â†’ é™ä½é˜ˆå€¼")

        # è§„åˆ™3: å¦‚æœæ ‡å‡†å·®å¤§ï¼Œè¯´æ˜ç½®ä¿¡åº¦ä¸ç¨³å®šï¼Œç¨å¾®æé«˜é˜ˆå€¼
        elif std_confidence > 0.15:
            self.current_threshold += self.config.THRESHOLD_ADJUSTMENT_STEP * 0.5
            print(f"  è§„åˆ™3è§¦å‘: ç½®ä¿¡åº¦ä¸ç¨³å®š â†’ ç¨å¾®æé«˜é˜ˆå€¼")

        # è§„åˆ™4: åŸºäºå¹³æ»‘ç½®ä¿¡åº¦å¾®è°ƒ
        if self.smoothed_confidence > 0.35:
            self.current_threshold = min(self.current_threshold + 0.02, self.config.MAX_THRESHOLD)
        elif self.smoothed_confidence < 0.15:
            self.current_threshold = max(self.current_threshold - 0.02, self.config.MIN_THRESHOLD)

        # ç¡®ä¿é˜ˆå€¼åœ¨èŒƒå›´å†…
        self.current_threshold = max(self.config.MIN_THRESHOLD,
                                   min(self.current_threshold, self.config.MAX_THRESHOLD))

    def get_history_stats(self) -> Dict[str, Any]:
        """è·å–å†å²ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "current_threshold": self.current_threshold,
            "history_size": len(self.confidence_history),
            "mean_confidence": np.mean(self.confidence_history) if self.confidence_history else 0,
            "std_confidence": np.std(self.confidence_history) if len(self.confidence_history) > 1 else 0,
            "threshold_history": self.threshold_history.copy(),
            "smoothed_confidence": self.smoothed_confidence
        }

    def save_threshold_log(self, filepath: str):
        """ä¿å­˜é˜ˆå€¼æ¼”åŒ–æ—¥å¿—"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['æ ·æœ¬ç´¢å¼•', 'é˜ˆå€¼', 'ç½®ä¿¡åº¦', 'æ˜¯å¦æ­£ç¡®', 'å¹³æ»‘ç½®ä¿¡åº¦'])

            for i in range(len(self.threshold_history)):
                confidence = self.confidence_history[i] if i < len(self.confidence_history) else 0
                is_correct = self.performance_history[i] if i < len(self.performance_history) else False
                smoothed = self.smoothed_confidence if i == len(self.threshold_history) - 1 else 0
                writer.writerow([
                    i + 1,
                    f"{self.threshold_history[i]:.3f}",
                    f"{confidence:.3f}",
                    "æ˜¯" if is_correct else "å¦",
                    f"{smoothed:.3f}"
                ])

        print(f"ğŸ“ˆ é˜ˆå€¼æ¼”åŒ–æ—¥å¿—å·²ä¿å­˜: {filepath}")


# ==================== æ•°æ®ç»“æ„ ====================
@dataclass
class ExperimentResult:
    sample_id: int
    image_file: str
    question: str
    ground_truth_answers: List[str]

    # ç³»ç»Ÿè¾“å‡º
    initial_answer: str = ""
    initial_bbox: str = ""
    refined_answer: str = ""
    final_confidence: float = 0.0
    clip_scores: Dict[str, float] = None
    used_threshold: float = 0.0  # è®°å½•ä½¿ç”¨çš„é˜ˆå€¼

    # æ€§èƒ½æŒ‡æ ‡
    iteration_count: int = 0
    sam_calls: int = 0
    clip_calls: int = 0
    qwen_calls: int = 0
    total_time: float = 0.0

    # è¯„ä¼°
    accuracy: float = 0.0
    is_correct: bool = False
    failure_type: str = ""
    notes: str = ""

    def __post_init__(self):
        if self.clip_scores is None:
            self.clip_scores = {}


@dataclass
class SystemStatistics:
    total_samples: int = 0
    correct_samples: int = 0
    total_iterations: int = 0
    total_sam_calls: int = 0
    total_clip_calls: int = 0
    total_qwen_calls: int = 0
    total_time: float = 0.0

    # é˜ˆå€¼ç›¸å…³ç»Ÿè®¡
    threshold_stats: Dict[str, float] = None
    adaptive_performance: Dict[str, float] = None

    # æŒ‰å¤±è´¥ç±»å‹ç»Ÿè®¡
    failure_counts: Dict[str, int] = None

    def __post_init__(self):
        if self.failure_counts is None:
            self.failure_counts = {
                "location_failure": 0,
                "segmentation_failure": 0,
                "reasoning_failure": 0,
                "verification_failure": 0,
                "other": 0
            }
        if self.threshold_stats is None:
            self.threshold_stats = {
                "min_threshold": 1.0,
                "max_threshold": 0.0,
                "avg_threshold": 0.0,
                "threshold_adjustments": 0
            }
        if self.adaptive_performance is None:
            self.adaptive_performance = {
                "correct_below_threshold": 0,
                "wrong_above_threshold": 0,
                "threshold_effectiveness": 0.0
            }

    @property
    def accuracy(self) -> float:
        return self.correct_samples / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_iterations(self) -> float:
        return self.total_iterations / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_time_per_sample(self) -> float:
        return self.total_time / self.total_samples if self.total_samples > 0 else 0


# ==================== å·¥å…·å‡½æ•° ====================
def load_textvqa_dataset(config: Config) -> List[Dict]:
    """åŠ è½½TextVQAæ•°æ®é›†"""
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†: {config.METADATA_PATH}")
    with open(config.METADATA_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆç¡®ä¿å¯å¤ç°ï¼‰
    np.random.seed(config.RANDOM_SEED)
    selected_indices = np.random.choice(len(data), min(config.NUM_SAMPLES, len(data)), replace=False)

    samples = []
    for idx in selected_indices:
        sample = data[idx]
        sample['id'] = idx
        samples.append(sample)

    print(f"ğŸ“Š åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    return samples


def image_to_base64(image_path: str, max_size=(512, 512)) -> str:
    """å›¾åƒè½¬Base64"""
    try:
        img = Image.open(image_path)
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
        img.thumbnail(max_size)
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ å›¾åƒè½¬Base64å¤±è´¥: {e}")
        return ""


def call_qwen(prompt: str, image_path: str = None, config: Config = None) -> str:
    """è°ƒç”¨Qwen-VLæœåŠ¡"""
    try:
        payload = {"prompt": prompt}
        if image_path and os.path.exists(image_path):
            print(f"ğŸ“¤ å‘é€å›¾åƒ: {os.path.basename(image_path)}")
            payload["image_url"] = image_to_base64(image_path)

        response = requests.post(config.QWEN_URL, json=payload, timeout=120)

        print(f"ğŸ“¡ Qwenå“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code == 200:
            res = response.json()
            print(f"ğŸ“¥ QwenåŸå§‹å“åº”: {res}")
            return res.get("response", "").strip()
        else:
            print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except requests.exceptions.Timeout:
        print("â° Qwenè°ƒç”¨è¶…æ—¶")
    except Exception as e:
        print(f"ğŸ’¥ Qwenè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return ""


def call_sam(image_path: str, bbox_str: str, config: Config,
             save_segment: bool = True, iteration: int = 1) -> bool:
    """è°ƒç”¨SAMæœåŠ¡"""
    try:
        with open(image_path, 'rb') as f:
            files = {'image': f}
            data = {'bbox': bbox_str}
            response = requests.post(config.SAM_URL, files=files, data=data, timeout=30)

            if response.status_code == 200:
                segment_data = response.content

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                    out.write(segment_data)

                # ä¿å­˜åˆ†å‰²å›¾åƒ
                if save_segment:
                    segment_path = save_sam_segment(
                        segment_data, image_path, bbox_str, iteration, config
                    )
                    print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜: {segment_path}")

                return True
            else:
                print(f"âŒ SAMè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ SAMè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return False


def call_clip(image_bytes: bytes, text_label: str, config: Config) -> float:
    """è°ƒç”¨CLIPæœåŠ¡ï¼Œè¿”å›æœ€é«˜ç›¸ä¼¼åº¦"""
    files = {'imagefile': ('evidence.png', image_bytes, 'image/png')}
    data = {'text': text_label, 'temperature': 100.0}

    try:
        print(f"ğŸ“¤ è°ƒç”¨CLIPéªŒè¯ï¼Œæ–‡æœ¬æ ‡ç­¾: {text_label[:30]}...")
        response = requests.post(config.CLIP_URL, files=files, data=data, timeout=10)
        if response.status_code == 200:
            res = response.json()
            if res.get('results'):
                # è¿”å›æ‰€æœ‰æ ‡ç­¾ä¸­çš„æœ€é«˜ç›¸ä¼¼åº¦
                similarities = [v['similarity'] for v in res['results'].values()]
                max_similarity = float(max(similarities)) if similarities else 0.0
                print(f"ğŸ“¥ CLIPè¿”å›ç›¸ä¼¼åº¦: {max_similarity:.3f}")
                return max_similarity
        else:
            print(f"âŒ CLIPè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ CLIPè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return 0.0


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            x1, x2 = sorted([max(0, min(img_w, x)) for x in (x1, x2)])
            y1, y2 = sorted([max(0, min(img_h, y)) for y in (y1, y2)])
            return f"{x1},{y1},{x2},{y2}"

    return f"0,0,{img_w},{img_h}"


def normalize_answer(answer: str) -> str:
    """æ ‡å‡†åŒ–ç­”æ¡ˆ"""
    if not answer:
        return ""
    answer = answer.lower()
    answer = re.sub(r'[^\w\s]', '', answer)
    answer = ' '.join(answer.split())
    return answer


def calculate_accuracy(predicted_answer: str, ground_truths: List[str]) -> Tuple[float, bool]:
    """è®¡ç®—ç­”æ¡ˆå‡†ç¡®æ€§"""
    if not predicted_answer:
        return 0.0, False

    pred_normalized = normalize_answer(predicted_answer)

    for truth in ground_truths:
        if not truth:
            continue

        truth_normalized = normalize_answer(truth)

        # ç²¾ç¡®åŒ¹é…
        if pred_normalized == truth_normalized:
            return 1.0, True

        # åŒ…å«åŒ¹é…
        if truth_normalized in pred_normalized or pred_normalized in truth_normalized:
            return 1.0, True

        # æ•°å­—æå–åŒ¹é…
        pred_digits = ''.join(filter(str.isdigit, pred_normalized))
        truth_digits = ''.join(filter(str.isdigit, truth_normalized))
        if pred_digits and pred_digits == truth_digits:
            return 1.0, True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å“ç‰Œ/åç§°
        common_brands = ['yamaha', 'red', 'mike lee', 'aj52uyv']
        for brand in common_brands:
            if brand in pred_normalized and brand in truth_normalized:
                return 1.0, True

    return 0.0, False


def analyze_failure_type(result: ExperimentResult, threshold: float) -> str:
    """åˆ†æå¤±è´¥ç±»å‹"""
    if result.final_confidence < threshold:
        return "verification_failure"
    elif result.iteration_count == 0:
        return "location_failure"
    elif "æ— æ³•" in result.refined_answer or "ä¸èƒ½" in result.refined_answer:
        return "reasoning_failure"
    else:
        return "other"


# ==================== ä¸»å®éªŒæµç¨‹ ====================
def run_single_experiment(sample: Dict, config: Config,
                         threshold_manager: AdaptiveThresholdManager) -> ExperimentResult:
    """è¿è¡Œå•ä¸ªæ ·æœ¬çš„å®éªŒ"""
    print(f"\n{'='*60}")
    print(f"ğŸ” å¼€å§‹å¤„ç†æ ·æœ¬ ID: {sample['id']}")
    print(f"ğŸ“· å›¾åƒ: {sample['image_file']}")
    print(f"â“ é—®é¢˜: {sample['question']}")
    print(f"ğŸ“ å‚è€ƒç­”æ¡ˆ: {sample['answers'][:3]}")

    result = ExperimentResult(
        sample_id=sample['id'],
        image_file=sample['image_file'],
        question=sample['question'],
        ground_truth_answers=sample['answers']
    )

    start_time = time.time()
    image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])

    # Step 1: è·å–å›¾åƒå°ºå¯¸
    print(f"ğŸ“ è·å–å›¾åƒå°ºå¯¸...")
    try:
        with Image.open(image_path) as img:
            img_w, img_h = img.size
            print(f"   å›¾åƒå°ºå¯¸: {img_w} x {img_h}")
    except Exception as e:
        result.notes = f"æ— æ³•æ‰“å¼€å›¾åƒ: {e}"
        result.total_time = time.time() - start_time
        print(f"âŒ æ— æ³•æ‰“å¼€å›¾åƒ: {e}")
        return result

    # Step 2: è·å–å½“å‰é˜ˆå€¼
    current_threshold = threshold_manager.get_threshold()
    result.used_threshold = current_threshold
    print(f"ğŸ¯ å½“å‰è‡ªé€‚åº”é˜ˆå€¼: {current_threshold:.3f}")

    # Step 3: Qwenåˆæ­¥å›ç­” + å®šä½
    prompt1 = f"é—®é¢˜ï¼š{sample['question']} è¯·å…ˆç»™å‡ºç­”æ¡ˆï¼›å†ä»¥æ ¼å¼(å·¦ä¸Šè§’xåæ ‡,å·¦ä¸Šè§’yåæ ‡) (å³ä¸‹è§’xåæ ‡,å³ä¸‹è§’yåæ ‡) ä¸¤ç‚¹ç”Ÿæˆçš„çŸ©å½¢æ¡†å°†å›¾ç‰‡éœ€è¦å…³æ³¨åŒºåŸŸåŒ…å›´è¿›å»ã€‚"
    print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º: {prompt1}")

    initial_response = call_qwen(prompt1, image_path, config)
    result.qwen_calls += 1

    if not initial_response:
        result.notes = "Qwenåˆæ­¥å›ç­”å¤±è´¥"
        result.total_time = time.time() - start_time
        print(f"âŒ Qwenåˆæ­¥å›ç­”å¤±è´¥")
        return result

    print(f"ğŸ“¥ Qwenåˆæ­¥å›ç­”: {initial_response}")
    result.initial_answer = initial_response
    result.initial_bbox = extract_bbox_from_text(initial_response, img_w, img_h)
    print(f"ğŸ“ æå–çš„BBox: {result.initial_bbox}")

    # Step 4: é—­ç¯éªŒè¯å¾ªç¯
    bbox_str = result.initial_bbox
    refined_answer = ""
    confidence = 0.0
    iteration = 0

    for retry in range(config.MAX_RETRIES + 1):
        iteration += 1
        print(f"\nğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£å°è¯•...")

        # è°ƒç”¨SAMåˆ†å‰²
        print(f"ğŸ“¦ è°ƒç”¨SAMåˆ†å‰²ï¼ŒBBox: {bbox_str}")
        if not call_sam(image_path, bbox_str, config,
                        save_segment=True, iteration=iteration):
            result.notes = f"SAMåˆ†å‰²å¤±è´¥ (è¿­ä»£{iteration})"
            print(f"âŒ SAMåˆ†å‰²å¤±è´¥")
            break

        result.sam_calls += 1

        # æ£€æŸ¥è¯æ®å›¾
        if not os.path.exists(config.TEMP_EVIDENCE_PATH):
            result.notes = f"è¯æ®å›¾æœªç”Ÿæˆ (è¿­ä»£{iteration})"
            print(f"âŒ è¯æ®å›¾æœªç”Ÿæˆ")
            break

        # è¯»å–è¯æ®å›¾
        try:
            evidence_size = os.path.getsize(config.TEMP_EVIDENCE_PATH)
            if evidence_size == 0:
                result.notes = f"è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶ (è¿­ä»£{iteration})"
                print(f"âŒ è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶")
                break

            with open(config.TEMP_EVIDENCE_PATH, "rb") as f:
                evidence_bytes = f.read()
            print(f"ğŸ“„ è¯æ®å›¾å¤§å°: {evidence_size} å­—èŠ‚")
        except Exception as e:
            result.notes = f"è¯»å–è¯æ®å›¾å¤±è´¥: {e}"
            print(f"âŒ è¯»å–è¯æ®å›¾å¤±è´¥: {e}")
            break

        # QwenåŸºäºè¯æ®å›¾é‡æ–°å›ç­”
        prompt2 = f"åªçœ‹è¿™å¼ è£å‰ªåçš„å›¾åƒï¼Œå›ç­”ï¼š{sample['question']}"
        print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º (åŸºäºè¯æ®å›¾): {prompt2}")

        refined_answer = call_qwen(prompt2, config.TEMP_EVIDENCE_PATH, config)
        result.qwen_calls += 1

        if not refined_answer:
            result.notes = f"Qwené‡ç­”å¤±è´¥ (è¿­ä»£{iteration})"
            print(f"âŒ Qwené‡ç­”å¤±è´¥")
            break

        print(f"ğŸ“¥ Qwenç²¾ç‚¼å›ç­”: {refined_answer}")

        # CLIPéªŒè¯
        confidence = call_clip(evidence_bytes, refined_answer, config)
        result.clip_calls += 1
        result.clip_scores[f"iteration_{iteration}"] = float(confidence)

        print(f"ğŸ¯ CLIPç½®ä¿¡åº¦: {confidence:.3f} (é˜ˆå€¼: {current_threshold:.3f})")

        if confidence >= current_threshold:
            result.refined_answer = refined_answer
            result.final_confidence = float(confidence)
            print(f"âœ… éªŒè¯é€šè¿‡!")
            break
        elif retry == 0:
            # ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾
            print(f"âš ï¸ ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾...")
            bbox_str = f"0,0,{img_w},{img_h}"
        else:
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥")

    result.iteration_count = iteration
    result.total_time = time.time() - start_time

    # å¦‚æœç²¾ç‚¼ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨åˆå§‹ç­”æ¡ˆ
    if not result.refined_answer and result.initial_answer:
        result.refined_answer = result.initial_answer
        # å¦‚æœæ²¡æœ‰CLIPéªŒè¯ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
        if result.final_confidence == 0.0:
            result.final_confidence = 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
        print(f"âš ï¸ ä½¿ç”¨åˆå§‹ç­”æ¡ˆä½œä¸ºç²¾ç‚¼ç­”æ¡ˆ")

    print(f"ğŸ’¡ æœ€ç»ˆç­”æ¡ˆ: {result.refined_answer}")
    print(f"ğŸ“Š æœ€ç»ˆç½®ä¿¡åº¦: {result.final_confidence:.3f}")

    # è¯„ä¼°å‡†ç¡®æ€§
    answer_to_evaluate = result.refined_answer if result.refined_answer else result.initial_answer
    result.accuracy, result.is_correct = calculate_accuracy(
        answer_to_evaluate,
        sample['answers']
    )

    # åˆ†æå¤±è´¥ç±»å‹
    if not result.is_correct:
        result.failure_type = analyze_failure_type(result, current_threshold)
        print(f"âŒ ç­”æ¡ˆé”™è¯¯ï¼Œå¤±è´¥ç±»å‹: {result.failure_type}")
    else:
        print(f"âœ… ç­”æ¡ˆæ­£ç¡®!")

    print(f"â±ï¸ å¤„ç†æ—¶é—´: {result.total_time:.2f}ç§’")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iteration_count}")
    print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡: SAM={result.sam_calls}, CLIP={result.clip_calls}, Qwen={result.qwen_calls}")

    # æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨
    print(f"\nğŸ”„ æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼...")
    new_threshold = threshold_manager.update(result.final_confidence, result.is_correct)
    print(f"ğŸ“ˆ æ›´æ–°åçš„é˜ˆå€¼: {new_threshold:.3f}")

    return result


def save_sam_segment(segment_data: bytes, original_image_path: str,
                     bbox_str: str, iteration: int, config: Config):
    """ä¿å­˜SAMåˆ†å‰²çš„å›¾åƒ"""
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    base_name = os.path.splitext(os.path.basename(original_image_path))[0]
    if iteration == 1:
        suffix = "initial"
    elif iteration == 2:
        suffix = "full"
    else:
        suffix = f"retry{iteration}"

    bbox_simple = bbox_str.replace(',', '_')
    filename = f"{base_name}_{suffix}_{bbox_simple}.png"
    filepath = os.path.join(config.SAM_SEGMENTS_DIR, filename)

    with open(filepath, "wb") as f:
        f.write(segment_data)

    return filepath


# ==================== å®éªŒç®¡ç† ====================
class ExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.results: List[ExperimentResult] = []
        self.stats = SystemStatistics()
        self.threshold_manager = AdaptiveThresholdManager(config)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}")

    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹è‡ªé€‚åº”é˜ˆå€¼å®éªŒ...")
        print(f"ğŸ“Š åˆå§‹é˜ˆå€¼: {self.config.INITIAL_CONFIDENCE_THRESHOLD}")
        print(f"ğŸ“Š é˜ˆå€¼èŒƒå›´: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]")

        # åŠ è½½æ•°æ®
        samples = load_textvqa_dataset(self.config)
        self.stats.total_samples = len(samples)

        # é€ä¸ªè¿è¡Œå®éªŒ
        for i, sample in enumerate(tqdm(samples, desc="è¿›è¡Œå®éªŒ")):
            print(f"\n{'='*80}")
            print(f"ğŸ“‹ æ ·æœ¬ {i + 1}/{len(samples)}")

            result = run_single_experiment(sample, self.config, self.threshold_manager)
            self.results.append(result)

            # æ›´æ–°ç»Ÿè®¡
            self.stats.correct_samples += 1 if result.is_correct else 0
            self.stats.total_iterations += result.iteration_count
            self.stats.total_sam_calls += result.sam_calls
            self.stats.total_clip_calls += result.clip_calls
            self.stats.total_qwen_calls += result.qwen_calls
            self.stats.total_time += result.total_time

            # æ›´æ–°é˜ˆå€¼ç»Ÿè®¡
            self.stats.threshold_stats['min_threshold'] = min(
                self.stats.threshold_stats['min_threshold'],
                result.used_threshold
            )
            self.stats.threshold_stats['max_threshold'] = max(
                self.stats.threshold_stats['max_threshold'],
                result.used_threshold
            )

            if result.failure_type:
                self.stats.failure_counts[result.failure_type] += 1

            # æ›´æ–°è‡ªé€‚åº”æ€§èƒ½ç»Ÿè®¡
            if result.is_correct and result.final_confidence < result.used_threshold:
                self.stats.adaptive_performance['correct_below_threshold'] += 1
                print(f"â„¹ï¸  æ ·æœ¬æ­£ç¡®ä½†ç½®ä¿¡åº¦ä½äºé˜ˆå€¼")
            elif not result.is_correct and result.final_confidence >= result.used_threshold:
                self.stats.adaptive_performance['wrong_above_threshold'] += 1
                print(f"â„¹ï¸  æ ·æœ¬é”™è¯¯ä½†ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼")

            # æ¯5ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡è¿›åº¦
            if (i + 1) % 5 == 0:
                self.save_results()
                print(f"\nğŸ’¾ å·²ä¿å­˜{len(self.results)}ä¸ªæ ·æœ¬çš„ç»“æœ")
                print(f"ğŸ“ˆ å½“å‰å‡†ç¡®ç‡: {self.stats.correct_samples}/{len(self.results)} ({self.stats.accuracy:.2%})")

        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        self._calculate_final_stats()

        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_results()
        self.threshold_manager.save_threshold_log(self.config.THRESHOLD_LOG)
        self.generate_report()
        print("\nâœ… è‡ªé€‚åº”é˜ˆå€¼å®éªŒå®Œæˆ!")

    def _calculate_final_stats(self):
        """è®¡ç®—æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—å¹³å‡é˜ˆå€¼
        thresholds = [r.used_threshold for r in self.results]
        self.stats.threshold_stats['avg_threshold'] = np.mean(thresholds)

        # è®¡ç®—é˜ˆå€¼è°ƒæ•´æ¬¡æ•°
        threshold_history = self.threshold_manager.threshold_history
        adjustments = sum(1 for i in range(1, len(threshold_history))
                         if abs(threshold_history[i] - threshold_history[i-1]) > 0.01)
        self.stats.threshold_stats['threshold_adjustments'] = adjustments

        # è®¡ç®—é˜ˆå€¼æœ‰æ•ˆæ€§
        total_samples = len(self.results)
        if total_samples > 0:
            effectiveness = (self.stats.correct_samples -
                           self.stats.adaptive_performance['wrong_above_threshold']) / total_samples
            self.stats.adaptive_performance['threshold_effectiveness'] = max(0, effectiveness)

        print(f"\nğŸ“Š æœ€ç»ˆé˜ˆå€¼ç»Ÿè®¡:")
        print(f"   å¹³å‡é˜ˆå€¼: {self.stats.threshold_stats['avg_threshold']:.3f}")
        print(f"   æœ€å°é˜ˆå€¼: {self.stats.threshold_stats['min_threshold']:.3f}")
        print(f"   æœ€å¤§é˜ˆå€¼: {self.stats.threshold_stats['max_threshold']:.3f}")
        print(f"   é˜ˆå€¼è°ƒæ•´æ¬¡æ•°: {self.stats.threshold_stats['threshold_adjustments']}")

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # è½¬æ¢ç»“æœä¸ºå­—å…¸
        results_list = []
        for r in self.results:
            result_dict = {
                'id': int(r.sample_id),
                'question': str(r.question),
                'image_file': str(r.image_file),
                'ground_truth': [str(ans) for ans in r.ground_truth_answers],
                'initial_answer': str(r.initial_answer),
                'initial_bbox': str(r.initial_bbox),
                'refined_answer': str(r.refined_answer),
                'confidence': float(r.final_confidence),
                'used_threshold': float(r.used_threshold),
                'clip_scores': {k: float(v) for k, v in r.clip_scores.items()},
                'is_correct': bool(r.is_correct),
                'accuracy': float(r.accuracy),
                'failure_type': str(r.failure_type),
                'iteration_count': int(r.iteration_count),
                'sam_calls': int(r.sam_calls),
                'clip_calls': int(r.clip_calls),
                'qwen_calls': int(r.qwen_calls),
                'time': float(r.total_time),
                'notes': str(r.notes)
            }
            results_list.append(result_dict)

        # è·å–é˜ˆå€¼ç»Ÿè®¡
        threshold_stats = self.threshold_manager.get_history_stats()

        results_dict = {
            'config': {
                'initial_threshold': float(self.config.INITIAL_CONFIDENCE_THRESHOLD),
                'min_threshold': float(self.config.MIN_THRESHOLD),
                'max_threshold': float(self.config.MAX_THRESHOLD),
                'window_size': int(self.config.ADAPTIVE_WINDOW_SIZE),
                'max_retries': int(self.config.MAX_RETRIES),
                'num_samples': int(self.config.NUM_SAMPLES),
                'random_seed': int(self.config.RANDOM_SEED)
            },
            'adaptive_threshold_stats': threshold_stats,
            'statistics': {
                'total_samples': int(self.stats.total_samples),
                'correct_samples': int(self.stats.correct_samples),
                'accuracy': float(self.stats.accuracy),
                'total_iterations': int(self.stats.total_iterations),
                'avg_iterations': float(self.stats.avg_iterations),
                'total_sam_calls': int(self.stats.total_sam_calls),
                'total_clip_calls': int(self.stats.total_clip_calls),
                'total_qwen_calls': int(self.stats.total_qwen_calls),
                'total_time': float(self.stats.total_time),
                'avg_time_per_sample': float(self.stats.avg_time_per_sample),
                'threshold_stats': self.stats.threshold_stats,
                'adaptive_performance': self.stats.adaptive_performance,
                'failure_counts': {k: int(v) for k, v in self.stats.failure_counts.items()}
            },
            'results': results_list
        }

        # ä¿å­˜JSON
        with open(self.config.RESULTS_JSON, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)

        # ä¿å­˜CSV
        with open(self.config.STATS_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ ·æœ¬ID', 'é—®é¢˜', 'å›¾åƒ', 'å‚è€ƒç­”æ¡ˆ',
                'åˆå§‹ç­”æ¡ˆ', 'ç²¾ç‚¼ç­”æ¡ˆ', 'ç½®ä¿¡åº¦', 'ä½¿ç”¨é˜ˆå€¼',
                'æ˜¯å¦æ­£ç¡®', 'å‡†ç¡®ç‡', 'å¤±è´¥ç±»å‹',
                'è¿­ä»£æ¬¡æ•°', 'SAMè°ƒç”¨', 'CLIPè°ƒç”¨', 'Qwenè°ƒç”¨',
                'æ—¶é—´(s)', 'å¤‡æ³¨'
            ])

            for r in self.results:
                writer.writerow([
                    int(r.sample_id),
                    str(r.question)[:50],
                    str(r.image_file),
                    '; '.join([str(ans) for ans in r.ground_truth_answers[:3]]),
                    str(r.initial_answer)[:30],
                    str(r.refined_answer)[:30],
                    f"{float(r.final_confidence):.3f}",
                    f"{float(r.used_threshold):.3f}",
                    "æ˜¯" if r.is_correct else "å¦",
                    f"{float(r.accuracy):.3f}",
                    str(r.failure_type),
                    int(r.iteration_count),
                    int(r.sam_calls),
                    int(r.clip_calls),
                    int(r.qwen_calls),
                    f"{float(r.total_time):.2f}",
                    str(r.notes)[:50]
                ])

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {self.config.OUTPUT_DIR}")

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        threshold_stats = self.threshold_manager.get_history_stats()

        report = f"""
# è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿå®éªŒæŠ¥å‘Š

## 1. å®éªŒæ¦‚è¿°
- **ç³»ç»Ÿç±»å‹**: è‡ªé€‚åº”é˜ˆå€¼é—­ç¯ç³»ç»Ÿ
- **æ•°æ®é›†**: TextVQA ({self.stats.total_samples}ä¸ªæ ·æœ¬)
- **é˜ˆå€¼ç­–ç•¥**: åŸºäºå†å²ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´
- **é˜ˆå€¼èŒƒå›´**: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]
- **åˆå§‹é˜ˆå€¼**: {self.config.INITIAL_CONFIDENCE_THRESHOLD}
- **æ»‘åŠ¨çª—å£**: {self.config.ADAPTIVE_WINDOW_SIZE}ä¸ªæ ·æœ¬
- **éšæœºç§å­**: {self.config.RANDOM_SEED}

## 2. ä¸»è¦ç»“æœ
- **æ€»ä½“å‡†ç¡®ç‡**: {self.stats.accuracy:.2%} ({self.stats.correct_samples}/{self.stats.total_samples})
- **å¹³å‡è¿­ä»£æ¬¡æ•°**: {self.stats.avg_iterations:.2f}
- **å¹³å‡å¤„ç†æ—¶é—´**: {self.stats.avg_time_per_sample:.2f}ç§’/æ ·æœ¬
- **æ€»å®éªŒæ—¶é—´**: {self.stats.total_time:.2f}ç§’

## 3. è‡ªé€‚åº”é˜ˆå€¼ç»Ÿè®¡
- **å¹³å‡é˜ˆå€¼**: {self.stats.threshold_stats['avg_threshold']:.3f}
- **æœ€å°é˜ˆå€¼**: {self.stats.threshold_stats['min_threshold']:.3f}
- **æœ€å¤§é˜ˆå€¼**: {self.stats.threshold_stats['max_threshold']:.3f}
- **é˜ˆå€¼è°ƒæ•´æ¬¡æ•°**: {self.stats.threshold_stats['threshold_adjustments']}
- **å¹³æ»‘ç½®ä¿¡åº¦**: {threshold_stats['smoothed_confidence']:.3f}
- **ç½®ä¿¡åº¦å‡å€¼**: {threshold_stats['mean_confidence']:.3f}
- **ç½®ä¿¡åº¦æ ‡å‡†å·®**: {threshold_stats['std_confidence']:.3f}

## 4. é˜ˆå€¼æ€§èƒ½åˆ†æ
- **é˜ˆå€¼æœ‰æ•ˆæ€§**: {self.stats.adaptive_performance['threshold_effectiveness']:.2%}
- **ä½äºé˜ˆå€¼ä½†æ­£ç¡®**: {self.stats.adaptive_performance['correct_below_threshold']}ä¸ªæ ·æœ¬
- **é«˜äºé˜ˆå€¼ä½†é”™è¯¯**: {self.stats.adaptive_performance['wrong_above_threshold']}ä¸ªæ ·æœ¬

## 5. å·¥å…·è°ƒç”¨ç»Ÿè®¡
- SAMè°ƒç”¨æ¬¡æ•°: {self.stats.total_sam_calls}
- CLIPè°ƒç”¨æ¬¡æ•°: {self.stats.total_clip_calls}
- Qwenè°ƒç”¨æ¬¡æ•°: {self.stats.total_qwen_calls}

## 6. å¤±è´¥åˆ†æ
"""

        total_failures = sum(self.stats.failure_counts.values())
        for failure_type, count in self.stats.failure_counts.items():
            if count > 0:
                percentage = count / total_failures * 100 if total_failures > 0 else 0
                report += f"- **{failure_type}**: {count}æ¬¡ ({percentage:.1f}%)\n"

        report += """
## 7. è‡ªé€‚åº”é˜ˆå€¼ç®—æ³•åˆ†æ

### 7.1 è°ƒæ•´ç­–ç•¥
1. **ç½®ä¿¡åº¦æ™®éè¾ƒé«˜æ—¶**: æé«˜é˜ˆå€¼ä»¥æé«˜ç²¾åº¦
2. **ç½®ä¿¡åº¦æ™®éè¾ƒä½æ—¶**: é™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
3. **ç½®ä¿¡åº¦ä¸ç¨³å®šæ—¶**: ç¨å¾®æé«˜é˜ˆå€¼ä»¥å‡å°‘è¯¯åˆ¤
4. **åŸºäºå¹³æ»‘ç½®ä¿¡åº¦**: è¿›è¡Œå¾®è°ƒä»¥å¹³è¡¡ç²¾åº¦å’Œå¬å›ç‡

### 7.2 é˜ˆå€¼æ¼”åŒ–è¶‹åŠ¿
- é˜ˆå€¼æ ¹æ®å†å²ç½®ä¿¡åº¦åˆ†å¸ƒåŠ¨æ€è°ƒæ•´
- éšç€æ ·æœ¬å¢åŠ ï¼Œé˜ˆå€¼é€æ¸ç¨³å®šåœ¨æœ€ä¼˜å€¼é™„è¿‘
- ç³»ç»Ÿèƒ½å¤Ÿé€‚åº”ä¸åŒéš¾åº¦çš„æ ·æœ¬

## 8. ä¸å›ºå®šé˜ˆå€¼ç³»ç»Ÿå¯¹æ¯”ä¼˜åŠ¿
1. **é€‚åº”æ€§**: èƒ½å¤Ÿæ ¹æ®æ ·æœ¬éš¾åº¦è‡ªåŠ¨è°ƒæ•´é˜ˆå€¼
2. **é²æ£’æ€§**: å¯¹ä¸åŒç±»å‹çš„VQAé—®é¢˜å…·æœ‰æ›´å¥½çš„é€‚åº”æ€§
3. **å¹³è¡¡æ€§**: åœ¨ç²¾åº¦å’Œå¬å›ç‡ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡
4. **è‡ªå­¦ä¹ **: ç³»ç»Ÿéšç€å¤„ç†æ ·æœ¬å¢å¤šè€Œä¸æ–­ä¼˜åŒ–

## 9. æ”¹è¿›å»ºè®®
1. **æ›´å¤æ‚çš„è°ƒæ•´ç­–ç•¥**: è€ƒè™‘æ ·æœ¬éš¾åº¦ä¼°è®¡
2. **å¤šç»´åº¦ç‰¹å¾**: ç»“åˆç­”æ¡ˆé•¿åº¦ã€é—®é¢˜ç±»å‹ç­‰ç‰¹å¾
3. **åœ¨çº¿å­¦ä¹ **: ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–é˜ˆå€¼è°ƒæ•´ç­–ç•¥
4. **ç½®ä¿¡åº¦æ ¡å‡†**: æ”¹è¿›CLIPè¾“å‡ºçš„ç½®ä¿¡åº¦æ ¡å‡†

## 10. æ ·æœ¬ç¤ºä¾‹
"""

        # æ·»åŠ 3ä¸ªä»£è¡¨æ€§ç¤ºä¾‹
        for i, r in enumerate(self.results[:3]):
            report += f"""
### ç¤ºä¾‹ {i + 1}
- **æ ·æœ¬ID**: {r.sample_id}
- **é—®é¢˜**: {r.question}
- **å›¾åƒ**: {r.image_file}
- **ä½¿ç”¨é˜ˆå€¼**: {r.used_threshold:.3f}
- **CLIPç½®ä¿¡åº¦**: {r.final_confidence:.3f}
- **ç²¾ç‚¼ç­”æ¡ˆ**: {r.refined_answer}
- **å‚è€ƒç­”æ¡ˆ**: {', '.join(r.ground_truth_answers[:3])}
- **æ˜¯å¦æ­£ç¡®**: {'æ˜¯' if r.is_correct else 'å¦'}
- **å¤„ç†æ—¶é—´**: {r.total_time:.2f}ç§’
- **è¿­ä»£æ¬¡æ•°**: {r.iteration_count}
"""

        report_path = os.path.join(self.config.OUTPUT_DIR, "adaptive_experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ğŸ“Š å®éªŒæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")


# ==================== ä¸»ç¨‹åº ====================
def main():
    # åˆå§‹åŒ–é…ç½®
    config = Config()

    # ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•éƒ½å­˜åœ¨
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # è¿è¡Œä¸»å®éªŒ
    print("=" * 80)
    print("ğŸ¤– è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿ")
    print("=" * 80)

    manager = ExperimentManager(config)
    manager.run_experiments()

    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {config.OUTPUT_DIR}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {config.RESULTS_JSON}")
    print(f"ğŸ“Š ç»Ÿè®¡è¡¨æ ¼: {config.STATS_CSV}")
    print(f"ğŸ“ˆ é˜ˆå€¼æ¼”åŒ–: {config.THRESHOLD_LOG}")
    print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {config.OUTPUT_DIR}/adaptive_experiment_report.md")
    print(f"ğŸ–¼ï¸  SAMåˆ†å‰²å›¾åƒ: {config.SAM_SEGMENTS_DIR}")


if __name__ == "__main__":
    main()

