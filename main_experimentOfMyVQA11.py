'''
2.è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿ
åŸºäºå†å²ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´é˜ˆå€¼
æ–°ä¸€ç‰ˆçš„ä»£ç 
'''

import os
import json
import time
import csv
import numpy as np
from PIL import Image
import requests
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Tuple, Any, Optional
from tqdm import tqdm
import re
import base64
from io import BytesIO
from collections import deque
import statistics


# ==================== é…ç½® ====================
@dataclass
class Config:
    # æœåŠ¡å™¨é…ç½®
    SERVER_IP = "è¿™æ˜¯æˆ‘çš„æœåŠ¡å™¨IPåœ°å€ï¼Œæˆ‘éšè—äº†"
    QWEN_URL = f"http://{SERVER_IP}:8020/chat_vl"
    CLIP_URL = f"http://{SERVER_IP}:8021/clip/score"
    SAM_URL = f"http://{SERVER_IP}:8022/segment_by_bbox"

    # æ•°æ®é›†è·¯å¾„
    DATA_ROOT = r"C:\Users\kuanzhang\Desktop\courseB\fuwuqisanhaoji\MyVQA\combined_dataset"
    METADATA_PATH = os.path.join(DATA_ROOT, "combined_metadata.json")
    IMAGE_DIR = os.path.join(DATA_ROOT, "images")

    # å®éªŒå‚æ•°
    MAX_RETRIES = 2
    INITIAL_CONFIDENCE_THRESHOLD = 0.2  # åˆå§‹é˜ˆå€¼
    TEMP_EVIDENCE_PATH = "./temp_evidence.png"

    # è‡ªé€‚åº”é˜ˆå€¼å‚æ•°
    ADAPTIVE_WINDOW_SIZE = 20  # æ»‘åŠ¨çª—å£å¤§å°
    MIN_THRESHOLD = 0.1  # æœ€å°é˜ˆå€¼
    MAX_THRESHOLD = 0.5  # æœ€å¤§é˜ˆå€¼
    THRESHOLD_ADJUSTMENT_STEP = 0.05  # è°ƒæ•´æ­¥é•¿
    CONFIDENCE_SMOOTHING_ALPHA = 0.3  # æŒ‡æ•°å¹³æ»‘ç³»æ•°

    # æ–°å¢ï¼šé˜ˆå€¼æ›´æ–°ç­–ç•¥å‚æ•°
    UPDATE_ONLY_ON_VERIFIED = True  # ä»…åœ¨éªŒè¯é€šè¿‡çš„æ ·æœ¬ä¸Šæ›´æ–°é˜ˆå€¼
    MIN_CONFIDENCE_FOR_UPDATE = 0.15  # å‚ä¸é˜ˆå€¼æ›´æ–°çš„æœ€å°ç½®ä¿¡åº¦

    # è¾“å‡ºè·¯å¾„
    OUTPUT_DIR = "./results_adaptive_new"
    RESULTS_JSON = os.path.join(OUTPUT_DIR, "results_adaptive.json")
    STATS_CSV = os.path.join(OUTPUT_DIR, "statistics_adaptive.csv")
    THRESHOLD_LOG = os.path.join(OUTPUT_DIR, "threshold_evolution.csv")
    SAM_SEGMENTS_DIR = os.path.join(OUTPUT_DIR, "sam_segments")

    # å®éªŒè®¾ç½®
    NUM_SAMPLES = 110
    RANDOM_SEED = 42


# ==================== è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨ ====================
class AdaptiveThresholdManager:
    """ç®¡ç†è‡ªé€‚åº”é˜ˆå€¼ï¼ŒåŸºäºéªŒè¯å¾ªç¯çš„å®é™…è¡¨ç°åŠ¨æ€è°ƒæ•´"""

    def __init__(self, config: Config):
        self.config = config
        self.current_threshold = config.INITIAL_CONFIDENCE_THRESHOLD
        self.confidence_history = deque(maxlen=config.ADAPTIVE_WINDOW_SIZE)
        self.threshold_history = []
        self.performance_history = []  # è®°å½•æ­£ç¡®/é”™è¯¯
        self.verified_samples = []  # è®°å½•æ˜¯å¦é€šè¿‡éªŒè¯
        self.smoothed_confidence = 0.0

        # æ–°å¢ï¼šè®°å½•è¯¦ç»†éªŒè¯ä¿¡æ¯
        self.verification_details = []  # æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†éªŒè¯ä¿¡æ¯

        # æ–°å¢ï¼šè®°å½•ç”¨äºé˜ˆå€¼æ›´æ–°çš„æ ·æœ¬ä¿¡æ¯
        self.update_samples = []  # è®°å½•å“ªäº›æ ·æœ¬ç”¨äºæ›´æ–°é˜ˆå€¼

        print(f"ğŸ“Š åˆå§‹åŒ–è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨")
        print(f"  åˆå§‹é˜ˆå€¼: {self.current_threshold:.3f}")
        print(f"  é˜ˆå€¼èŒƒå›´: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]")
        print(f"  æ»‘åŠ¨çª—å£å¤§å°: {self.config.ADAPTIVE_WINDOW_SIZE}")
        print(f"  ä»…åœ¨éªŒè¯é€šè¿‡æ—¶æ›´æ–°: {self.config.UPDATE_ONLY_ON_VERIFIED}")

    def get_threshold(self) -> float:
        """è·å–å½“å‰é˜ˆå€¼"""
        return self.current_threshold

    def update(self, verification_details: Dict[str, Any]):
        """åŸºäºéªŒè¯å¾ªç¯çš„è¯¦ç»†ç»“æœæ›´æ–°é˜ˆå€¼"""
        confidence = verification_details.get('max_confidence', 0.0)
        is_correct = verification_details.get('is_correct', False)
        passed_verification = verification_details.get('passed_verification', False)
        used_threshold = verification_details.get('used_threshold', self.current_threshold)

        # è®°å½•è¯¦ç»†éªŒè¯ä¿¡æ¯
        self.verification_details.append(verification_details)
        self.verified_samples.append(passed_verification)

        print(f"ğŸ“ˆ éªŒè¯è¯¦æƒ…: æœ€å¤§ç½®ä¿¡åº¦={confidence:.3f}, æ˜¯å¦é€šè¿‡éªŒè¯={passed_verification}, æ˜¯å¦æ­£ç¡®={is_correct}")

        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ›´æ–°é˜ˆå€¼
        should_update = True
        update_reason = ""

        if self.config.UPDATE_ONLY_ON_VERIFIED and not passed_verification:
            should_update = False
            update_reason = "æ ·æœ¬æœªé€šè¿‡éªŒè¯"

        if confidence < self.config.MIN_CONFIDENCE_FOR_UPDATE:
            should_update = False
            update_reason = f"ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.3f} < {self.config.MIN_CONFIDENCE_FOR_UPDATE})"

        if not should_update:
            print(f"  è·³è¿‡é˜ˆå€¼æ›´æ–°: {update_reason}")
            # è®°å½•é˜ˆå€¼å†å²ï¼ˆå³ä½¿ä¸æ›´æ–°ï¼Œä¹Ÿè¦è®°å½•å½“å‰é˜ˆå€¼ï¼‰
            self.threshold_history.append(self.current_threshold)
            return self.current_threshold

        # è®°å½•è¯¥æ ·æœ¬ç”¨äºæ›´æ–°é˜ˆå€¼
        self.update_samples.append(True)

        # æ›´æ–°å†å²è®°å½•
        self.confidence_history.append(confidence)
        self.performance_history.append(is_correct)
        self.threshold_history.append(self.current_threshold)

        # è®¡ç®—æŒ‡æ•°å¹³æ»‘çš„ç½®ä¿¡åº¦
        if self.smoothed_confidence == 0:
            self.smoothed_confidence = confidence
        else:
            alpha = self.config.CONFIDENCE_SMOOTHING_ALPHA
            self.smoothed_confidence = (alpha * confidence +
                                       (1 - alpha) * self.smoothed_confidence)

        print(f"  å†å²ç½®ä¿¡åº¦çª—å£: {len(self.confidence_history)}/{self.config.ADAPTIVE_WINDOW_SIZE}")
        print(f"  å¹³æ»‘ç½®ä¿¡åº¦: {self.smoothed_confidence:.3f}")

        # å¦‚æœæœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œè°ƒæ•´é˜ˆå€¼
        if len(self.confidence_history) >= 5:
            old_threshold = self.current_threshold
            self._adjust_threshold_based_on_verification()

            # è¾“å‡ºè°ƒæ•´ä¿¡æ¯
            if abs(old_threshold - self.current_threshold) > 0.001:
                print(f"ğŸ”„ é˜ˆå€¼è°ƒæ•´: {old_threshold:.3f} â†’ {self.current_threshold:.3f}")

        return self.current_threshold

    def _adjust_threshold_based_on_verification(self):
        """åŸºäºéªŒè¯è¡¨ç°è°ƒæ•´é˜ˆå€¼"""
        if len(self.confidence_history) < 5:
            return

        # ä½¿ç”¨confidence_historyä¸­çš„æ ·æœ¬æ¥è°ƒæ•´é˜ˆå€¼
        # æ³¨æ„ï¼šconfidence_historyä¸­åªåŒ…å«ç”¨äºæ›´æ–°çš„æ ·æœ¬
        verified_confidences = list(self.confidence_history)
        verified_performances = list(self.performance_history)

        # è®¡ç®—ç»Ÿè®¡é‡
        window_size = min(10, len(verified_confidences))
        recent_confidences = verified_confidences[-window_size:]
        mean_confidence = np.mean(recent_confidences)
        std_confidence = np.std(recent_confidences)

        recent_performances = verified_performances[-window_size:] if len(verified_performances) >= window_size else verified_performances
        if recent_performances:
            recent_accuracy = sum(recent_performances) / len(recent_performances)
        else:
            recent_accuracy = 0.5

        print(f"ğŸ“Š éªŒè¯æ ·æœ¬ç»Ÿè®¡: å¹³å‡ç½®ä¿¡åº¦={mean_confidence:.3f}, æ ‡å‡†å·®={std_confidence:.3f}, æœ€è¿‘æ­£ç¡®ç‡={recent_accuracy:.2%}")

        old_threshold = self.current_threshold

        # ç­–ç•¥1: å¦‚æœéªŒè¯é€šè¿‡ä¸”æ­£ç¡®ç‡é«˜ï¼Œä½†ç½®ä¿¡åº¦æ™®éæ¥è¿‘é˜ˆå€¼ï¼Œè¯´æ˜é˜ˆå€¼è®¾ç½®åˆé€‚
        if recent_accuracy > 0.7 and mean_confidence > self.current_threshold * 1.2:
            # ç¨å¾®æé«˜é˜ˆå€¼ä»¥å¢åŠ ç²¾åº¦
            self.current_threshold = min(
                self.current_threshold + self.config.THRESHOLD_ADJUSTMENT_STEP * 0.5,
                self.config.MAX_THRESHOLD
            )
            print(f"  ç­–ç•¥1: é«˜æ­£ç¡®ç‡é«˜ç½®ä¿¡åº¦ â†’ ç¨å¾®æé«˜é˜ˆå€¼")

        # ç­–ç•¥2: å¦‚æœéªŒè¯é€šè¿‡ä½†æ­£ç¡®ç‡ä½ï¼Œè¯´æ˜é˜ˆå€¼å¤ªä½ï¼Œéœ€è¦æé«˜
        elif recent_accuracy < 0.3:
            self.current_threshold = min(
                self.current_threshold + self.config.THRESHOLD_ADJUSTMENT_STEP,
                self.config.MAX_THRESHOLD
            )
            print(f"  ç­–ç•¥2: ä½æ­£ç¡®ç‡ â†’ æé«˜é˜ˆå€¼")

        # ç­–ç•¥3: å¦‚æœéªŒè¯é€šè¿‡å°‘ä½†ç½®ä¿¡åº¦é€‚ä¸­ï¼Œå¯èƒ½é˜ˆå€¼å¤ªé«˜
        # è®¡ç®—éªŒè¯é€šè¿‡ç‡ï¼ˆåŸºäºæ‰€æœ‰æ ·æœ¬ï¼‰
        if len(self.verified_samples) > 0:
            verification_rate = sum(self.verified_samples) / len(self.verified_samples)
            if verification_rate < 0.3 and mean_confidence > 0.25:
                self.current_threshold = max(
                    self.current_threshold - self.config.THRESHOLD_ADJUSTMENT_STEP,
                    self.config.MIN_THRESHOLD
                )
                print(f"  ç­–ç•¥3: ä½éªŒè¯ç‡ä½†ä¸­ç­‰ç½®ä¿¡åº¦ â†’ é™ä½é˜ˆå€¼")

        # ç­–ç•¥4: åŸºäºå¹³æ»‘ç½®ä¿¡åº¦å¾®è°ƒ
        if self.smoothed_confidence > 0.35 and len(self.confidence_history) > 5:
            self.current_threshold = min(
                self.current_threshold + 0.02,
                self.config.MAX_THRESHOLD
            )
        elif self.smoothed_confidence < 0.15 and len(self.confidence_history) > 5:
            self.current_threshold = max(
                self.current_threshold - 0.02,
                self.config.MIN_THRESHOLD
            )

        # ç¡®ä¿é˜ˆå€¼åœ¨èŒƒå›´å†…
        self.current_threshold = max(
            self.config.MIN_THRESHOLD,
            min(self.current_threshold, self.config.MAX_THRESHOLD)
        )

    def get_history_stats(self) -> Dict[str, Any]:
        """è·å–å†å²ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—é€šè¿‡éªŒè¯çš„æ ·æœ¬ç»Ÿè®¡
        verified_confidences = list(self.confidence_history)

        return {
            "current_threshold": self.current_threshold,
            "history_size": len(self.confidence_history),
            "total_samples": len(self.verification_details),
            "verified_samples": sum(self.verified_samples),
            "verification_rate": sum(self.verified_samples) / len(self.verified_samples) if self.verified_samples else 0,
            "mean_confidence": np.mean(verified_confidences) if verified_confidences else 0,
            "std_confidence": np.std(verified_confidences) if len(verified_confidences) > 1 else 0,
            "threshold_history": self.threshold_history.copy(),
            "smoothed_confidence": self.smoothed_confidence,
            "performance_rate": np.mean(self.performance_history) if self.performance_history else 0
        }

    def save_threshold_log(self, filepath: str):
        """ä¿å­˜é˜ˆå€¼æ¼”åŒ–æ—¥å¿—"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['æ ·æœ¬ç´¢å¼•', 'é˜ˆå€¼', 'æœ€å¤§ç½®ä¿¡åº¦', 'æ˜¯å¦é€šè¿‡éªŒè¯', 'æ˜¯å¦æ­£ç¡®', 'å¹³æ»‘ç½®ä¿¡åº¦', 'éªŒè¯çŠ¶æ€', 'æ˜¯å¦ç”¨äºæ›´æ–°'])

            for i in range(len(self.threshold_history)):
                if i < len(self.verification_details):
                    detail = self.verification_details[i]
                    confidence = detail.get('max_confidence', 0)
                    passed = detail.get('passed_verification', False)
                    is_correct = detail.get('is_correct', False)
                    status = "é€šè¿‡éªŒè¯" if passed else "æœªé€šè¿‡"
                    used_for_update = i < len(self.update_samples) and self.update_samples[i]
                else:
                    confidence = 0
                    passed = False
                    is_correct = False
                    status = "N/A"
                    used_for_update = False

                smoothed = self.smoothed_confidence if i == len(self.threshold_history) - 1 else 0
                writer.writerow([
                    i + 1,
                    f"{self.threshold_history[i]:.3f}",
                    f"{confidence:.3f}",
                    "æ˜¯" if passed else "å¦",
                    "æ˜¯" if is_correct else "å¦",
                    f"{smoothed:.3f}",
                    status,
                    "æ˜¯" if used_for_update else "å¦"
                ])

        print(f"ğŸ“ˆ é˜ˆå€¼æ¼”åŒ–æ—¥å¿—å·²ä¿å­˜: {filepath}")


# ==================== æ•°æ®ç»“æ„ ====================
@dataclass
class ExperimentResult:
    sample_id: int
    image_file: str
    question: str
    ground_truth_answers: List[str]

    # ç³»ç»Ÿè¾“å‡º
    initial_answer: str = ""
    initial_bbox: str = ""
    refined_answer: str = ""
    final_confidence: float = 0.0
    max_iteration_confidence: float = 0.0  # æ–°å¢ï¼šè®°å½•æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦
    clip_scores: Dict[str, float] = None
    used_threshold: float = 0.0

    # æ–°å¢ï¼šéªŒè¯çŠ¶æ€
    passed_verification: bool = False  # æ˜¯å¦é€šè¿‡éªŒè¯å¾ªç¯
    verification_iteration: int = 0  # é€šè¿‡éªŒè¯çš„è¿­ä»£æ¬¡æ•°ï¼ˆ0è¡¨ç¤ºæœªé€šè¿‡ï¼‰

    # æ€§èƒ½æŒ‡æ ‡
    iteration_count: int = 0
    sam_calls: int = 0
    clip_calls: int = 0
    qwen_calls: int = 0
    total_time: float = 0.0

    # è¯„ä¼°
    accuracy: float = 0.0
    is_correct: bool = False
    failure_type: str = ""
    notes: str = ""

    def __post_init__(self):
        if self.clip_scores is None:
            self.clip_scores = {}


@dataclass
class SystemStatistics:
    total_samples: int = 0
    correct_samples: int = 0
    verified_samples: int = 0  # æ–°å¢ï¼šé€šè¿‡éªŒè¯çš„æ ·æœ¬æ•°
    total_iterations: int = 0
    total_sam_calls: int = 0
    total_clip_calls: int = 0
    total_qwen_calls: int = 0
    total_time: float = 0.0

    # é˜ˆå€¼ç›¸å…³ç»Ÿè®¡
    threshold_stats: Dict[str, float] = None
    adaptive_performance: Dict[str, float] = None
    verification_stats: Dict[str, float] = None  # æ–°å¢ï¼šéªŒè¯ç»Ÿè®¡

    # æŒ‰å¤±è´¥ç±»å‹ç»Ÿè®¡
    failure_counts: Dict[str, int] = None

    def __post_init__(self):
        if self.failure_counts is None:
            self.failure_counts = {
                "verification_failure": 0,  # éªŒè¯å¤±è´¥
                "location_failure": 0,      # å®šä½å¤±è´¥
                "reasoning_failure": 0,     # æ¨ç†å¤±è´¥
                "other": 0
            }
        if self.threshold_stats is None:
            self.threshold_stats = {
                "min_threshold": 1.0,
                "max_threshold": 0.0,
                "avg_threshold": 0.0,
                "threshold_adjustments": 0
            }
        if self.adaptive_performance is None:
            self.adaptive_performance = {
                "verified_correct": 0,      # éªŒè¯é€šè¿‡ä¸”æ­£ç¡®
                "verified_wrong": 0,        # éªŒè¯é€šè¿‡ä½†é”™è¯¯
                "unverified_correct": 0,    # æœªéªŒè¯ä½†æ­£ç¡®ï¼ˆå…œåº•æ­£ç¡®ï¼‰
                "unverified_wrong": 0,      # æœªéªŒè¯ä¸”é”™è¯¯
                "threshold_effectiveness": 0.0
            }
        if self.verification_stats is None:
            self.verification_stats = {
                "verification_rate": 0.0,   # éªŒè¯é€šè¿‡ç‡
                "avg_verified_confidence": 0.0,  # éªŒè¯é€šè¿‡çš„å¹³å‡ç½®ä¿¡åº¦
                "avg_unverified_confidence": 0.0  # æœªéªŒè¯çš„å¹³å‡ç½®ä¿¡åº¦
            }

    @property
    def accuracy(self) -> float:
        return self.correct_samples / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_iterations(self) -> float:
        return self.total_iterations / self.total_samples if self.total_samples > 0 else 0

    @property
    def avg_time_per_sample(self) -> float:
        return self.total_time / self.total_samples if self.total_samples > 0 else 0


# ==================== å·¥å…·å‡½æ•° ====================
def load_textvqa_dataset(config: Config) -> List[Dict]:
    """åŠ è½½MyVQAæ•°æ®é›†"""
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†: {config.METADATA_PATH}")

    try:
        with open(config.METADATA_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if not isinstance(data, list):
            print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯: æœŸæœ›åˆ—è¡¨ï¼Œä½†å¾—åˆ° {type(data)}")
            return []

        # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆç¡®ä¿å¯å¤ç°ï¼‰
        np.random.seed(config.RANDOM_SEED)
        selected_indices = np.random.choice(len(data), min(config.NUM_SAMPLES, len(data)), replace=False)

        samples = []
        for idx in selected_indices:
            sample = data[idx]
            sample['id'] = idx
            samples.append(sample)

        print(f"ğŸ“Š åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
        return samples

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {config.METADATA_PATH}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        return []
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}")
        return []


def image_to_base64(image_path: str, max_size=(512, 512)) -> str:
    """å›¾åƒè½¬Base64"""
    try:
        img = Image.open(image_path)
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
        img.thumbnail(max_size)
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ å›¾åƒè½¬Base64å¤±è´¥: {e}")
        return ""


def call_qwen(prompt: str, image_path: str = None, config: Config = None) -> str:
    """è°ƒç”¨Qwen-VLæœåŠ¡"""
    try:
        payload = {"prompt": prompt}
        if image_path and os.path.exists(image_path):
            print(f"ğŸ“¤ å‘é€å›¾åƒ: {os.path.basename(image_path)}")
            payload["image_url"] = image_to_base64(image_path)

        response = requests.post(config.QWEN_URL, json=payload, timeout=120)

        print(f"ğŸ“¡ Qwenå“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code == 200:
            res = response.json()
            print(f"ğŸ“¥ QwenåŸå§‹å“åº”: {res}")
            return res.get("response", "").strip()
        else:
            print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except requests.exceptions.Timeout:
        print("â° Qwenè°ƒç”¨è¶…æ—¶")
    except Exception as e:
        print(f"ğŸ’¥ Qwenè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return ""


def call_sam(image_path: str, bbox_str: str, config: Config,
             save_segment: bool = True, iteration: int = 1) -> bool:
    """è°ƒç”¨SAMæœåŠ¡"""
    try:
        with open(image_path, 'rb') as f:
            files = {'image': f}
            data = {'bbox': bbox_str}
            response = requests.post(config.SAM_URL, files=files, data=data, timeout=30)

            if response.status_code == 200:
                segment_data = response.content

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                with open(config.TEMP_EVIDENCE_PATH, "wb") as out:
                    out.write(segment_data)

                # ä¿å­˜åˆ†å‰²å›¾åƒ
                if save_segment:
                    segment_path = save_sam_segment(
                        segment_data, image_path, bbox_str, iteration, config
                    )
                    print(f"ğŸ’¾ SAMåˆ†å‰²å›¾åƒå·²ä¿å­˜: {segment_path}")

                return True
            else:
                print(f"âŒ SAMè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ SAMè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return False


def call_clip(image_bytes: bytes, text_label: str, config: Config) -> float:
    """è°ƒç”¨CLIPæœåŠ¡ï¼Œè¿”å›æœ€é«˜ç›¸ä¼¼åº¦"""
    files = {'imagefile': ('evidence.png', image_bytes, 'image/png')}
    data = {'text': text_label, 'temperature': 100.0}

    try:
        print(f"ğŸ“¤ è°ƒç”¨CLIPéªŒè¯ï¼Œæ–‡æœ¬æ ‡ç­¾: {text_label[:30]}...")
        response = requests.post(config.CLIP_URL, files=files, data=data, timeout=10)
        if response.status_code == 200:
            res = response.json()
            if res.get('results'):
                # è¿”å›æ‰€æœ‰æ ‡ç­¾ä¸­çš„æœ€é«˜ç›¸ä¼¼åº¦
                similarities = [v['similarity'] for v in res['results'].values()]
                max_similarity = float(max(similarities)) if similarities else 0.0
                print(f"ğŸ“¥ CLIPè¿”å›ç›¸ä¼¼åº¦: {max_similarity:.3f}")
                return max_similarity
        else:
            print(f"âŒ CLIPè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {response.text}")
    except Exception as e:
        print(f"ğŸ’¥ CLIPè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
    return 0.0


def extract_bbox_from_text(text: str, img_w: int, img_h: int) -> str:
    """ä»æ–‡æœ¬ä¸­æå–bboxåæ ‡"""
    patterns = [
        r'\((\d+)\s*[,ï¼Œ]\s*(\d+)\)\s*\((\d+)\s*[,ï¼Œ]\s*(\d+)\)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s+(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[,ï¼Œ]\s*(\d+)',
        r'åæ ‡[ï¼š:]?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?\s*\(?(\d+)\s*[,ï¼Œ]\s*(\d+)\)?',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            x1, y1, x2, y2 = map(int, match.groups())
            x1, x2 = sorted([max(0, min(img_w, x)) for x in (x1, x2)])
            y1, y2 = sorted([max(0, min(img_h, y)) for y in (y1, y2)])
            return f"{x1},{y1},{x2},{y2}"

    return f"0,0,{img_w},{img_h}"


def normalize_answer(answer: str) -> str:
    """æ ‡å‡†åŒ–ç­”æ¡ˆ"""
    if not answer:
        return ""
    answer = answer.lower()
    answer = re.sub(r'[^\w\s]', '', answer)
    answer = ' '.join(answer.split())
    return answer


def calculate_accuracy(predicted_answer: str, ground_truths: List[str]) -> Tuple[float, bool]:
    """è®¡ç®—ç­”æ¡ˆå‡†ç¡®æ€§"""
    if not predicted_answer:
        return 0.0, False

    pred_normalized = normalize_answer(predicted_answer)

    for truth in ground_truths:
        if not truth:
            continue

        truth_normalized = normalize_answer(truth)

        # ç²¾ç¡®åŒ¹é…
        if pred_normalized == truth_normalized:
            return 1.0, True

        # åŒ…å«åŒ¹é…
        if truth_normalized in pred_normalized or pred_normalized in truth_normalized:
            return 1.0, True

        # æ•°å­—æå–åŒ¹é…
        pred_digits = ''.join(filter(str.isdigit, pred_normalized))
        truth_digits = ''.join(filter(str.isdigit, truth_normalized))
        if pred_digits and pred_digits == truth_digits:
            return 1.0, True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®å“ç‰Œ/åç§°
        common_brands = ['yamaha', 'red', 'mike lee', 'aj52uyv']
        for brand in common_brands:
            if brand in pred_normalized and brand in truth_normalized:
                return 1.0, True

    return 0.0, False


def analyze_failure_type(result: ExperimentResult, threshold: float) -> str:
    """åˆ†æå¤±è´¥ç±»å‹"""
    if not result.passed_verification and result.final_confidence < threshold:
        return "verification_failure"
    elif result.iteration_count == 0:
        return "location_failure"
    elif "æ— æ³•" in result.refined_answer or "ä¸èƒ½" in result.refined_answer:
        return "reasoning_failure"
    else:
        return "other"


def save_sam_segment(segment_data: bytes, original_image_path: str,
                     bbox_str: str, iteration: int, config: Config) -> str:
    """ä¿å­˜SAMåˆ†å‰²çš„å›¾åƒ"""
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    base_name = os.path.splitext(os.path.basename(original_image_path))[0]
    if iteration == 1:
        suffix = "initial"
    elif iteration == 2:
        suffix = "full"
    else:
        suffix = f"retry{iteration}"

    bbox_simple = bbox_str.replace(',', '_')
    filename = f"{base_name}_{suffix}_{bbox_simple}.png"
    filepath = os.path.join(config.SAM_SEGMENTS_DIR, filename)

    with open(filepath, "wb") as f:
        f.write(segment_data)

    return filepath


# ==================== ä¸»å®éªŒæµç¨‹ ====================
def run_single_experiment(sample: Dict, config: Config,
                         threshold_manager: AdaptiveThresholdManager) -> ExperimentResult:
    """è¿è¡Œå•ä¸ªæ ·æœ¬çš„å®éªŒ"""
    print(f"\n{'='*60}")
    print(f"ğŸ” å¼€å§‹å¤„ç†æ ·æœ¬ ID: {sample['id']}")
    print(f"ğŸ“· å›¾åƒ: {sample['image_file']}")
    print(f"â“ é—®é¢˜: {sample['question']}")
    print(f"ğŸ“ å‚è€ƒç­”æ¡ˆ: {sample['answers'][:3]}")

    result = ExperimentResult(
        sample_id=sample['id'],
        image_file=sample['image_file'],
        question=sample['question'],
        ground_truth_answers=sample['answers']
    )

    start_time = time.time()
    image_path = os.path.join(config.IMAGE_DIR, sample['image_file'])

    # Step 1: è·å–å›¾åƒå°ºå¯¸
    print(f"ğŸ“ è·å–å›¾åƒå°ºå¯¸...")
    try:
        with Image.open(image_path) as img:
            img_w, img_h = img.size
            print(f"   å›¾åƒå°ºå¯¸: {img_w} x {img_h}")
    except Exception as e:
        result.notes = f"æ— æ³•æ‰“å¼€å›¾åƒ: {e}"
        result.total_time = time.time() - start_time
        print(f"âŒ æ— æ³•æ‰“å¼€å›¾åƒ: {e}")
        return result

    # Step 2: è·å–å½“å‰é˜ˆå€¼
    current_threshold = threshold_manager.get_threshold()
    result.used_threshold = current_threshold
    print(f"ğŸ¯ å½“å‰è‡ªé€‚åº”é˜ˆå€¼: {current_threshold:.3f}")

    # Step 3: Qwenåˆæ­¥å›ç­” + å®šä½
    prompt1 = f"é—®é¢˜ï¼š{sample['question']} è¯·å…ˆç»™å‡ºç­”æ¡ˆï¼›å†ä»¥æ ¼å¼(å·¦ä¸Šè§’xåæ ‡,å·¦ä¸Šè§’yåæ ‡) (å³ä¸‹è§’xåæ ‡,å³ä¸‹è§’yåæ ‡) ä¸¤ç‚¹ç”Ÿæˆçš„çŸ©å½¢æ¡†å°†å›¾ç‰‡éœ€è¦å…³æ³¨åŒºåŸŸåŒ…å›´è¿›å»ã€‚"
    print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º: {prompt1}")

    initial_response = call_qwen(prompt1, image_path, config)
    result.qwen_calls += 1

    if not initial_response:
        result.notes = "Qwenåˆæ­¥å›ç­”å¤±è´¥"
        result.total_time = time.time() - start_time
        print(f"âŒ Qwenåˆæ­¥å›ç­”å¤±è´¥")
        return result

    print(f"ğŸ“¥ Qwenåˆæ­¥å›ç­”: {initial_response}")
    result.initial_answer = initial_response
    result.initial_bbox = extract_bbox_from_text(initial_response, img_w, img_h)
    print(f"ğŸ“ æå–çš„BBox: {result.initial_bbox}")

    # Step 4: é—­ç¯éªŒè¯å¾ªç¯
    bbox_str = result.initial_bbox
    refined_answer = ""
    max_confidence = 0.0
    iteration = 0
    passed_verification = False
    verification_iteration = 0

    # ç”¨äºè®°å½•æ¯æ¬¡è¿­ä»£çš„ç½®ä¿¡åº¦
    iteration_confidences = []

    for retry in range(config.MAX_RETRIES + 1):
        iteration += 1
        print(f"\nğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£å°è¯•...")

        # è°ƒç”¨SAMåˆ†å‰²
        print(f"ğŸ“¦ è°ƒç”¨SAMåˆ†å‰²ï¼ŒBBox: {bbox_str}")
        if not call_sam(image_path, bbox_str, config,
                        save_segment=True, iteration=iteration):
            result.notes = f"SAMåˆ†å‰²å¤±è´¥ (è¿­ä»£{iteration})"
            print(f"âŒ SAMåˆ†å‰²å¤±è´¥")
            break

        result.sam_calls += 1

        # æ£€æŸ¥è¯æ®å›¾
        if not os.path.exists(config.TEMP_EVIDENCE_PATH):
            result.notes = f"è¯æ®å›¾æœªç”Ÿæˆ (è¿­ä»£{iteration})"
            print(f"âŒ è¯æ®å›¾æœªç”Ÿæˆ")
            break

        # è¯»å–è¯æ®å›¾
        try:
            evidence_size = os.path.getsize(config.TEMP_EVIDENCE_PATH)
            if evidence_size == 0:
                result.notes = f"è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶ (è¿­ä»£{iteration})"
                print(f"âŒ è¯æ®å›¾ä¸ºç©ºæ–‡ä»¶")
                break

            with open(config.TEMP_EVIDENCE_PATH, "rb") as f:
                evidence_bytes = f.read()
            print(f"ğŸ“„ è¯æ®å›¾å¤§å°: {evidence_size} å­—èŠ‚")
        except Exception as e:
            result.notes = f"è¯»å–è¯æ®å›¾å¤±è´¥: {e}"
            print(f"âŒ è¯»å–è¯æ®å›¾å¤±è´¥: {e}")
            break

        # QwenåŸºäºè¯æ®å›¾é‡æ–°å›ç­”
        prompt2 = f"åªçœ‹è¿™å¼ è£å‰ªåçš„å›¾åƒï¼Œå›ç­”ï¼š{sample['question']}"
        print(f"ğŸ“¤ å‘é€ç»™Qwençš„æç¤º (åŸºäºè¯æ®å›¾): {prompt2}")

        refined_answer = call_qwen(prompt2, config.TEMP_EVIDENCE_PATH, config)
        result.qwen_calls += 1

        if not refined_answer:
            result.notes = f"Qwené‡ç­”å¤±è´¥ (è¿­ä»£{iteration})"
            print(f"âŒ Qwené‡ç­”å¤±è´¥")
            break

        print(f"ğŸ“¥ Qwenç²¾ç‚¼å›ç­”: {refined_answer}")

        # CLIPéªŒè¯
        confidence = call_clip(evidence_bytes, refined_answer, config)
        result.clip_calls += 1
        result.clip_scores[f"iteration_{iteration}"] = float(confidence)

        # è®°å½•æœ€å¤§ç½®ä¿¡åº¦
        iteration_confidences.append(confidence)
        if confidence > max_confidence:
            max_confidence = confidence

        print(f"ğŸ¯ CLIPç½®ä¿¡åº¦: {confidence:.3f} (é˜ˆå€¼: {current_threshold:.3f})")

        if confidence >= current_threshold:
            result.refined_answer = refined_answer
            result.final_confidence = float(confidence)
            result.passed_verification = True
            result.verification_iteration = iteration
            passed_verification = True
            verification_iteration = iteration
            print(f"âœ… éªŒè¯é€šè¿‡!")
            break
        elif retry == 0:
            # ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾
            print(f"âš ï¸ ç¬¬ä¸€æ¬¡éªŒè¯å¤±è´¥ï¼Œå°è¯•å…¨å›¾...")
            bbox_str = f"0,0,{img_w},{img_h}"
        else:
            print(f"âš ï¸ ç¬¬{retry + 1}æ¬¡éªŒè¯å¤±è´¥")

    result.iteration_count = iteration
    result.total_time = time.time() - start_time

    # è®°å½•æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦
    result.max_iteration_confidence = max_confidence

    # å¦‚æœç²¾ç‚¼ç­”æ¡ˆä¸ºç©ºï¼Œä½¿ç”¨åˆå§‹ç­”æ¡ˆ
    if not result.refined_answer and result.initial_answer:
        result.refined_answer = result.initial_answer
        # å¦‚æœæ²¡æœ‰CLIPéªŒè¯ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
        if result.final_confidence == 0.0:
            result.final_confidence = 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
        print(f"âš ï¸ ä½¿ç”¨åˆå§‹ç­”æ¡ˆä½œä¸ºç²¾ç‚¼ç­”æ¡ˆ (æœªé€šè¿‡éªŒè¯)")

    print(f"ğŸ’¡ æœ€ç»ˆç­”æ¡ˆ: {result.refined_answer}")
    print(f"ğŸ“Š æœ€ç»ˆç½®ä¿¡åº¦: {result.final_confidence:.3f}")
    print(f"ğŸ“ˆ æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦: {max_confidence:.3f}")
    print(f"âœ… éªŒè¯çŠ¶æ€: {'é€šè¿‡' if passed_verification else 'æœªé€šè¿‡'}")

    # è¯„ä¼°å‡†ç¡®æ€§ï¼ˆåŸºäºæœ€ç»ˆç­”æ¡ˆï¼‰
    answer_to_evaluate = result.refined_answer
    result.accuracy, result.is_correct = calculate_accuracy(
        answer_to_evaluate,
        sample['answers']
    )

    # åˆ†æå¤±è´¥ç±»å‹
    if not result.is_correct:
        result.failure_type = analyze_failure_type(result, current_threshold)
        print(f"âŒ ç­”æ¡ˆé”™è¯¯ï¼Œå¤±è´¥ç±»å‹: {result.failure_type}")
    else:
        print(f"âœ… ç­”æ¡ˆæ­£ç¡®!")

    print(f"â±ï¸ å¤„ç†æ—¶é—´: {result.total_time:.2f}ç§’")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iteration_count}")
    print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡: SAM={result.sam_calls}, CLIP={result.clip_calls}, Qwen={result.qwen_calls}")

    # å‡†å¤‡éªŒè¯è¯¦æƒ…ç”¨äºæ›´æ–°é˜ˆå€¼
    verification_details = {
        'max_confidence': max_confidence,
        'is_correct': result.is_correct,
        'passed_verification': passed_verification,
        'used_threshold': current_threshold,
        'iteration_confidences': iteration_confidences,
        'verification_iteration': verification_iteration,
        'final_answer': result.refined_answer
    }

    # æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨
    print(f"\nğŸ”„ æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼...")
    new_threshold = threshold_manager.update(verification_details)
    print(f"ğŸ“ˆ æ›´æ–°åçš„é˜ˆå€¼: {new_threshold:.3f}")

    return result


# ==================== å®éªŒç®¡ç† ====================
class ExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.results: List[ExperimentResult] = []
        self.stats = SystemStatistics()
        self.threshold_manager = AdaptiveThresholdManager(config)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}")

    def run_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print("ğŸš€ å¼€å§‹è‡ªé€‚åº”é˜ˆå€¼å®éªŒ...")
        print(f"ğŸ“Š åˆå§‹é˜ˆå€¼: {self.config.INITIAL_CONFIDENCE_THRESHOLD}")
        print(f"ğŸ“Š é˜ˆå€¼èŒƒå›´: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]")
        print(f"ğŸ“Š æ›´æ–°ç­–ç•¥: ä»…åœ¨éªŒè¯é€šè¿‡æ—¶æ›´æ–°={self.config.UPDATE_ONLY_ON_VERIFIED}")

        # åŠ è½½æ•°æ®
        samples = load_textvqa_dataset(self.config)
        if not samples:
            print("âŒ æ— æ³•åŠ è½½æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼")
            return

        self.stats.total_samples = len(samples)

        # é€ä¸ªè¿è¡Œå®éªŒ
        for i, sample in enumerate(tqdm(samples, desc="è¿›è¡Œå®éªŒ")):
            print(f"\n{'='*80}")
            print(f"ğŸ“‹ æ ·æœ¬ {i + 1}/{len(samples)}")

            result = run_single_experiment(sample, self.config, self.threshold_manager)
            self.results.append(result)

            # æ›´æ–°ç»Ÿè®¡
            self.stats.correct_samples += 1 if result.is_correct else 0
            self.stats.verified_samples += 1 if result.passed_verification else 0
            self.stats.total_iterations += result.iteration_count
            self.stats.total_sam_calls += result.sam_calls
            self.stats.total_clip_calls += result.clip_calls
            self.stats.total_qwen_calls += result.qwen_calls
            self.stats.total_time += result.total_time

            # æ›´æ–°é˜ˆå€¼ç»Ÿè®¡
            self.stats.threshold_stats['min_threshold'] = min(
                self.stats.threshold_stats['min_threshold'],
                result.used_threshold
            )
            self.stats.threshold_stats['max_threshold'] = max(
                self.stats.threshold_stats['max_threshold'],
                result.used_threshold
            )

            if result.failure_type:
                self.stats.failure_counts[result.failure_type] += 1

            # æ›´æ–°è‡ªé€‚åº”æ€§èƒ½ç»Ÿè®¡
            if result.passed_verification:
                if result.is_correct:
                    self.stats.adaptive_performance['verified_correct'] += 1
                else:
                    self.stats.adaptive_performance['verified_wrong'] += 1
            else:
                if result.is_correct:
                    self.stats.adaptive_performance['unverified_correct'] += 1
                else:
                    self.stats.adaptive_performance['unverified_wrong'] += 1

            # æ¯5ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡è¿›åº¦
            if (i + 1) % 5 == 0:
                self.save_results()
                print(f"\nğŸ’¾ å·²ä¿å­˜{len(self.results)}ä¸ªæ ·æœ¬çš„ç»“æœ")
                print(f"ğŸ“ˆ å½“å‰å‡†ç¡®ç‡: {self.stats.correct_samples}/{len(self.results)} ({self.stats.accuracy:.2%})")
                print(f"âœ… éªŒè¯é€šè¿‡ç‡: {self.stats.verified_samples}/{len(self.results)} ({self.stats.verified_samples/len(self.results):.2%})")

        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        self._calculate_final_stats()

        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_results()
        self.threshold_manager.save_threshold_log(self.config.THRESHOLD_LOG)
        self.generate_report()
        print("\nâœ… è‡ªé€‚åº”é˜ˆå€¼å®éªŒå®Œæˆ!")

    def _calculate_final_stats(self):
        """è®¡ç®—æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—å¹³å‡é˜ˆå€¼
        thresholds = [r.used_threshold for r in self.results]
        self.stats.threshold_stats['avg_threshold'] = np.mean(thresholds)

        # è®¡ç®—é˜ˆå€¼è°ƒæ•´æ¬¡æ•°
        threshold_history = self.threshold_manager.threshold_history
        adjustments = sum(1 for i in range(1, len(threshold_history))
                         if abs(threshold_history[i] - threshold_history[i-1]) > 0.01)
        self.stats.threshold_stats['threshold_adjustments'] = adjustments

        # è®¡ç®—éªŒè¯ç»Ÿè®¡
        verified_confidences = [r.max_iteration_confidence for r in self.results if r.passed_verification]
        unverified_confidences = [r.max_iteration_confidence for r in self.results if not r.passed_verification]

        self.stats.verification_stats['verification_rate'] = (
            self.stats.verified_samples / self.stats.total_samples if self.stats.total_samples > 0 else 0
        )
        self.stats.verification_stats['avg_verified_confidence'] = (
            np.mean(verified_confidences) if verified_confidences else 0
        )
        self.stats.verification_stats['avg_unverified_confidence'] = (
            np.mean(unverified_confidences) if unverified_confidences else 0
        )

        # è®¡ç®—é˜ˆå€¼æœ‰æ•ˆæ€§ï¼šéªŒè¯é€šè¿‡çš„æ­£ç¡®ç‡
        if self.stats.verified_samples > 0:
            verified_correct_rate = (
                self.stats.adaptive_performance['verified_correct'] / self.stats.verified_samples
            )
            self.stats.adaptive_performance['threshold_effectiveness'] = verified_correct_rate

        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   å¹³å‡é˜ˆå€¼: {self.stats.threshold_stats['avg_threshold']:.3f}")
        print(f"   éªŒè¯é€šè¿‡ç‡: {self.stats.verification_stats['verification_rate']:.2%}")
        print(f"   éªŒè¯é€šè¿‡çš„æ­£ç¡®ç‡: {self.stats.adaptive_performance['threshold_effectiveness']:.2%}")

    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # è½¬æ¢ç»“æœä¸ºå­—å…¸
        results_list = []
        for r in self.results:
            result_dict = {
                'id': int(r.sample_id),
                'question': str(r.question),
                'image_file': str(r.image_file),
                'ground_truth': [str(ans) for ans in r.ground_truth_answers],
                'initial_answer': str(r.initial_answer),
                'initial_bbox': str(r.initial_bbox),
                'refined_answer': str(r.refined_answer),
                'confidence': float(r.final_confidence),
                'max_iteration_confidence': float(r.max_iteration_confidence),
                'used_threshold': float(r.used_threshold),
                'passed_verification': bool(r.passed_verification),
                'verification_iteration': int(r.verification_iteration),
                'clip_scores': {k: float(v) for k, v in r.clip_scores.items()},
                'is_correct': bool(r.is_correct),
                'accuracy': float(r.accuracy),
                'failure_type': str(r.failure_type),
                'iteration_count': int(r.iteration_count),
                'sam_calls': int(r.sam_calls),
                'clip_calls': int(r.clip_calls),
                'qwen_calls': int(r.qwen_calls),
                'time': float(r.total_time),
                'notes': str(r.notes)
            }
            results_list.append(result_dict)

        # è·å–é˜ˆå€¼ç»Ÿè®¡
        threshold_stats = self.threshold_manager.get_history_stats()

        results_dict = {
            'config': {
                'initial_threshold': float(self.config.INITIAL_CONFIDENCE_THRESHOLD),
                'min_threshold': float(self.config.MIN_THRESHOLD),
                'max_threshold': float(self.config.MAX_THRESHOLD),
                'window_size': int(self.config.ADAPTIVE_WINDOW_SIZE),
                'update_only_on_verified': bool(self.config.UPDATE_ONLY_ON_VERIFIED),
                'min_confidence_for_update': float(self.config.MIN_CONFIDENCE_FOR_UPDATE),
                'max_retries': int(self.config.MAX_RETRIES),
                'num_samples': int(self.config.NUM_SAMPLES),
                'random_seed': int(self.config.RANDOM_SEED)
            },
            'adaptive_threshold_stats': threshold_stats,
            'statistics': {
                'total_samples': int(self.stats.total_samples),
                'correct_samples': int(self.stats.correct_samples),
                'verified_samples': int(self.stats.verified_samples),
                'accuracy': float(self.stats.accuracy),
                'total_iterations': int(self.stats.total_iterations),
                'avg_iterations': float(self.stats.avg_iterations),
                'total_sam_calls': int(self.stats.total_sam_calls),
                'total_clip_calls': int(self.stats.total_clip_calls),
                'total_qwen_calls': int(self.stats.total_qwen_calls),
                'total_time': float(self.stats.total_time),
                'avg_time_per_sample': float(self.stats.avg_time_per_sample),
                'threshold_stats': self.stats.threshold_stats,
                'adaptive_performance': self.stats.adaptive_performance,
                'verification_stats': self.stats.verification_stats,
                'failure_counts': {k: int(v) for k, v in self.stats.failure_counts.items()}
            },
            'results': results_list
        }

        # ä¿å­˜JSON
        with open(self.config.RESULTS_JSON, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)

        # ä¿å­˜CSV
        with open(self.config.STATS_CSV, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ ·æœ¬ID', 'é—®é¢˜', 'å›¾åƒ', 'å‚è€ƒç­”æ¡ˆ',
                'åˆå§‹ç­”æ¡ˆ', 'ç²¾ç‚¼ç­”æ¡ˆ', 'ç½®ä¿¡åº¦', 'æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦', 'ä½¿ç”¨é˜ˆå€¼',
                'æ˜¯å¦éªŒè¯é€šè¿‡', 'éªŒè¯è¿­ä»£', 'æ˜¯å¦æ­£ç¡®', 'å‡†ç¡®ç‡', 'å¤±è´¥ç±»å‹',
                'è¿­ä»£æ¬¡æ•°', 'SAMè°ƒç”¨', 'CLIPè°ƒç”¨', 'Qwenè°ƒç”¨',
                'æ—¶é—´(s)', 'å¤‡æ³¨'
            ])

            for r in self.results:
                writer.writerow([
                    int(r.sample_id),
                    str(r.question)[:50],
                    str(r.image_file),
                    '; '.join([str(ans) for ans in r.ground_truth_answers[:3]]),
                    str(r.initial_answer)[:30],
                    str(r.refined_answer)[:30],
                    f"{float(r.final_confidence):.3f}",
                    f"{float(r.max_iteration_confidence):.3f}",
                    f"{float(r.used_threshold):.3f}",
                    "æ˜¯" if r.passed_verification else "å¦",
                    int(r.verification_iteration),
                    "æ˜¯" if r.is_correct else "å¦",
                    f"{float(r.accuracy):.3f}",
                    str(r.failure_type),
                    int(r.iteration_count),
                    int(r.sam_calls),
                    int(r.clip_calls),
                    int(r.qwen_calls),
                    f"{float(r.total_time):.2f}",
                    str(r.notes)[:50]
                ])

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {self.config.OUTPUT_DIR}")

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        threshold_stats = self.threshold_manager.get_history_stats()

        report = f"""
# è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿå®éªŒæŠ¥å‘Š (æ”¹è¿›ç‰ˆ)

## 1. å®éªŒæ¦‚è¿°
- **ç³»ç»Ÿç±»å‹**: è‡ªé€‚åº”é˜ˆå€¼é—­ç¯ç³»ç»Ÿ (æ”¹è¿›ç‰ˆ)
- **æ•°æ®é›†**: MyVQA ({self.stats.total_samples}ä¸ªæ ·æœ¬)
- **é˜ˆå€¼ç­–ç•¥**: åŸºäºéªŒè¯è¡¨ç°åŠ¨æ€è°ƒæ•´
- **é˜ˆå€¼èŒƒå›´**: [{self.config.MIN_THRESHOLD}, {self.config.MAX_THRESHOLD}]
- **åˆå§‹é˜ˆå€¼**: {self.config.INITIAL_CONFIDENCE_THRESHOLD}
- **æ›´æ–°ç­–ç•¥**: ä»…åœ¨éªŒè¯é€šè¿‡æ—¶æ›´æ–°={self.config.UPDATE_ONLY_ON_VERIFIED}
- **æœ€å°æ›´æ–°ç½®ä¿¡åº¦**: {self.config.MIN_CONFIDENCE_FOR_UPDATE}
- **éšæœºç§å­**: {self.config.RANDOM_SEED}

## 2. ä¸»è¦ç»“æœ
- **æ€»ä½“å‡†ç¡®ç‡**: {self.stats.accuracy:.2%} ({self.stats.correct_samples}/{self.stats.total_samples})
- **éªŒè¯é€šè¿‡ç‡**: {self.stats.verification_stats['verification_rate']:.2%} ({self.stats.verified_samples}/{self.stats.total_samples})
- **å¹³å‡è¿­ä»£æ¬¡æ•°**: {self.stats.avg_iterations:.2f}
- **å¹³å‡å¤„ç†æ—¶é—´**: {self.stats.avg_time_per_sample:.2f}ç§’/æ ·æœ¬
- **æ€»å®éªŒæ—¶é—´**: {self.stats.total_time:.2f}ç§’

## 3. è‡ªé€‚åº”é˜ˆå€¼ç»Ÿè®¡
- **å¹³å‡é˜ˆå€¼**: {self.stats.threshold_stats['avg_threshold']:.3f}
- **æœ€å°é˜ˆå€¼**: {self.stats.threshold_stats['min_threshold']:.3f}
- **æœ€å¤§é˜ˆå€¼**: {self.stats.threshold_stats['max_threshold']:.3f}
- **é˜ˆå€¼è°ƒæ•´æ¬¡æ•°**: {self.stats.threshold_stats['threshold_adjustments']}
- **éªŒè¯é€šè¿‡ç‡**: {self.stats.verification_stats['verification_rate']:.2%}

## 4. éªŒè¯è¡¨ç°åˆ†æ
### 4.1 éªŒè¯é€šè¿‡æ ·æœ¬
- **éªŒè¯é€šè¿‡ä¸”æ­£ç¡®**: {self.stats.adaptive_performance['verified_correct']}ä¸ª
- **éªŒè¯é€šè¿‡ä½†é”™è¯¯**: {self.stats.adaptive_performance['verified_wrong']}ä¸ª
- **éªŒè¯é€šè¿‡çš„æ­£ç¡®ç‡**: {self.stats.adaptive_performance['threshold_effectiveness']:.2%}
- **å¹³å‡ç½®ä¿¡åº¦**: {self.stats.verification_stats['avg_verified_confidence']:.3f}

### 4.2 æœªéªŒè¯æ ·æœ¬
- **æœªéªŒè¯ä½†æ­£ç¡®**: {self.stats.adaptive_performance['unverified_correct']}ä¸ª
- **æœªéªŒè¯ä¸”é”™è¯¯**: {self.stats.adaptive_performance['unverified_wrong']}ä¸ª
- **å¹³å‡ç½®ä¿¡åº¦**: {self.stats.verification_stats['avg_unverified_confidence']:.3f}

## 5. å·¥å…·è°ƒç”¨ç»Ÿè®¡
- SAMè°ƒç”¨æ¬¡æ•°: {self.stats.total_sam_calls}
- CLIPè°ƒç”¨æ¬¡æ•°: {self.stats.total_clip_calls}
- Qwenè°ƒç”¨æ¬¡æ•°: {self.stats.total_qwen_calls}

## 6. å¤±è´¥åˆ†æ
"""

        total_failures = sum(self.stats.failure_counts.values())
        for failure_type, count in self.stats.failure_counts.items():
            if count > 0:
                percentage = count / total_failures * 100 if total_failures > 0 else 0
                report += f"- **{failure_type}**: {count}æ¬¡ ({percentage:.1f}%)\n"

        report += """
## 7. æ”¹è¿›çš„é˜ˆå€¼è°ƒæ•´ç­–ç•¥

### 7.1 ä¸»è¦æ”¹è¿›
1. **åªåœ¨éªŒè¯é€šè¿‡çš„æ ·æœ¬ä¸Šæ›´æ–°é˜ˆå€¼**ï¼šé¿å…å…œåº•å›ç­”å¹²æ‰°é˜ˆå€¼è°ƒæ•´
2. **ä½¿ç”¨æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦**ï¼šæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹ç½®ä¿¡åº¦
3. **è¯¦ç»†çš„éªŒè¯ç»Ÿè®¡**ï¼šåŒºåˆ†éªŒè¯é€šè¿‡å’Œæœªé€šè¿‡æ ·æœ¬
4. **æ›´åˆç†çš„è°ƒæ•´è§„åˆ™**ï¼šåŸºäºéªŒè¯è¡¨ç°è°ƒæ•´ï¼Œè€Œéæœ€ç»ˆç»“æœ

### 7.2 è°ƒæ•´è§„åˆ™
1. **é«˜æ­£ç¡®ç‡é«˜ç½®ä¿¡åº¦**ï¼šç¨å¾®æé«˜é˜ˆå€¼ä»¥æé«˜ç²¾åº¦
2. **ä½æ­£ç¡®ç‡**ï¼šæé«˜é˜ˆå€¼ä»¥å‡å°‘è¯¯åˆ¤
3. **ä½éªŒè¯ç‡ä½†ä¸­ç­‰ç½®ä¿¡åº¦**ï¼šé™ä½é˜ˆå€¼ä»¥æé«˜éªŒè¯é€šè¿‡ç‡
4. **åŸºäºå¹³æ»‘ç½®ä¿¡åº¦å¾®è°ƒ**ï¼šä¿æŒé˜ˆå€¼ç¨³å®šæ€§

## 8. ä¼˜åŠ¿åˆ†æ
1. **é¿å…å…œåº•å¹²æ‰°**ï¼šé˜ˆå€¼è°ƒæ•´ä¸å—åˆå§‹ç­”æ¡ˆå½±å“
2. **æ›´å‡†ç¡®çš„ç½®ä¿¡åº¦è¯„ä¼°**ï¼šä½¿ç”¨æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦
3. **æ›´å¥½çš„æ³›åŒ–æ€§**ï¼šé˜ˆå€¼åŸºäºéªŒè¯è¡¨ç°è€Œéæœ€ç»ˆç»“æœ
4. **æ›´é«˜çš„ç¨³å®šæ€§**ï¼šå‡å°‘é˜ˆå€¼å¤§å¹…æ³¢åŠ¨

## 9. æ ·æœ¬ç¤ºä¾‹
"""

        # æ·»åŠ 3ä¸ªä»£è¡¨æ€§ç¤ºä¾‹
        for i, r in enumerate(self.results[:3]):
            report += f"""
### ç¤ºä¾‹ {i + 1}
- **æ ·æœ¬ID**: {r.sample_id}
- **é—®é¢˜**: {r.question}
- **å›¾åƒ**: {r.image_file}
- **éªŒè¯çŠ¶æ€**: {'é€šè¿‡' if r.passed_verification else 'æœªé€šè¿‡'}
- **ä½¿ç”¨é˜ˆå€¼**: {r.used_threshold:.3f}
- **æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦**: {r.max_iteration_confidence:.3f}
- **ç²¾ç‚¼ç­”æ¡ˆ**: {r.refined_answer}
- **å‚è€ƒç­”æ¡ˆ**: {', '.join(r.ground_truth_answers[:3])}
- **æ˜¯å¦æ­£ç¡®**: {'æ˜¯' if r.is_correct else 'å¦'}
- **å¤„ç†æ—¶é—´**: {r.total_time:.2f}ç§’
- **è¿­ä»£æ¬¡æ•°**: {r.iteration_count}
"""

        report_path = os.path.join(self.config.OUTPUT_DIR, "adaptive_experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ğŸ“Š å®éªŒæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")


# ==================== ä¸»ç¨‹åº ====================
def main():
    # åˆå§‹åŒ–é…ç½®
    config = Config()

    # ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•éƒ½å­˜åœ¨
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    os.makedirs(config.SAM_SEGMENTS_DIR, exist_ok=True)

    # è¿è¡Œä¸»å®éªŒ
    print("=" * 80)
    print("ğŸ¤– è‡ªé€‚åº”é˜ˆå€¼VQAé—­ç¯ç³»ç»Ÿ (æ”¹è¿›ç‰ˆ)")
    print("=" * 80)
    print("ğŸ“Š ä¸»è¦æ”¹è¿›:")
    print("  1. åªåœ¨éªŒè¯é€šè¿‡çš„æ ·æœ¬ä¸Šæ›´æ–°é˜ˆå€¼")
    print("  2. ä½¿ç”¨æœ€å¤§è¿­ä»£ç½®ä¿¡åº¦è€Œä¸æ˜¯æœ€ç»ˆç½®ä¿¡åº¦")
    print("  3. æ–°å¢éªŒè¯é€šè¿‡ç‡ç»Ÿè®¡")
    print("  4. æ›´åˆç†çš„é˜ˆå€¼è°ƒæ•´ç­–ç•¥")

    manager = ExperimentManager(config)
    manager.run_experiments()

    print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {config.OUTPUT_DIR}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {config.RESULTS_JSON}")
    print(f"ğŸ“Š ç»Ÿè®¡è¡¨æ ¼: {config.STATS_CSV}")
    print(f"ğŸ“ˆ é˜ˆå€¼æ¼”åŒ–: {config.THRESHOLD_LOG}")
    print(f"ğŸ“‹ å®éªŒæŠ¥å‘Š: {config.OUTPUT_DIR}/adaptive_experiment_report.md")
    print(f"ğŸ–¼ï¸  SAMåˆ†å‰²å›¾åƒ: {config.SAM_SEGMENTS_DIR}")


if __name__ == "__main__":
    main()